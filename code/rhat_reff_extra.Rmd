---
title: "Rank-normalized split-Rhat and relative efficiency estimates"
author: "Aki Vehtari, Andrew Gelman, Daniel Simpson, Bob Carpenter, Paul BÃ¼rkner"
date: "First version 2017-05-23. Last modified `r format(Sys.Date())`."
encoding: "UTF-8"
output:
  html_document:
    fig_caption: yes
    toc: TRUE
    toc_depth: 2
    number_sections: TRUE
    toc_float:
      smooth_scroll: FALSE
bibliography: rhat_neff.bib
csl: harvard-cite-them-right.csl
---

# Setup {.unnumbered}

```{r setup, include=FALSE}
knitr::opts_chunk$set(
  comment=NA, 
  cache=FALSE,
  fig.width = 10
)
options(width=78)
```

The code for alternative new *split*-$\widehat{R}$ and $S_{\rm eff}$ versions are in [monitornew.R](monitornew.R).

**Load packages**
```{r, comment=NA, message=FALSE, warning=FALSE, results='hide', cache=FALSE}
library(rstan)
options(mc.cores = parallel::detectCores())
rstan_options(auto_write = TRUE)
library(bayesplot)
theme_set(bayesplot::theme_default(base_family = "sans"))
library(tidyverse)
library(gridExtra)
library(latex2exp)
source('monitornew.R')
source('monitorplot.R')
source('stan_utility.R')
```

# Introduction

Split-$\widehat{R}$ and effective sample size $S_{\rm eff}$
(previously $N_{\rm eff}$ or $n_{\rm eff}$), are routinely used
to monitor the convergence of iterative simulations.  $\widehat{R}$
[@Gelman+Rubin:1992; @Brooks+Gelman:1998] and
*split*-$\widehat{R}$ [@BDA3] are based on the ratio of
between and within-chain marginal variances of the simulations. The
effective sample size estimate by @BDA3
is based on marginal variance and autocorrelation estimates from split
chains.

$\widehat{R}$, *split*-$\widehat{R}$, and $S_{\rm eff}$ are well
defined only if the marginal distributions have finite mean and
variance.  and even in that case, they are less stable for
distributions with long tails. To alleviate these problems, we propose
to compute *split*-$\widehat{R}$ and $S_{\rm eff}$ using rank
normalized values, empirical cumulative density functions, and small
posterior intervals.

We additionally propose

- to diagnose convergence and relative efficiency of the scale of the
  marginal distribution in addition to the usual location estimate
  (mean or median)
- to use relative efficiency of several ECDFs or small interval
  probability estimates as local relative efficiency measures to
  reveal local sampling problems
- to compute Monte Carlo error of quantiles (including median) via
  empirical inverse transform of the Monte Carlo error of ECDF
- to use local efficiency and rank plots as a more compact alternative
  to trace plots.

# Review of *split*-$\widehat{R}$ and effective sample size

In this section, we will review split-$\widehat{R}$ and 
effective sample size estimates as implemented in Stan 2.18 [@Stan.2.18].

## *Split*-$\widehat{R}$ {#SplitRhat}

Below, we present the computation of *Split*-$\widehat{R}$ following
@BDA3, but using the notation style of @StanBook. Our recommendation
is to run several chains. $N$ is the number of draws per chain, $M$ is
the number of chains, and $S=MN$ is the total number of draws from all
chains. For each scalar summary of interest $\theta$, we
compute $B$ and $W$, the between- and within-chain variances:
<!--
$$
B = \frac{N}{M-1}\sum_{m=1}^{M}(\overline{\theta}_{.m}-\overline{\theta}_{..})^2,
\;\mbox{ where }\;\;\overline{\theta}_{.m}=\frac{1}{N}\sum_{n=1}^nN \theta_{nm},\;\;
\;\;\overline{\theta}_{..} = \frac{1}{M}\sum_{m=1}^M\overline{\theta}_{.m}\\
W =
 \frac{1}{M}\sum_{m=1}^{M}s_j^2, \;\mbox{ where }\;\; s_m^2=\frac{1}{N-1}
\sum_{n=1}^N (\theta_{nm}-\overline{\theta}_{.m})^2.
$$
-->
$$
B = \frac{N}{M-1}\sum_{m=1}^{M}(\overline{\theta}^{(.m)}-\overline{\theta}^{(..)})^2,
\;\mbox{ where }\;\;\overline{\theta}^{(.m)}=\frac{1}{N}\sum_{n=1}^N \theta^{(nm)},\;\;
\;\;\overline{\theta}^{(..)} = \frac{1}{M}\sum_{m=1}^M\overline{\theta}^{(.m)}\\
W =
 \frac{1}{M}\sum_{m=1}^{M}s_j^2, \;\mbox{ where }\;\; s_m^2=\frac{1}{N-1}
\sum_{n=1}^N (\theta^{(nm)}-\overline{\theta}^{(.m)})^2.
$$

The between-chain variance, $B$, 
also contains the factor $N$ because it is based on the variance of 
the within-chain means, $\overline{\theta}^{(.m)}$, each of which 
is an average of $N$ values $\theta^{(nm)}$.

We can estimate $\mbox{var}(\theta \mid y)$, the marginal posterior variance
of the estimand, by a weighted average of $W$ and $B$, namely
$$
\widehat{\mbox{var}}^+(\theta \mid y)=\frac{N-1}{N}W + \frac{1}{N}B.
$$
This quantity *overestimates* the marginal posterior variance 
assuming the starting distribution is appropriately overdispersed
compared to the target distribution, 
but is *unbiased* under stationarity (that is, if the starting 
distribution equals the target distribution), or in the limit
$N\rightarrow\infty$. To have an overdispersed starting distribution, 
independent Markov chains should be initialized with diffuse starting
values for the parameters.

Meanwhile, for any finite $N$, the within-chain variance
$W$ should *underestimate* $\mbox{var}(\theta \mid y)$ because the 
individual chains haven't had the time to explore all of the target 
distribution and, as a result, will have less variability. 
In the limit as $N\rightarrow\infty$, the expectation of $W$ 
approaches $\mbox{var}(\theta \mid y)$.

We monitor convergence of the iterative simulation to the target
distribution by estimating the factor by which the scale of the 
current distribution for $\theta$ might be reduced if the simulations 
were continued in the limit $N\rightarrow\infty$. This potential 
scale reduction is estimated as
$$
\widehat{R}=
\sqrt{\frac{\widehat{\mbox{var}}^+(\theta \mid y)}{W}},
$$
which declines to 1 as $N\rightarrow\infty$. We call this *split*-$\widehat{R}$
because we are applying it to chains that have been split in half so that $M$ is
twice the number of actual chains. Without splitting, $\widehat{R}$ would get
fooled by non-stationary chains.

We note that *split*-$\widehat{R}$ is also well defined for sequences that are not Markov-chains. However, for simplicity, we always refer to 'chains' instead
of more generally to 'sequences' as the former is our primary use case for 
$\widehat{R}$ measures.

## Effective sample size $S_{\rm eff}$ {#Seff}

If the $N$ simulation draws within each chain were truly
independent, the between-chain variance $B$ would be an unbiased
estimate of the posterior variance, $\mbox{var}(\theta \mid y)$, and we would have
a total of $S = M \times N$ independent simulations from the $M$
chains. In general, however, the simulations of $\theta$ within each
chain will be autocorrelated, and thus $B$ will be larger than 
$\mbox{var}(\theta \mid y)$, in expectation.

A nice introductory reference for analyzing MCMC results in general
and effective sample size in particular is provided by @Geyer:2011
[see also @Geyer:1992].  The particular calculations used by Stan
[@Stan.2.18] follow those for split-$\hat{R}$, which involve both
between-chain (mean) and within-chain calculations
(autocorrelation). They were introduced in the Stan manual
[@StanManual.2.18.0] and explained in more detail in @BDA3.

One way to define effective sample size for correlated simulation
draws is to consider the statistical efficiency of the average of the
simulations $\bar{\theta}^{(..)}$ as an estimate of the posterior mean
$\mbox{E}(\theta \mid y)$. This can be a reasonable baseline even though it is
not the only possible summary and might be inappropriate, for example,
if there is particular interest in accurate representation of
low-probability events in the tails of the distribution.

The effective sample size of a chain is defined in terms of the
autocorrelations within the chain at different lags. The
autocorrelation $\rho_t$ at lag $t \geq 0$ for a chain with joint
probability function $p(\theta)$ with mean $\mu$ and variance
$\sigma^2$ is defined to be
$$
\rho_t 
=
\frac{1}{\sigma^2} \, \int_{\Theta} (\theta^{(n)} - \mu)
(\theta^{(n+t)} - \mu) \, p(\theta) \, d\theta.
$$
This is just the correlation between the two chains offset by $t$
positions.  Because we know $\theta^{(n)}$ and $\theta^{(n+t)}$ have
the same marginal distribution in an MCMC setting, multiplying the
two difference terms and reducing yields
$$
\rho_t
=
\frac{1}{\sigma^2} \, \int_{\Theta} \theta^{(n)} \, \theta^{(n+t)} \, p(\theta) \, d\theta.
$$

The effective sample size of one chain generated by a process with
autocorrelations $\rho_t$ is defined by
$$
N_{\rm eff}
\ = \
\frac{N}{\sum_{t = -\infty}^{\infty} \rho_t}
\ = \
\frac{N}{1 + 2 \sum_{t = 1}^{\infty} \rho_t}.
$$

Effective sample size $N_{\rm eff}$ can be larger than $N$ in case of
antithetic Markov chains, which have negative autocorrelations on odd
lags. Dynamic Hamiltonian algorithm [@Hoffman+Gelman:2014] used in Stan 
can produce $N_{\rm eff}>N$ for parameters which have close to Gaussian 
posterior with low dependency on other parameters (before version 2.18, 
Stan computed $N_{\rm eff}$ so that the maximum reported value was $N$).

\subsection{Estimation of Effective Sample Size}

In practice, the probability function in question cannot be tractably
integrated and thus neither autocorrelation not the effective sample size
can be calculated. Instead, these quantities must be estimated
from the samples themselves. The rest of this section describes an
autocorrelation and split-$\hat{R}$ based effective sample
size estimator, based on multiple split chains. For simplicity, 
each chain will be assumed to be of the same length $N$.

Stan carries out the autocorrelation computations for all lags
simultaneously using Eigen's fast Fourier transform (FFT) package with
appropriate padding; see @Geyer:2011 for more details on using
FFT for autocorrelation calculations.
The autocorrelation estimates $\hat{\rho}_{t,m}$ at lag $t$ from
multiple chains $m \in (1,\ldots,M)$ are combined with the within-chain
variance estimate $W$ and the multi-chain variance estimate
$\widehat{\mbox{var}}^{+}$ introduced in the previous section to
compute the combined autocorrelation at lag $t$ as
$$
\hat{\rho}_t
= 1 - \frac{\displaystyle W - \textstyle \frac{1}{M}\sum_{m=1}^M 
\hat{\rho}_{t,j}}{\widehat{\mbox{var}}^{+}}. \label{rhohat}
$$
If the chains have not converged, the variance estimator
$\widehat{\mbox{var}}^{+}$ will overestimate the true marginal variance 
which leads to an overestimation of the autocorrelation and an 
underestimation of the effective sample size.

Because of the noise in the correlation estimates $\hat{\rho}_t$ as
$t$ increases, typically the truncated sum of $\hat{\rho}_t$ is used.
Negative autocorrelations can happen only on odd lags and by summing
over pairs starting from lag $t=0$, the paired autocorrelation is
guaranteed to be positive, monotone and convex modulo estimator noise
[@Geyer:1992; @Geyer:2011].  Stan 2.18 uses Geyer's initial monotone
sequence criterion. The effective sample size of combined chains is defined as
$$
S_{\rm eff} = \frac{N \, M}{\hat{\tau}},
$$
where
$$
\hat{\tau} = 1 + 2 \sum_{t=1}^{2k+1} \hat{\rho}_t = 
-1 + 2 \sum_{t'=0}^{k} \hat{P}_{t'},
$$
and $\hat{P}_{t'}=\hat{\rho}_{2t'}+\hat{\rho}_{2t'+1}$. Initial
positive sequence estimators is obtained by choosing the largest $k$
such that $\hat{P}_{t'}>0, \quad t' = 1,\ldots,k$. The initial monotone
sequence is obtained by further reducing $\hat{P}_{t'}$ to the minimum
of the preceding ones so that the estimated sequence is monotone.

$S_{\rm eff}$ described here is different from similar formulas in
the literature in that we use multiple chains and between-chain variance in the
computation which typically gives us more conservative claims (lower
values of $S_{\rm eff}$) compared to single chain
estimates, especially when mixing is poor. If the chains are not
mixing at all (e.g. the posterior is multimodal and the chains are
stuck in different modes), then our $S_{\rm eff}$ is close to
the number of chains.

In Stan pre 2.18, a slightly incorrect initial sequence was used, which 
implied that $S_{\rm eff}$ was capped at $S$. As
antithetic behavior $S_{\rm eff} > S$ is not that common or the
effect is small and capping at $S$ can be considered to be
pessimistic, this had negligible effect on any inference.
However, it may have led to an underestimation of Stan's efficiency
when compared to other packages performing MCMC sampling.

# Rank normalized *split*-$\widehat{R}$ and relative efficiency estimates

As *split*-$\widehat{R}$, and $S_{\rm eff}$ are well defined only if
the marginal posteriors have finite mean and variance, we next
describe variants which are well defined for all distributions and
more robust for long tailed distributions.

<!--
We should be thinking of standardizing the notation
a bit more. For instance, we use \psi and \theta for parameters
and later used x and y for some arbitrary quantity.
I have already tried to standardized the notation, but not
sure how successful I was.
-->

## Rank normalization

<!--
*Split*-$\widehat{R}$ assumes that the quantities being considered
have finite mean and variance and it's more stable for distributions
close to Gaussian.  Target distribution can be far from normal and for
example Cauchy distribution has non-finite mean and  variance,
and thus *split*-$\widehat{R}$ is not well defined. To alleviate
those we propose to compute *split*-$\widehat{R}$ using rank
normalized values.
-->

Rank normalization is commonly used, for example, in Spearman's rank
correlation coefficient and to transform predictor values in
epidemiology.

1. Rank: Replace each value $\theta^{(nm)}$ by its rank $r^{(nm)}$. Average
rank for ties are used to conserve the number of unique values of discrete
quantities. Ranks are computed jointly for all draws from all chains.
2. Normalize: Normalize ranks by inverse normal transformation $z^{(nm)} =
\phi^{-1}((r^{(nm)}-1/2)/S)$. 

For continuous variables and $S \rightarrow \infty$, the rank normalized values are normally distributed and rank normalization performs non-parametric transformation to normal distribution. Using normalized ranks instead of ranks directly, has the benefit that the behavior of $\widehat{R}$ and $S_{\rm eff}$ do not change for normally distributed $\theta$.

### Examples of rank normalization

We illustrate rank normalization with a few examples. We first define a plotting function.
```{r}
plotranknorm <- function(theta, n, m = 1, interval = NULL) {
    df <- data.frame(theta = theta) %>%
        mutate(gid = gl(m, n),
               r = r_scale(theta),
               u = u_scale(theta),
               z = z_scale(theta))
    blue <- color_scheme_get(scheme ='blue', i = 4)[[1]]
    p2 <- ggplot(df, aes(x=theta, grp=gid)) +
        stat_ecdf(color=blue, alpha=0.5, pad = FALSE) +
        labs(x=TeX('$\\theta$'), y='ECDF')
    p3 <- ggplot(df, aes(x=r/(n*m), grp=gid)) +
        stat_ecdf(color=blue, alpha=0.5, pad = FALSE) +
        labs(x='Scaled rank', y='ECDF')
    if (is.null(interval)) {
      p1 <- mcmc_hist(as.data.frame(theta)) +
         xlab(TeX('$\\theta$'))
      p4 <- ggplot(df, aes(x=z, grp=gid)) +
        stat_ecdf(color=blue, alpha=0.5, pad = FALSE) +
        labs(x='z', y='ECDF')
      grid.arrange(p1, p2, p3, p4, nrow = 1)
    } else {
    	df <- mutate(df,
          psd = sqrt((r+1)*(n-r+1)/(n+2)^2/(n+3)), #sqrt(n*u*(1-u))/n,
          pm2sd = (r+1)/(n+2)-1.96*psd,
          pp2sd = (r+1)/(n+2)+1.96*psd,
          p975 = qbeta(0.975,r+1,n-r+1),
          p025 = qbeta(0.025,r+1,n-r+1))
        p2b <- p2 + geom_linerange(data=df, aes(ymin=p025, ymax=p975), color=blue) +
          ylab('ECDF + beta 95% interval')
        p3b <- p3 + geom_linerange(data=df, aes(ymin=p025, ymax=p975), color=blue) + 
          ylab('ECDF + beta 95% interval')
        p3c <- p3 + geom_linerange(data=df, aes(ymin=pm2sd, ymax=pp2sd), color=blue) +
          ylab('ECDF + normal approximated 95% interval')
        grid.arrange(p2b, p3b, p3c, nrow = 1)
    }
}
```

We first plot histograms, and empirical cumulative distribution functions (ECDF)  with respect to original parameter values ($\theta$), scaled ranks (ranks divided by the max rank), and rank normalized values (z). We used scaled ranks to make the plots look similar for different number of draws.

100 draws from N(0,1):
```{r, message=FALSE}
n<-100
theta <- rnorm(n)
plotranknorm(theta, n)
```

100 draws from exp(1):
```{r, message=FALSE}
theta <- rexp(n)
plotranknorm(theta, n)
```

100 draws from Cauchy(0, 1):
```{r, message=FALSE}
theta <- rcauchy(n)
plotranknorm(theta, n)
```

### Variation in ranks and ECDF

In the above plots, the ECDF with respect to scaled rank and rank normalized $z$-values look all exatly same for all distributions. In *Split*-$\widehat{R}$ and effective sample size computations, we rank all draws jointly, but then compare ranks and ECDF of individual split chains. To illustrate the variation between chains, we draw 8 batches of 100 draws each from N(0,1):
```{r, message=FALSE}
n<-100
m<-8
theta <- rnorm(n*m)
plotranknorm(theta, n, m)
```

The variation in ECDF due to the variation ranks is now visible also in scale ranks and rank normalized z-values from different batches.

The benefit of rank normalization is more obvious for non-normal distribution such as Cauchy:
```{r, message=FALSE}
theta <- rcauchy(n*m)
plotranknorm(theta, n, m)
```

Rank normalization makes the subsequent computations well defined and
invariant under bijective transformations. This means that we get the
same results, for example, if we use unconstrained or constrained
parameterisation in a model. 

## Rank normalized *Split*-$\widehat{R}$

Rank normalized *Split*-$\widehat{R}$ is computed using the equations in [Section *Split*-$\widehat{R}$](#SplitRhat) by replacing parameter values $\theta^{(nm)}$ with rank normalized values $z^{(nm)}$.

## Rank normalized folded *split*-$\widehat{R}$

Both original and rank-normalized *Split*-$\widehat{R}$ can miss if
chains have different scales but the same location. To alleviate this,
we propose to compute rank normalized *folded-split*-$\widehat{R}$
using *folded* split chains by rank normalizing absolute deviations from
median
$$
  {\rm abs}(\theta^{(nm)}-{\rm median}(\theta)).
$$

<!--
Notation for median?
-->

To obtain a single conservative $\widehat{R}$ estimate, we propose to
report the maximum of *rank-normalized-split*-$\widehat{R}$ and
*rank-normalized-folded-split*-$\widehat{R}$ for each parameter.

## Relative efficiency using rank normalized values

In addition of using rank-normalized values for convergence
diagnostics via $\widehat{R}$, we can also compute the corresponding
effective sample size.  This estimate will be well defined even if the
original distribution does not have finite mean and variance. It is
not directly applicable to estimate the Monte Carlo error of the mean
of the original values, but it will provide bijective transformation
invariant estimate of the mixing efficiency of chains. For simplicity
we propose to report relative efficiency values
$$
R_{\rm eff}=\textit{rank-normalized-split-}S_{\rm eff} / S,
$$
where $\textit{split-}S_{\rm eff}$ is computed using equations in
[Section Effective sample size](#Seff) by replacing parameter values
$\theta^{(nm)}$ with rank normalized values $z^{(nm)}$. For $\theta$ which
have close to normal distribution the difference to using the original
values is small. For $\theta$ which has a distribution far from
normal, rank normalization can be seen as near optimal non-parametric
transformation.

We later demonstrate and discuss that this relative efficiency
estimate using means and variances of rank normalized values is a
useful measure for relative efficiency of estimating the bulk (mean
and quantiles near median) of the distribution, and as shorthand term
we use term *bulk relative efficiency* (*bulk*-$R_{\rm eff}$).

We propose to compute the relative efficiency also using *folded*
split chains by rank normalizing absolute deviations from median,
which we we later demonstrate to be a useful measure for relative
efficiency of estimating the tail of the distribution. As a shorthand
term we use a term *tail relative efficiency* (*tail*-$R_{\rm eff}$).

## Relative efficiency of cumulative distribution function

Bulk and tail relative efficiency measures introduced above are useful
as overall efficiency measures. Next we introduce relative efficiency
estimate of cumulative distribution function, and later we use that to
introduce relative efficiency of quantiles and local small probability
interval relative efficiency diagnostic.

The quantiles and posterior intervals are often reported quantities,
which are easy to estimate from posterior draws.  Estimating the
relative efficiency of such quantiles thus has high practical
relevance in particular as we observe the relative efficiency for tail
quantiles is often lower than for mean.  $\alpha$-quantile is
$\theta^*$ for which $p(\theta < \theta^*) = \alpha$. This is not in a
form of expectation, and thus $\widehat{R}$ and $S_{\rm eff}$
equations are not directly applicable. Thus we first focus on
relative efficiency of cumulative distribution function $p(\theta <
\theta^*)$ for different values of $\theta^*$. For easier
visualisation we may also use scaled rank values in place of
$\theta^*$.

For any $\theta^*$ ECDF gives an estimate of cumulative probability
$$
p(\theta<\theta^*) \approx \bar{I} = \frac{1}{S}\sum_{s=1}^S
I(\theta^{(s)}<\theta^*),
$$
where $I()$ is the indicator function. The indicator
function transforms simulation draws to 0's and 1's, and thus the
subsequent computations are bijectively invariant. For independent
draws and $Y=\sum_{s=1}^S I(\theta^{(s)}<\theta^*)$, this estimate has ${\rm
Beta}(Y+1, S - Y + 1)$ distribution. Thus we can easily examine
variation of ECDF for any $\theta^*$ value from a single chain. If $Y$
is not very close to $1$ or $S$ and $S$ is large, we can use the
variance of Beta distribution
$$
{\rm Var}[p(\theta<\theta^*)] = \frac{(Y+1)*(S-Y+1)}{(S+2)^2(S+3)}.
$$

We illustrate uncertainty intervals of Beta distribution and normal approximation of ECDF for 100 draws from N(0,1)
from N(0,1):
```{r, message=FALSE}
n<-100
m<-1
theta <- rnorm(n*m)
plotranknorm(theta, n, m, interval=TRUE)
```

Uncertainty intervals of ECDF for draws from Cauchy(0,1) illustrate again the improved visual clarity in plotting when using scaled ranks:
```{r, message=FALSE}
n<-100
m<-1
theta <- rcauchy(n*m)
plotranknorm(theta, n, m, interval=TRUE)
```

The above plots illustrate that the normal approximation is accurate
for practical purposes in MCMC diagnostics using indicator function
for most purposes. By using
the relative efficiency equations for several split chains and the
indicator function $I(\theta^{(s)}<\theta^*)$, we can compute the relative
efficiency for different values of $\theta^*$.  By computing relative
efficiency for many quantiles, we can obtain local efficiency measures
as demonstrated in the experiments.

## Relative efficiency of quantiles {#quantile_R_eff}

Assuming the cumulative distribution function $F$ is continuous and smooth near
an $\alpha$-quantile and we know $F$, we could use delta method to
compute a variance estimate for $F_\theta^{-1}(\bar{I})$. Although we
don't usually know $F$, delta method approach reveals that the
variance of $\bar{I}$ is scaled by the (usually unknown) density
$f(\theta^*)$, but the relative efficiency depends only on the
relative efficiency of $\bar{I}$. Thus, we can use relative efficiency
of ECDF (via the indicator function $I(\theta^{(s)}<\theta^*)$) also for the
corresponding quantile estimates.

## Relative efficiency of median and MAD

Since the marginal posterior distributions might not have finite mean
and variance, by default RStan [@RStan.2.17] and RStanARM
[@RStanARM.2.17] report median and median absolute deviation (MAD)
instead of mean and standard error (SE). Median and MAD are well
defined even when the marginal distribution does not have finite mean
and variance.

Median is 50%-quantile, and we can estimate the relative efficiency as
for the other quantiles.  Compared to relative efficiency of the mean
rank, this is a more local measure as it only assesses how the Markov
chain jumps around the median.

We can also compute the relative efficiency for the
median absolute deviation (MAD), by computing the relative efficiency
for median of absolute deviations from the median of all draws. The
absolute deviations from the median of all draws are same as
previously defined for folded samples
$$
{\rm abs}(\theta^{(nm)}-{\rm median}(\theta)).
$$
We see that the relative efficiency of MAD is obtained by using the
same approach as for median (and other quantiles) but with the folded
values used also used in
*rank-normalized-folded-split*-$S_{\rm eff}$.

Previously, Stan had reported $S_{\rm eff}$ only for the posterior
mean, but we demonstrate that it is good to report the relative
efficiency also for the posterior scale.

## Monte Carlo error estimates for quantiles

Previously, Stan has reported Monte Carlo standard error estimates for
mean of a quantity. This is valid only if the corresponding
distribution has finite mean and variance. It would be possible to
estimate when mean and variance are finite, but easier option is focus
on median and other quantiles.

Median, MAD and quantiles are well defined even when the distribution
does not have finite mean and variance, and they are asymptotically
normally distributed for distributions which are continuous and
non-zero in the relevant neighborhood. As the delta method of
computing the variance would require knowledge of the normalized
posterior density, we propose to use following approach.

1. Sample draws from ${\rm Beta}((R_{\rm eff} Y)+1, R_{\rm eff}(S - Y)
+ 1)$ distribution or compute desired quantiles of that
distribution. Including $R_{\rm eff}$ takes into account the relative
efficiency of MCMC.
2. Find posterior draws with closest corresponding ranks. For example,
in case of quantiles $\alpha_1$ and $\alpha_2$, find $r_1$ and $r_2$
which are closest to $\alpha_1 S$ and $\alpha_2 S$.
3. Use the corresponding $\theta^{(s)}$ as draws from Monte Carlo
error distribution, report desired quantiles or, use draws or
quantiles to compute approximate standard error.

## Relative efficiency of small interval probability estimates {#small_interval_R_eff}

We can get more local relative efficiency estimate by considering
small probability intervals. We propose to compute the relative
efficiency for
$$
\bar{I} = p(\hat{Q}_\alpha \le \theta < \hat{Q}_{\alpha+\delta}),
$$
where $\hat{Q}_\alpha$ is an empirical $\alpha$-quantile, $\delta=1/k$
is the length of the interval with some positive integer $k$, and
$\alpha \in (0,\delta,\ldots,1-\delta)$ changes in steps of $\delta$.
Each interval has $S/k$ draws, and the efficiency measures
autocorrelation of an indicator function which is one when the values
are inside the specific interval and zero otherwise. This gives us a
local efficiency measure which does not depend on the shape of the
distribution. We demonstrate its usefulness as a diagnostic and
educational tool to teach why expectations of different functionals
may have different $S_{\rm eff}$.

## Local efficiency for distributional approximations

We note that we can plot similar local relative efficiency plots also
for distributional approximations (like Laplace and ADVI
[@Kucukelbir+etal:ADVI:2017] approximations), using Pareto smoothed
importance sampling based effective sample size estimates
[@Vehtari+etal:PSIS:2017]. There will be another case study for this.

## Rank plots

In addition to using rank-normalized values to compute
*split*-$\widehat{R}$, we propose to use rank plots for each chain
instead of trace plots. Rank plots are nothing else than histograms of the 
ranked posterior samples (ranked over all chains) plotted separately
for each chain. If rank plots of all chains look similar, this indicates
good mixing of the chains. As compared to trace plots, they don't tend
to squeeze to a mess in case of long chains. Within this case study,
we will illustrate the use and interpretation of rank plots.

## Abbreviations

In the code and figures the following abbreviations have been used

 - Rhat = classic no-split-Rhat
 - sRhat = classic split-Rhat
 - zsRhat = rank-normalized split-Rhat
    + all chains are jointly ranked and z-transformed
    + can detect differences in location and trends
 - zfsRhat = rank-normalized folded split-Rhat
    + all chains are jointly "folded" by computing absolute deviation
      from median, ranked and z-transformed
    + can detect differences in scales
 - neff = no-split effective sample size
 - reff = neff / N
 - zsneff = rank-normalized split effective sample size
    + estimates the efficiency of mean estimate for rank normalized values
 - zsreff = zsneff / N
 - zfsneff = rank-normalized folded split effective sample size
    + estimates the efficiency of rank normalized *mean* absolute deviation
 - zfsreff = zfsneff / N
 - medsneff = median split effective sample size
    + estimates the efficiency of median
    + approximated using efficiency for $p(\theta < \hat{Q}_{0.5})$
 - medsreff = medsneff / N
 - madsneff = mad split effective sample size
    + estimates the efficiency of median absolute deviation
 - madsreff = madsneff / N

## Proposed changes in Stan

The proposal is to switch in Stan

 - from split-$\widehat{R}$ (sRhat) to the maximum of 
 rank-normalized-split-$\widehat{R}$ and 
 rank-normalized-folded-split-$\widehat{R}$: max(zsRhat, zfsRhat)
 - from classic effective sample size estimate (neff), 
 which currently doesn't use chain splitting, to 
 rank-normalized-split-$R_{\rm eff}$ (zsreff) and 
 rank-normalized-folded-split-$R_{\rm eff}$ (zfsreff)
 - if computing median and MAD_SD, report corresponding 
 $R_{\rm eff}$'s (medsreff and madsreff)

Justifications for the change are:

- Rank normalization makes zsRhat and zsreff well defined for all
  distributions, under bijective transformations invariant and more
  stable than sRhat and neff. Adding a folded versions zfsRhat and
  zfsreff helps to detect differences in scale.
- Relative efficiencies of the median and MAD (medsreff and masreff) are
  well defined for all distributions, bijective transformation invariant, 
  more stable than neff, and focus on the quantities we are actually 
  reporting.

In summary outputs, we propose to eventually use `Rhat` to denote the new
version. However, to make it more clear that rank-normalized efficiency 
is different than standard efficiency, we could use the term `R_eff` and 
display relative efficiency. The relative efficiency is also easier to 
check for low values as we don't need to compare it to the total number 
of draws.

## Warning thresholds

Based on the experiments presented below, more strict convergence 
diagnostics and relative efficiency warning limits could be used.

We propose the following warning thresholds, although additional
experiments would be useful:

 - 1.01 or 1.02 for new Rhat max(zsRhat, zfsRhat)
 - 0.1 for new relative efficiency (zsreff, zfsreff, medsreff, madsreff)

Plots shown in the upcoming section have dashed lines based on these 
thresholds (in continuous plots, a dashed line at 1.005 is plotted instead 
of 1.01, as values larger than that are usually rounded in our summaries to 1.01).

## Proposed additions to bayesplot

The proposal is to add to `bayesplot` package the following

- Rank plot
- Relative efficiency of quantiles plot
- Relative efficiency of small probability interval plot

# Experiments

We demonstrate the proposed approached with several simulation studies.

## Independent draws from normal distribution with additional trend, shift or scaling

This part focuses on diagnostics for

 - all chains have a trend and similar marginal distribution
 - one of the chains has different mean
 - one of the chains has lower marginal variance
 
To simplify, in this part independent draws are used as a proxy for
very efficient MCMC and we sample draws from a standard-normal
distribution. We will discuss the behavior for non-Gaussian
distributions later.

### Trend: All chains from the same $N(0,1)$ distribution plus linear trend added to all chains.

```{r}
conds <- expand.grid(
  iters = c(250, 1000, 4000), 
  trend = c(0, 0.25, 0.5, 0.75, 1),
  rep = 1:10
)
res <- vector("list", nrow(conds))
chains = 4
for (i in 1:nrow(conds)) {
  iters <- conds[i, "iters"]
  trend <- conds[i, "trend"]
  rep <- conds[i, "rep"]
  r <- array(rnorm(iters * chains), c(iters, chains))
  r <- r + seq(-trend, trend, length.out = iters)
  rs <- monitor_simple(r)
  res[[i]] <- cbind(iters, trend, rep, rs)
}
res <- bind_rows(res)
```

If we don't split chains, Rhat misses the trends if all chains still have
similar marginal distribution.
```{r}
ggplot(data=res, aes(y=Rhat, x=trend)) + 
  geom_point() + 
  geom_jitter() + 
  facet_grid(. ~ iters) + 
  geom_hline(yintercept = 1.005, linetype = 'dashed') + 
  geom_hline(yintercept = 1) + 
  ggtitle('Rhat without splitting chains')
```

Split-Rhat can detect trends, even if the marginals of the chains are similar.
```{r}
ggplot(data=res, aes(y=zsRhat, x=trend)) + 
  geom_point() + geom_jitter() + 
  facet_grid(. ~ iters) + 
  geom_hline(yintercept = 1.005, linetype = 'dashed') + 
  geom_hline(yintercept = 1) + 
  ggtitle('Split-Rhat')
```

**Result:** Split-Rhat is useful for detecting non-stationarity in
 the chains. If we use a threshold of $1.01$, we can detect trends which have
 account for 2% of the total marginal variance. If we use a threshold of $1.1$, we
 can detect trends which account for 30% of the total marginal variance.

Relative efficiency (effective sample size divided by the number of
draws) is based on split Rhat and within-chain autocorrelation.

```{r}
ggplot(data=res, aes(y=zsreff, x=trend)) + 
  geom_point() + 
  geom_jitter() + 
  facet_grid(. ~ iters) + 
  geom_hline(yintercept = c(0,1)) + 
  geom_hline(yintercept = 0.1, linetype = 'dashed') + 
  ggtitle('Relative efficiency (zsreff)') + 
  scale_y_continuous(breaks = seq(0,1,by=0.25))
```

**Result:** Split-Rhat is more sensitive to trends in small sample
 sizes, but relative efficiency is more sensitive with larger samples
 sizes (as autocorrelations can be estimated more accurately).

**Advice:** If in doubt, run longer chains for more accurate estimates.

### Shifted: Three chains from $N(0,1)$ and one chain from $N(a,1)$

Next we investigate the sensitivity to detect if one of the chains has
not converged to the same distribution as the others, but has a different mean.

```{r}
conds <- expand.grid(
  iters = c(250, 1000, 4000), 
  shift = c(0, 0.25, 0.5, 0.75, 1),
  rep = 1:10
)
res <- vector("list", nrow(conds))
chains = 4
for (i in 1:nrow(conds)) {
  iters <- conds[i, "iters"]
  shift <- conds[i, "shift"]
  rep <- conds[i, "rep"]
  r <- array(rnorm(iters * chains), c(iters, chains))
  r[, 1] <- r[, 1] + shift
  rs <- monitor_simple(r)
  res[[i]] <- cbind(iters, shift, rep, rs)
}
res <- bind_rows(res)
```

```{r}
ggplot(data=res, aes(y=zsRhat, x=shift)) + 
  geom_point() + 
  geom_jitter() + 
  facet_grid(. ~ iters) + 
  geom_hline(yintercept = 1.005, linetype = 'dashed') + 
  geom_hline(yintercept = 1) + 
  ggtitle('Split-Rhat')
```

**Result:** If we use a threshold of $1.01$, we can detect shift with
  a magnitude of one third of the marginal standard deviation. If we use
  a threshold of $1.1$, we can detect shift with a magnitude equal to
  the marginal standard deviation. The rank plot can be used to visualize
  where the problem is.

```{r}
ggplot(data=res, aes(y=zsreff, x=shift)) + 
  geom_point() +
  geom_jitter() + 
  facet_grid(. ~ iters) + 
  geom_hline(yintercept = c(0,1)) + 
  geom_hline(yintercept = 0.1, linetype = 'dashed') + 
  ggtitle('Relative efficiency (zsreff)') + 
  scale_y_continuous(breaks = seq(0,1,by=0.25))
```

**Result:** The relative efficiency is not as sensitive, but a shift
with a magnitude of half the marginal standard deviation will lead to
very low efficiency when sample size increases.

Rank plot visualisation for a case with 4 chains and 250 draws per
chain, and shift = 0.5.
```{r}
iters = 250
chains = 4
shift = 0.5
r <- array(rnorm(iters * chains), c(iters, chains))
r[,1] <- r[,1] + shift
colnames(r) <- 1:4
```

```{r mcmc_hist_r_scale}
mcmc_hist_r_scale <- function(x, nbreaks = 50) {
  max <- prod(dim(x)[1:2])
  mcmc_hist(
    r_scale(x), 
    breaks = seq(0, max, by = max / nbreaks) + 0.5
  )
}
```
<!--
add guidelines for uniformity as in
https://betanalpha.github.io/assets/case_studies/principled_bayesian_workflow.html
-->


```{r}
mcmc_hist_r_scale(r)
```

Rhat is less than $1.05$, but the rank plot clearly shows the location of the problem (first chain).

### Scaled: Three chains from $N(0,1)$ and one chain from $N(0,a)$

Next we investigate the sensitivity to detect if one of the chains has
not converged to the same distribution as the others but has lower
marginal variance.

```{r, cache=FALSE}
conds <- expand.grid(
  iters = c(250, 1000, 4000), 
  scale = c(0, 0.25, 0.5, 0.75, 1),
  rep = 1:10
)
res <- vector("list", nrow(conds))
chains = 4
for (i in 1:nrow(conds)) {
  iters <- conds[i, "iters"]
  scale <- conds[i, "scale"]
  rep <- conds[i, "rep"]
  r <- array(rnorm(iters * chains), c(iters, chains))
  r[, 1] <- r[, 1] * scale
  rs <- monitor_simple(r)
  res[[i]] <- cbind(iters, scale, rep, rs)
}
res <- bind_rows(res)
```

```{r}
ggplot(data=res, aes(y=zsRhat, x=scale)) + 
  geom_point() + 
  geom_jitter() + 
  facet_grid(. ~ iters) + 
  geom_hline(yintercept = 1.005, linetype = 'dashed') + 
  geom_hline(yintercept = 1) + 
  ggtitle('Split-Rhat')
```

**Result:** Split-Rhat is not able to detect scale differences between chains.

```{r}
ggplot(data=res, aes(y=zfsRhat, x=scale)) + 
  geom_point() + 
  geom_jitter() + 
  facet_grid(. ~ iters) + 
  geom_hline(yintercept = 1.005, linetype = 'dashed') + 
  geom_hline(yintercept = 1) + 
  ggtitle('Folded-split-Rhat')
```

**Result:** Folded-Split-Rhat focuses explicitly on scales 
and can thus detect scale differences.

**Result:** If we use a threshold of $1.01$, we can detect a chain with scale
  less than $3/4$ of the standard deviation of the others. If we use threshold 
  of $1.1$, we can detect a chain with standard deviation less than $1/4$ of 
  the standard deviation of the others.

```{r}
ggplot(data=res, aes(y=zsreff, x=scale)) + 
  geom_point() + 
  geom_jitter() + 
  facet_grid(. ~ iters) + 
  geom_hline(yintercept = c(0,1)) + 
  geom_hline(yintercept = 0.1, linetype = 'dashed') + 
  ggtitle('Relative efficiency (zsreff)') + 
  scale_y_continuous(breaks = seq(0,1,by=0.25))
```

**Result:** The relative efficiency does not see a problem as it
focuses on location differences between chains.

```{r}
ggplot(data=res, aes(y=zfsreff, x=scale)) + 
  geom_point() + 
  geom_jitter() + 
  facet_grid(. ~ iters) + 
  geom_hline(yintercept = c(0,1)) + 
  geom_hline(yintercept = 0.1, linetype = 'dashed') + 
  ggtitle('Folded relative efficiency (zfsreff)') + 
  scale_y_continuous(breaks = seq(0,1,by=0.25))
```

**Result:** The relative efficiency of the standard deviation 
does see the problem as it focuses on scale.

Rank plot visualisation for a case with 4 chains and 250 draws per
chain, and with one chain having a standard deviation of 0.75 as opposed
to a standard deviation of 1 for the other chains.

```{r}
iters = 250
chains = 4
scale = 0.75
r <- array(rnorm(iters * chains), c(iters, chains))
r[, 1] <- r[, 1] * scale
colnames(r) <- 1:4
mcmc_hist_r_scale(r)
```

Folded Rhat is $1.06$, but the rank plot clearly shows where the problem is.

## Cauchy: A distribution with infinite mean and variance

The classic split-Rhat is based on calculating within and between chain
variances. If the marginal distribution of a chain is such that
the variance is not defined (i.e. infinite), the classic split-Rhat is not 
well justified. In this section, we will use the Cauchy distribution 
as an example of such distribution. Also in cases where
mean and variance are finite, the distribution can be far from
Gaussian. Especially distributions with very long tails cause
instability for variance and autocorrelation estimates. To alleviate
these problems we will use Split-Rhat for rank-normalized draws. 

The following Cauchy models are from Michael Betancourt's case study
[Fitting The Cauchy Distribution](https://betanalpha.github.io/assets/case_studies/fitting_the_cauchy.html)

### Nominal parameterization of Cauchy

The nominal Cauchy model with direct parameterization is as follows.

```{r}
writeLines(readLines("cauchy_nom.stan"))
```

#### Default Stan options

Run the nominal model:
```{r fit_nom, cache=TRUE, comment=NA, results='hide'}
fit_nom <- stan(file='cauchy_nom.stan', seed=7878, refresh = 0)
```

Treedepth exceedence and Bayesian Fraction of Missing Information are
dynamic HMC specific diagnostics [@betancourt2017conceptual]. We get
warnings about very large number of transitions after
warmup that exceeded the maximum treedepth, which is likely due to
very long tails of the Cauchy distribution. All chains have low 
estimated Bayesian fraction of missing information also indicating
slow mixing.

MCMC trace for the first parameter looks wild with occasional large values
```{r}
samp <- as.array(fit_nom) 
mcmc_trace(samp[, , 1])
```

Let's check Rhat and relative efficiency diagnostics.

```{r}
res <- monitor_simple(samp[, , 1:50])
which_min_eff <- which(res$zsreff == min(res$zsreff))
```

```{r}
plot_rhat(res)
```

For one parameter, Rhats exceed the classic threshold of 1.1. Depending on the 
Rhat estimate, a few others also exceed the threshold 1.01. The rank normalized
split-Rhat have several values over 1.01. Please note that the classic
split-Rhat is not well defined in this example.

```{r, warning=FALSE}
plot_reff(res) 
```

Both classic and new relative efficiency estimates have
several near zero values, and the overall sample shouldn't be trusted.

**Result:** Relative efficiency is more sensitive than (rank-normalized) 
split-Rhat to detect problems of slow mixing.

We also check `lp__` and find out that
the relative efficiency is worryingly low.

```{r}
res <- monitor_simple(samp[, , 51:52]) 
cat('lp__: Bulk-R_eff = ', round(res['lp__','zsreff'], 2), '\n')
cat('lp__: Tail-R_eff = ', round(res['lp__','zfsreff'], 2), '\n')
```

We can further analyze potential problems using local relative
efficiency and rank plots.  We examine x[`r which_min_eff`], which has
the smallest bulk relative efficiency `r round(min(res$zsreff), 2)`.

We examine the relative efficiency in different parts of the
posterior by computing the relative efficiency of small interval
probability estimates (see [Section Relative efficiency of small
interval probability estimates](#small_interval_R_eff)).  Each
interval contains $1/k$ of the draws (e.g., with $k=20$).
The small interval efficiency measures mixing of an indicator
function which indicates when the values are inside the specific
small interval.  This gives us a local efficiency measure which does not
depend on the shape of the distribution.

```{r}
plot_local_reff(fit = fit_nom, par = which_min_eff, nalpha = 20)
```

We see that the efficiency of MCMC is worryingly low in the tails
(which is caused by slow mixing in long tails of Cauchy). Orange ticks
show chains with maximum treedepth.

Alternative way to examine the relative efficiency in different parts
of the posterior, is to compute relative efficiency for quantiles (see
[Section Relative efficiency of quantiles](#quantile_R_eff)). Each
interval has specified proportion of draws, and the efficiency measures
mixing of an indicator function which indicates when the
values are inside the specific interval. 

```{r, cahce=FALSE}
plot_quantile_reff(fit = fit_nom, par = which_min_eff, nalpha = 40)
```

We see that the efficiency of MCMC is worryingly low in the tails
(which is caused by slow mixing in long tails of Cauchy). Orange ticks
show chains with maximum treedepth.

We can further analyze potential problems using rank plots.

```{r}
xmin <- paste0("x[", which_min_eff, "]")
mcmc_hist_r_scale(samp[, , xmin])
```

The chains clearly have different rank plots.


#### Default Stan options + `max_treedepth=20`

We can try to improve the performance by increasing `max_treedepth`.

```{r fit_nom_td20, cache=TRUE, comment=NA, results='hide'}
fit_nom_td20 <- stan(
  file='cauchy_nom.stan', seed=7878, 
  refresh = 0, control = list(max_treedepth=20)
)
```

MCMC trace for the first parameter looks wild with occasional large values.
```{r}
samp <- as.array(fit_nom_td20)
mcmc_trace(samp[, , 1])
```

```{r}
res <- monitor_simple(samp[, , 1:50])
which_min_eff <- which(res$zsreff == min(res$zsreff))
```

We check the diagnostics for all x's.

```{r}
plot_rhat(res)
```

All Rhats are below $1.1$, but many are over $1.01$. Classic split-Rhat has more
variation than the rank normalized (and the former is not well
defined). The folded rank normalized Rhat shows that there is still
more variation in scale than location between different chains.

```{r, warning=FALSE}
plot_reff(res) 
```

Some classic R_eff's are close to zero. If we
wouldn't realize that the variance is infinite, we might try to run
longer chains, but in case of infinite variance, zero efficiency is
the truth and longer chains won't help. However other quantities can
be well defined, and that's why it is useful also to look at the
rank normalized version as a generic transformation with finite mean
and variance. The smallest bulk-$R_{\rm eff}$ are around $0.25$,
which is not that bad. The smallest median-$R_{\rm eff}$'s are larger
than $0.5$, that is we are able to estimate the median
efficiently. However, many tail-$R_{\rm eff}$'s are small indicating
problmes for estimating scale.		

**Result:** Rank normalized relative efficiency is more stable than
classic relative efficiency, which is not well defined for Cauchy.

**Result:** it is useful to look at both bulk and tail relative efficiencies.

We check also `lp__`. Although increasing `max_treedepth` improved
efficiency for bulk of `x`, the efficiency for `lp__` didn't change.

```{r}
res <- monitor_simple(samp[, , 51:52])
cat('lp__: Bulk-R_eff = ', round(res['lp__','zsreff'],2), '\n')
cat('lp__: Tail-R_eff = ', round(res['lp__','zfsreff'],2), '\n')
```

We examine the relative efficiency in different parts of the
posterior by computing the relative efficiency of small interval
probability estimates.

```{r}
plot_local_reff(fit = fit_nom_td20, par = which_min_eff, nalpha = 20)
```

It seems that increasing `max_treedepth` has not much improved the efficiency in the tails.

We examine also the relative efficiency of different quantile estimates.

```{r}
plot_quantile_reff(fit = fit_nom_td20, par = which_min_eff, nalpha = 40)
```

Rank plot visualisation of x[`r which_min_eff`], which has the smallest relative
efficiency `r round(min(res$zsreff))` among the x's. The rank plot indicates clear convergence problems.

```{r}
xmin <- paste0("x[", which_min_eff, "]")
mcmc_hist_r_scale(samp[, , xmin])
```

The rank plot visualisation of `lp__`, which has relative efficiency `r round(monitor_simple(samp[,, "lp__"])$zsreff)`, doesn't look so good either.

```{r}
mcmc_hist_r_scale(samp[, , "lp__"])
```

#### Default Stan options + `max_treedepth = 20` + 8 times longer sampling

Let's try running longer chains.
```{r fit_nom_td20l, cache=TRUE, comment=NA, results='hide'}
fit_nom_td20l <- stan(
  file='cauchy_nom.stan', seed=7878, 
  refresh = 0, control = list(max_treedepth=20), 
  warmup=1000, iter = 9000
)
```

MCMC trace for the first parameter looks wild with occasional large values
```{r}
samp <- as.array(fit_nom_td20l)
mcmc_trace(samp[, , 1])
```

```{r}
res <- monitor_simple(samp[, , 1:50])
which_min_eff <- which(res$zsreff == min(res$zsreff))
```

Check the diagnostics for all x's.

```{r}
plot_rhat(res)
```

All Rhats are below $1.01$. Classic split-Rhat has more variation than the
rank normalized Rhat (but the former is not well defined).

```{r, warning=FALSE}
plot_reff(res) 
```

Most classic R_eff's are close to zero. Running longer chains just made most classic R_eff's smaller.

The smallest bulk-$R_{\rm eff}$ are around $0.25$, which is not that
bad. The smallest median-$R_{\rm eff}$'s are larger than $0.75$, that
is we are able to estimate the median efficiently. However, many
tail-$R_{\rm eff}$'s are small indicating problmes for estimating
scale.

**Result:** Rank normalized relative efficiency is more stable than
classic relative efficiency, which is not well defined for Cauchy.

**Result:** it is useful to look at both bulk and tail relative efficiencies.

We check also `lp__`. Although increasing the number of iterations improved
efficiency for bulk of `x`, the efficiency for `lp__` didn't change.

```{r}
res <- monitor_simple(samp[, , 51:52])
cat('lp__: Bulk-R_eff = ', round(res['lp__','zsreff'],2), '\n')
cat('lp__: Tail-R_eff = ', round(res['lp__','zfsreff'],2), '\n')
```

We examine the relative efficiency in different parts of the
posterior by computing the relative efficiency of small interval
probability estimates.

```{r}
plot_local_reff(fit = fit_nom_td20l, par = which_min_eff, nalpha = 20)
```

Increasing chain length did not seem to change the relative
efficiency. With more draws from the longer chains we can use
finer resolution for the local efficiency estimates.

```{r}
plot_local_reff(fit = fit_nom_td20l, par = which_min_eff, nalpha = 100)
```

The efficiency far in the tails is worryingly low. This was more
difficult to see previously with less draws from the tails. We see
similar problems in the plot of relative efficiency of quantiles.

```{r}
plot_quantile_reff(fit = fit_nom_td20l, par = which_min_eff, nalpha = 100)
```

The rank plot visualisation of x[`r which_min_eff`], which has the smallest relative efficiency `r round(min(res$zsreff), 2)` among the x's.
```{r}
xmin <- paste0("x[", which_min_eff, "]")
mcmc_hist_r_scale(samp[, , xmin])
```

Increasing the number of iterations couldn't remove the mixing
problems at the edges. The mixing problem is inherent to Cauchy and
nominal parameterization.

The rank plot visualisation of `lp__`, which has relative efficiency 
`r round(res["lp__", "zsreff"], 2)`, looks as follows:
```{r}
mcmc_hist_r_scale(samp[, , "lp__"])
```

There seems to be slight problems also in mixing for energy.

<!--
From the above plot, I would naively don't see any problems in mixing.
Or am I just misinterpreting the plot?
-->

### First alternative parameterization of Cauchy

Next we examine alternative parameterization and consider Cauchy as a
scale mixture of Gaussian distributions. The model has two parameters
and the Cauchy distributed x's can be computed from those. In addition
of improved sampling performance, the example illustrates that focus
of diagnostics matter.

```{r}
writeLines(readLines("cauchy_alt_1.stan"))
```

Run the alternative model:

```{r fit_alt1, cache=TRUE, comment=NA, results='hide'}
fit_alt1 <- stan(file='cauchy_alt_1.stan', seed=7878, refresh = 0)
```

There are no warnings, and the sampling is much faster.

```{r}
samp <- as.array(fit_alt1)
res <- monitor_simple(samp[, , 101:150])
which_min_eff <- which(res$zsreff == min(res$zsreff))
```

```{r}
plot_rhat(res)
```

All Rhats are below 1.01. Classic split-Rhat's look also good even if the
classic is not well defined for Cauchy distribution.

```{r, warning=FALSE}
plot_reff(res) 
```

**Result:** Rank normalized R_eff's have less variation than classic 
one which is not well defined for Cauchy.

We check `lp__`:
```{r}
res <- monitor_simple(samp[, , 151:152])
cat('lp__: Bulk-R_eff = ', round(res['lp__','zsreff'],2), '\n')
cat('lp__: Tail-R_eff = ', round(res['lp__','zfsreff'],2), '\n')
```

The relative efficiencies for `lp__` are also much better than with
nominal parameterization.

We examine the relative efficiency in different parts of the
posterior by computing the relative efficiency of small interval
probability estimates.

```{r}
plot_local_reff(fit = fit_alt1, par = 100+which_min_eff, nalpha = 20)
```

The relative efficiency is good in all parts of the posterior.

We examine also the relative efficiency of different quantile estimates.

```{r}
plot_quantile_reff(fit = fit_alt1, par = 100+which_min_eff, nalpha = 40)
```

We compare mean relative efficiencies of underlying parameters in the new
parameterization and the actual x we are interested in.

```{r, cahce=FALSE}
res <- monitor_simple(samp[, , 101:150])
res1 <- monitor_simple(samp[, , 1:50])
res2 <- monitor_simple(samp[, , 51:100])
```

```{r}
cat('Mean bulk-R_eff for x\'s = ' , round(mean(res[,'zsreff']), 2), '\n')
cat('Mean tail-R_eff for x\'s = ' , round(mean(res[,'zfsreff']), 2), '\n')
cat('Mean bulk-R_eff for x_a\'s = ' , round(mean(res1[,'zsreff']), 2), '\n')
cat('Mean bulk-R_eff for x_b\'s = ' , round(mean(res2[,'zsreff']), 2), '\n')
```

**Result:** We see that the relative efficiency of the interesting $x$
can be different from the relative efficiency of the parameters $x_a$
and $x_b$ that we use to compute it.

Rank plot visualisation of x[`r which_min_eff`], which has the smallest relative
efficiency `r round(min(res$zsreff), 2)` among x's.

```{r}
xmin <- paste0("x[", which_min_eff, "]")
mcmc_hist_r_scale(samp[, , xmin])
```

Looks better than for the nominal parameterization.

Rank plot visualisation of `lp__`, which has a relative efficiency of `r round(monitor_simple(samp[,, "lp__"]), 2)`.
```{r}
mcmc_hist_r_scale(samp[, , "lp__"])
```

Looks better than for the nominal parameterization. 

### Another alternative parameterization of the Cauchy distribution

Another alternative parameterization is univariate transformation as
shown in the following code (3rd alternative in Michael Betancourt's case study).

```{r}
writeLines(readLines("cauchy_alt_3.stan"))
```

Run the alternative model:
```{r fit_alt2, cache=TRUE, comment=NA, results='hide'}
fit_alt3 <- stan(file='cauchy_alt_3.stan', seed=7878, refresh = 0)
```

There are no warnings, and the sampling is much faster than for the
nominal model.

```{r}
samp <- as.array(fit_alt3)
res <- monitor_simple(samp[, , 51:100])
which_min_eff <- which(res$zsreff == min(res$zsreff))
```

```{r}
plot_rhat(res)
```

All Rhats except some folded Rhats are below 1.01. Classic split-Rhat's look
also good even if it is not well defined for the Cauchy distribution.

```{r, warning=FALSE}
plot_reff(res) 
```

**Result:** Rank normalized relative efficiencies have less variation
than classic ones which is not well defined for Cauchy. 
Bulk-$R_{\rm eff}$ and median-$R_{\rm eff}$ are slightly larger than 1, 
which is possible for antithetic Markov chains which have negative 
correlation for odd lags.

We check `lp__`:
```{r}
res <- monitor_simple(samp[, , 101:102])
cat('lp__: Bulk-R_eff = ', round(res['lp__','zsreff'],2), '\n')
cat('lp__: Tail-R_eff = ', round(res['lp__','zfsreff'],2), '\n')
```

The relative efficiency for these are also much better than with
the nominal parameterization.

We examine the relative efficiency in different parts of the
posterior by computing the relative efficiency of small interval
probability estimates.

```{r}
plot_local_reff(fit = fit_alt3, par = 50+which_min_eff, nalpha = 20)
```

We examine also the relative efficiency of different quantile estimates.

```{r}
plot_quantile_reff(fit = fit_alt3, par = 50+which_min_eff, nalpha = 40)
```

The relative efficiency in tails is worse than for the first
alternative parameterization, although it's still better than for the
nominal model.

We compare mean relative efficiency of underlying parameter in the new
parameterization and the actual x we are interested in.

```{r}
res <- monitor_simple(samp[, , 51:100])
res1 <- monitor_simple(samp[, , 1:50])
cat('Mean bulk-R_eff for x\'s = ' , round(mean(res[,'zsreff']),2), '\n')
cat('Mean tail-R_eff for x\'s = ' , round(mean(res[,'zfsreff']),2), '\n')
cat('Mean bulk-R_eff for x_tilde\'s = ' , round(mean(res1[,'zsreff']),2), '\n')
```

**Result:** When the transformation is univariate and bijective (`x =
tan(pi() * (x_tilde - 0.5))`), the rank normalized Rhat and R_eff are
transformation invariant.

Naturally when computing the desired expectations, the final target
function should be taken into account.

Rank plot visualisation of x[`r which_min_eff`], which has the smallest relative
efficiency of `r round( min(res$zsreff), 2)` among x's.

```{r}
xmin <- paste0("x[", which_min_eff, "]")
mcmc_hist_r_scale(samp[, , xmin])
```

Nothing special.

Rank plot visualisation of `lp__`, which has relative efficiency 0.33.
```{r}
mcmc_hist_r_scale(samp[, , "lp__"])
```

Nothing special.

### Half-Cauchy with nominal parameterization

Half-Cauchy priors are common and, for example, in Stan usually set
using the nominal parameterization. However, when the constraint 
`<lower=0>` is used, Stan does the sampling automatically
in the unconstrained `log(x)` space, which changes the geometry
crucially.

```{r}
writeLines(readLines("half_cauchy_nom.stan"))
```

Run the half-Cauchy with nominal parameterization (and positive constraint).

```{r fit_half_nom, cache=TRUE, comment=NA, results='hide'}
fit_half_nom <- stan(file='half_cauchy_nom.stan', seed=7878, refresh = 0)
```

There are no warnings, and the sampling is much faster than for the
Cauchy nominal model.

```{r}
samp <- as.array(fit_half_nom)
res <- monitor_simple(samp[, , 1:50])
which_min_eff <- which(res$zsreff == min(res$zsreff))
```

```{r}
plot_rhat(res) 
```

All Rhats are below 1.01. Classic split-Rhat's look also good even if the
classic is not well defined for half-Cauchy distribution.

```{r, warning=FALSE}
plot_reff(res)  
```

**Result:** Rank normalized R_eff's have less variation than classic
one which is not well defined for Cauchy.
Bulk-$R_{\rm eff}$ and median-$R_{\rm eff}$ are larger than 1, 
which is possible for antithetic Markov chains which have negative 
correlation for odd lags.

Due to constraint `<lower=0>`, the sampling was made in `log(x)` space,
and we can also check the performance in that space.
```{r, cache=FALSE}
res <- monitor_simple(log(samp[, , 1:50]))
```

```{r, warning=FALSE, cache=FALSE}
plot_reff(res) 
```

$\log(x)$ is quite close to Gaussian, and thus classic R_eff is also
close to rank normalized R_eff which is exactly same as for $x$ as the
rank normalized version is invariant to bijective transformations.

**Result:** Rank normalized relative efficiency is close to classic 
relative efficiency for transformations which make the distribution 
close to Gaussian.

We check `lp__`:
```{r}
res <- monitor_simple(samp[, , 51:52])
cat('lp__: Bulk-R_eff = ', round(res['lp__','zsreff'],2), '\n')
cat('lp__: Tail-R_eff = ', round(res['lp__','zfsreff'],2), '\n')
```

We examine the relative efficiency in different parts of the
posterior by computing the relative efficiency of small interval
probability estimates.

```{r}
plot_local_reff(fit = fit_half_nom, par = which_min_eff, nalpha = 20)
```

The relative efficiency is good overall, with only a small dip in tails.

We examine also the relative efficiency of different quantile estimates.

```{r}
plot_quantile_reff(fit = fit_half_nom, par = which_min_eff, nalpha = 40)
```

Rank plot visualisation of x[`r which_min_eff`], which has the smallest relative
efficiency of `r round( min(res$zsreff), 2)` among x's.
```{r}
xmin <- paste0("x[", which_min_eff, "]")
mcmc_hist_r_scale(samp[, , xmin])
```

Nothing special.

Rank plot visualisation of `lp__`, which has relative efficiency 0.33.
```{r}
mcmc_hist_r_scale(samp[, , "lp__"])
```

Maybe small differences in scales, but it's difficult to know whether
small variation from uniform is relevant.

### Alternative parameterization of half-Cauchy

```{r}
writeLines(readLines("half_cauchy_alt.stan"))
```

Run half-Cauchy with alternative parameterization
```{r fit_half_reparam, cache=TRUE, comment=NA, results='hide'}
fit_half_reparam <- stan(file = 'half_cauchy_alt.stan', seed=7878, refresh = 0)
```

There are no warnings, and the sampling is as fast for the half-Cauchy
nominal model.

```{r}
samp <- as.array(fit_half_reparam)
res <- monitor_simple(samp[, , 101:150])
which_min_eff <- which(res$zsreff == min(res$zsreff))
```

```{r}
plot_rhat(res)
```

All Rhats are below 1.01. Classic split-Rhat's look also good even if the
classic is not well defined for half-Cauchy distribution.

```{r, warning=FALSE}
plot_reff(res) 
```

**Result:** Rank normalized relative efficiencies have less variation
than classic ones which is not well defined for Cauchy.  Based on
bulk-$R_{\rm eff}$ and median-$R_{\rm eff}$ the efficency for central
quantities is much lower, but based on tail- $R_{\rm eff}$ and
MAD-$R_{\rm eff}$ the efficency in tails is slightly better. We
also see that parameterization which is good for Cauchy is not
necessary good for half-Cauchy as constraint `<lower=0>` adds
additional change in the parameterization.

We check `lp__`:
```{r}
res <- monitor_simple(samp[, , 151:152])
cat('lp__: Bulk-R_eff = ', round(res['lp__','zsreff'],2), '\n')
cat('lp__: Tail-R_eff = ', round(res['lp__','zfsreff'],2), '\n')
```

We examine the relative efficiency in different parts of the
posterior by computing the relative efficiency of small interval
probability estimates.

```{r}
plot_local_reff(fit = fit_half_reparam, par = 100+which_min_eff, nalpha = 20)
```

We examine also the relative efficiency of different quantile estimates.

```{r}
plot_quantile_reff(fit = fit_half_reparam, par = 100+which_min_eff, nalpha = 40)
```

The relative efficiency near zero is much worse than for the
half-Cauchy with nominal parameterization and constraint `<lower=0>`.

Rank plot visualisation of x[`r which_min_eff`], which has the smallest relative
efficiency `r round( min(res$zsreff), 2)` among `x`'s.
```{r}
xmin <- paste0("x[", which_min_eff, "]")
mcmc_hist_r_scale(samp[, , "x[15]"])
```

The rank plots seem to be different from uniform, which is expected
with lower relative efficiency.

Rank plot visualisation of `lp__`, which has relative efficiency 0.24.
```{r}
mcmc_hist_r_scale(samp[, , "lp__"])
```

The rank plot is different from uniform, which is expected with lower
relative efficiency, but would require a reference.

## Hierarchical model: Eight Schools

Eight Schools data is classic example for hierarchical models (Section
5.5, @BDA3), which despite the apparent simplicity nicely illustrates
the typical problems in inference for hierarchical models.  The Stan
models below are from Michael Betancourt's case study on [Diagnosing
Biased Inference with
Divergences](http://mc-stan.org/users/documentation/case-studies/divergences_and_bias.html).

### A Centered Eight Schools model

```{r, comment=NA}
writeLines(readLines("eight_schools_cp.stan"))
```

#### Centered parameterization default MCMC options

Run centered parameterization model with default MCMC options.
```{r fit_cp, cache=TRUE, comment=NA, results='hide'}
input_data <- read_rdump("eight_schools.data.R")
fit_cp <- stan(
  file='eight_schools_cp.stan', data=input_data,
  iter=2000, chains=4, seed=483892929, refresh=0
)
```

We do observe divergent transitions, which is sensitive diagnostic for
this model and we observer also low BFMI, so we already know that the
results can't be trusted.  We can use Rhat and Reff diagnostics also
for other MCMC algorithms, but they can also be helpful to recognize
problematic parts of the posterior.

```{r, cache=FALSE}
sel <- c(
  'sRhat', 'zsRhat', 'zfsRhat', 'reff',
  'zsreff', 'zfsreff', 'medsreff', 'madsreff'
)
res <- monitor_simple(fit_cp)
round(res[, sel], 2)
```

Some rank-normalized split-Rhats are larger than 1.01. Bulk-$R_{\rm
eff}$ for `tau` and `lp__` are less than 10%, which is worryingly low
and longer chains should be run.

We examine the relative efficiency in different parts of the
posterior by computing the relative efficiency of small interval
probability estimates for `tau`. 

```{r}
plot_local_reff(fit = fit_cp, par = "tau", nalpha = 20)
```

We see that MCMC has difficulties in exploring small `tau` values. As
the efficiency for estimating small `tau` values is practically zero, we
may assume that we may miss substantial amount of posterior mass and
get biased estimates. Red ticks which show chains with divergences
have concentrated to small `tau` values, indicating problems exploring
even smaller values which is likely to cause bias.

We examine also the relative efficiency of different quantile estimates.

```{r}
plot_quantile_reff(fit = fit_cp, par = "tau", nalpha = 40)
```

Most of the quantile estimates have worryingly low relative efficiency.

Rank plot visualisation of `tau`, which has the smallest relative
efficiency 0.05 among parameters.

```{r}
samp_cp <- as.array(fit_cp)
mcmc_hist_r_scale(samp_cp[, , "tau"])
```

We observe clear problems.

Rank plot visualisation of `lp__`, which has relative efficiency 0.05.
```{r}
mcmc_hist_r_scale(samp_cp[, , "lp__"])
```

We observe clear problems.

As we observed clear problems we shouldn't trust any Monte Carlo error
estimates, but for illustration we show MCSE, interval and
corresponding S_eff for median of `mu` and `tau`.
<!-- This needs prettyfying -->
```{r}
round(quantile_mcse(samp_cp, par="mu", prob=0.5),2)
round(quantile_mcse(samp_cp, par="tau", prob=0.5),2)
```

The proposed default output from Stan would look as follows, with some
Rhat>1.01 and Reff<0.1 indicating potential convergence problem.
```{r}
monitorn(fit_cp)
```

#### Centered parameterization with longer chains

Low R_eff can be sometimes compensated with longer chains. Let's check
10 times longer chain.

```{r fit_cp2, cache=TRUE, comment=NA, results='hide'}
fit_cp2 <- stan(
  file='eight_schools_cp.stan', data=input_data,
  iter=20000, chains=4, seed=483892929, refresh=0
)
```

```{r}
res <- monitor_simple(fit_cp2)
round(res[, sel], 2)
```

Some rank-normalized split-Rhats are still larger than 1.01. Bulk-$R_{\rm
eff}$ for `tau` and `lp__` are around 1%. A drop in the relative
efficiency when increasing the number of iterations indicates serious
problems in mixing.

We examine the relative efficiency in different parts of the
posterior by computing the relative efficiency of small interval
probability estimates for `tau`.

```{r}
plot_local_reff(fit = fit_cp2, par = "tau", nalpha = 50)
```

We see that MCMC has difficulties in exploring small `tau` values. As
the efficiency for estimating small `tau` values is practically zero, 
we may assume that we may miss substantial amount of posterior mass and
get biased estimates.

We examine also the relative efficiency of different quantile estimates.
```{r}
plot_quantile_reff(fit = fit_cp2, par = "tau", nalpha = 100)
```

Most of the quantile estimates have worryingly low relative efficiency
and many practically zero efficiency indicating clear failure in
mixing.

We examine also small probability interval efficiency for `mu` in the following plot.
```{r}
plot_local_reff(fit = fit_cp2, par = "mu", nalpha = 50)
```

There are gaps of poor efficiency which indicates sticking of MCMC,
but the sticking doesn't occur for any specific range of values of `mu` as for `tau`.

We examine also the relative efficiency of different quantiles of `mu`
```{r}
plot_quantile_reff(fit = fit_cp2, par = "mu", nalpha = 100)
```

We see clear failure in mixing.

Rank plot visualisation of `tau`, which has the smallest relative
efficiency 0.01 among parameters.
```{r}
samp_cp2 <- as.array(fit_cp2)
mcmc_hist_r_scale(samp_cp2[, , "tau"])
```

We observe clear problems to sample small values of `tau` and sticking of the 4th chain.

Rank plot visualisation of lp__, which has relative efficiency 0.01.
```{r}
mcmc_hist_r_scale(samp_cp2[, , "lp__"])
```

We observe clear problems sampling different energy levels, which are connected to values of `tau`.

As we observed clear problems we shouldn't trust any Monte Carlo error
estimates, but for illustration we show MCSE, interval and
corresponding S_eff for median of `mu` and `tau`. Comparing to the
shorter MCMC run, 10 times more draws has not reduced the MCSE to one
third as would be expected without problems in in mixing.
<!-- This needs prettyfying -->
```{r}
round(quantile_mcse(samp_cp2, par="mu", prob=0.5),2)
round(quantile_mcse(samp_cp2, par="tau", prob=0.5),2)
```

The proposed default output from Stan would look as follows, with some
Rhat>1.01 and Reff<=0.01 indicating convergence problem.
```{r}
monitorn(fit_cp2)
```

#### Centered parameterization very long chains

And for further evidence let's check 100 times longer chains than the default.
```{r fit_cp3, cache=TRUE, comment=NA, results='hide'}
fit_cp3 <- stan(
  file='eight_schools_cp.stan', data=input_data,
  iter=200000, chains=4, seed=483892929, refresh=0
)
```

```{r}
res <- monitor_simple(fit_cp3)
round(res[, sel], 2)
```

Some rank-normalized split-Rhats are still larger than 1.01. Bulk-$R_{\rm
eff}$ for `tau` and `lp__` are around 0% and relative efficiencies
for other parameters are also very small. Drop in the relative
efficiency when the the sample size is increased indicates serious
problems in mixing.

We examine the relative efficiency in different parts of the
posterior by computing the relative efficiency of small interval
probability estimates for `tau`.
```{r}
plot_local_reff(fit = fit_cp3, par = "tau", nalpha = 100)
```

We see that MCMC has difficulties in exploring small `tau` values. As
the efficiency for estimating small `tau` values is practically zero, we
may assume that we may miss substantial amount of posterior mass and
get biased estimates. It is good to note that the low efficiency for
small `tau` values is due to too large step size, and the low efficiency
for large tau values is partially due to too small step size, but even
more importantly due to the random walk in energy space.

We examine also the relative efficiency of different quantile estimates.
```{r}
plot_quantile_reff(fit = fit_cp3, par = "tau", nalpha = 100)
```

Most of the quantile estimates have worryingly low relative efficiency
and many practically zero efficiency indicating clear failure in
mixing.

Rank plot visualisation of `tau`, which has the smallest relative
efficiency 0.00 among parameters.
```{r}
samp_cp3 <- as.array(fit_cp3)
mcmc_hist_r_scale(samp_cp3[, , 2])
```

We observe clear problems to sample small values of tau.  Even with
100000 draws per chain, the plots don't get crowded as traceplots
would, and sticking of chains is easy to see.

Rank plot visualisation of lp__, which has relative
efficiency 0.01.
```{r}
mcmc_hist(r_scale(samp_cp3[,,11]), breaks = seq(0,prod(dim(samp_cp3)[1:2]),by=prod(dim(samp_cp3)[1:2])/100)+0.5)
```

We observe clear problems sampling different energy levels and
sticking in all chains.

As we observed clear problems we shouldn't trust any Monte Carlo error
estimates, but for illustration we show MCSE, interval and
corresponding S_eff for median of `mu` and `tau`.  Comparing to the
shorter MCMC run, 100 times more draws has not reduced the MCSE to one
tenths as would be expected without problems in in mixing.
<!-- This needs prettyfying -->
```{r}
round(quantile_mcse(samp_cp3, par="mu", prob=0.5),2)
round(quantile_mcse(samp_cp3, par="tau", prob=0.5),2)
```

The proposed default output from Stan would look as follows, with some
Rhat>1.01 and Reff<0.01 indicating convergence problem.
```{r}
monitorn(fit_cp3)
```

### Non-centered Eight Schools model

For hierarchical models, non-centered parameterization often works better
```{r, comment=NA}
writeLines(readLines("eight_schools_ncp.stan"))
```

#### Non-centered parameterization default MCMC options

Run non-centered parameterization model with default options.
```{r fit_ncp, cache=TRUE, comment=NA, results='hide'}
input_data <- read_rdump("eight_schools.data.R")
fit_ncp <- stan(
  file='eight_schools_ncp.stan', data=input_data,
  iter=2000, chains=4, seed=483892929, refresh=0
)
```

We still observe some divergent transitions with the default
`adapt_delta=0.8`. Let's analyze the sample.

```{r}
res <- monitor_simple(fit_ncp)
round(res[, sel], 2)
```

All Rhats are close to 1, and relative efficiencies are good.

We examine the relative efficiency in different parts of the
posterior by computing the relative efficiency of small interval
probability estimates for `tau`.
```{r}
plot_local_reff(fit = fit_ncp, par = "tau", nalpha = 20)
```

Small `tau` values are still more difficult to explore, but the relative
efficiency is in a good range.

We examine also the relative efficiency of different quantile estimates.
```{r}
plot_quantile_reff(fit = fit_ncp, par = "tau", nalpha = 40)
```

Small quantile estimates have lower but still useful efficiencies.

Rank plot visualisation of `tau`, which has the smallest relative
efficiency 0.57 among parameters.

```{r}
samp_ncp <- as.array(fit_ncp)
mcmc_hist_r_scale(samp_ncp[, , 2])
```

We can see problems in sampling small values of tau.

Rank plot visualisation of lp__, which has relative efficiency 0.01.
```{r}
mcmc_hist_r_scale(samp_ncp[, , 19])
```

We observe clear problems sampling different energy levels.

As we observed clear problems we shouldn't trust any Monte Carlo error
estimates, but for illustration we show MCSE, interval and
corresponding S_eff for median of `mu` and `tau`. MCSE is much smaller
than with the problematic centered parameterization.
<!-- This needs prettyfying -->
```{r}
round(quantile_mcse(samp_ncp, par="mu", prob=0.5),2)
round(quantile_mcse(samp_ncp, par="tau", prob=0.5),2)
```

The proposed default output from Stan would look as follows, with all
Rhat<1.01 and Reff>0.1.
```{r}
monitorn(fit_ncp, warmup=0)
```

#### Non-centered parameterization default MCMC options plus `adapt_delta=0.95`

Next we examine the same model but with higher `adapt_delta=0.95`.
```{r fit_ncp2, cache=TRUE, comment=NA, results='hide'}
fit_ncp2 <- stan(
  file='eight_schools_ncp.stan', data=input_data,
  iter=2000, chains=4, control=list(adapt_delta = 0.95), 
  seed=483892929, refresh=0
)
```

We get zero divergences with `adapt_delta = 0.95`.

```{r}
res <- monitor_simple(fit_ncp2)
round(res[, sel], 2)
```

All Rhats are close to 1, and relative efficiencies are good and
slightly better than with the default `adapt_delta`.

We examine the relative efficiency in different parts of the
posterior by computing the relative efficiency of small interval
probability estimates for `tau`.
```{r}
plot_local_reff(fit = fit_ncp2, par = "mu", nalpha = 20)
```

Small `tau` values are still more difficult to explore, but the relative
efficiency is in a good range.

Check with a finer resolution
```{r}
plot_local_reff(fit = fit_ncp2, par = "mu", nalpha = 50)
```

Also with a finer resolution the efficiency of MCMC is good for
different values of tau.

We examine also the relative efficiency of different quantile estimates.
```{r}
plot_quantile_reff(fit = fit_ncp2, par = "mu", nalpha = 40)
```

Rank plot visualisation of `tau`, which has the smallest relative
efficiency 0.62 among parameters.
```{r}
samp_ncp2 <- as.array(fit_ncp2)
mcmc_hist_r_scale(samp_ncp2[, , 2])
```

Higher `adapt_delta` value seems to have improved sampling of small values.

Rank plot visualisation of `lp__`, which has relative efficiency 0.44.
```{r}
mcmc_hist_r_scale(samp_ncp2[, , 19])
```

Seems ok.

Now we should be able to trust Monte Carlo error estimates, and for
illustration we show MCSE, interval and corresponding S_eff for median
of `mu` and `tau`. The change compared to `adapt_delta=0.8` is small.
<!-- This needs prettyfying -->
```{r}
round(quantile_mcse(samp_ncp2, par="mu", prob=0.5),2)
round(quantile_mcse(samp_ncp2, par="tau", prob=0.5),2)
```

The proposed default output from Stan would look as follows, with all
Rhat<1.01 and Reff>0.1.
```{r}
monitorn(fit_ncp2)
```

#### Non-centered parameterization default MCMC options + adapt_delta=0.95 + longer chains

If in doubt, we can run longer chains.
```{r fit_ncp3, cache=TRUE, comment=NA, results='hide'}
input_data <- read_rdump("eight_schools.data.R")
fit_ncp3 <- stan(
  file='eight_schools_ncp.stan', data=input_data,
  iter=20000, chains=4, control=list(adapt_delta = 0.954), 
  seed=483892929, refresh=0
)
```

```{r}
res <- monitor_simple(fit_ncp3)
round(res[, sel], 2)
```

All Rhats are close to 1, and relative efficiencies are good. Relative efficiencies
are similar as for shorter chain, which means that running longer
chains is giving us higher effective sample size.

We examine the relative efficiency in different parts of the
posterior by computing the relative efficiency of small interval
probability estimates for `tau`.
```{r}
plot_local_reff(fit = fit_ncp3, par = "tau", nalpha = 100)
```

Small `tau` values are still more difficult to explore, but the relative
efficiency is in a good range.

We examine also the relative efficiency of different quantile estimates.
```{r, cache=FALSE}
plot_quantile_reff(fit = fit_ncp3, par = "tau", nalpha = 100)
```

Rank plot visualisation of `tau`, which has the smallest relative
efficiency of `r round(res["tau","zsreff"], 2)` among parameters.
```{r}
samp_ncp3 <- as.array(fit_ncp3)
mcmc_hist_r_scale(samp_ncp3[, , "tau"])
```

Nothing special.

Rank plot visualisation of `lp__`, which has a relative efficiency of `r round(monitor_simple(samp_ncp3[, , "lp__"])$zsreff, 2)`.
```{r}
mcmc_hist_r_scale(samp_ncp3[, , "lp__"])
```

Nothing special.

Now we should be able to trust Monte Carlo error estimates, and for
illustration we show MCSE, interval and corresponding S_eff for median
of `mu` and `tau`. Longer chains have reduced MCSE as we would expect
for well nehaving chains.
<!-- This needs prettyfying -->
```{r, cache=FALSE}
round(quantile_mcse(samp_ncp3, par="mu", prob=0.5),2)
round(quantile_mcse(samp_ncp3, par="tau", prob=0.5),2)
```

The proposed default output from Stan would look as follows, with all
Rhat<1.01 and Reff>0.1.
```{r}
monitorn(fit_ncp3)
```

## Dynamic HMC and effective sample size

We have already seen that the relative efficiency of dynamic can be
higher than with independent draws. The next example illustrates
interesting relative efficiency phenomena due to properties of the
dynamic HMC algorithms.

We sample from a simple 16-dimensional unit normal model.

```{r}
writeLines(readLines("normal.stan"))
```

```{r fit_n, cache=TRUE, comment=NA, results='hide'}
fit_n <- stan(
  file='normal.stan', data=data.frame(J=16),
  iter=20000, chains=4, seed=483892929, refresh=0
)
```

```{r}
samp <- as.array(fit_n)
res <- monitor_simple(samp)
round(res[, sel], 2)
```

Bulk-$R_{\rm eff}$ for all $x$ is larger than `r round(min(res[1:16,
"zsreff"]), 2)`.  However tail-$R_{\rm eff}$ for all $x$ is less than
`r round(max(res[1:16, "zfsreff"]), 2)`, and bulk-$R_{\rm eff}$ for
`lp__` is only `r round(res["lp__", "zsreff"], 2)`.  If we take a look
at all the Stan examples in this notebook, we see that the bulk-$R_{\rm eff}$
for `lp__` is always below 0.5. `lp__` correlates strongly with the total
energy in HMC, and that total energy is sampled using random walk
proposal once per iteration and thus it's likely that `lp__` has some
random walk behavior leading to autocorrelation and relative
efficiency below 1. On the other hand, No-U-Turn behavior and sampling
from the trajectory may make the Markov chain to be antithetic with
negative odd lag correlation and the bulk relative efficiency higher than 1
for some parameters.

Let's check the relative efficiency in different parts of the
posterior by computing the relative efficiency of small interval
probability estimates for `x[1]`.
```{r}
plot_local_reff(fit = fit_n, par = 1, nalpha = 100)
```

The relative efficiency for probability estimate for a small interval
is close to 1 with a slight drop in the tails. This is a good result,
but far from the relative efficiency for the bulk, mean, and median estimates.

Let's check the relative efficiency of quantiles.
```{r}
plot_quantile_reff(fit = fit_n, par = 1, nalpha = 100)
```

Central quantile estimates have higher relative efficiency than tail
quantile estimates.

The total energy of HMC should affect how far in the tails a chain in
one iteration can go. Fat tails of the target have high energy, and
thus only chains with high total energy can reach there. This will
suggest that the random walk in total energy would cause random walk
in variance of x. Let's check the second moment of x.
```{r}
samp <- as.array(fit_n, pars = "x")^2
res <- monitor_simple(samp)
round(res[, sel], 2)
```

Mean of bulk-$R_{\rm eff}$ for $x_j^2$ is 
`r round(mean(res$zsreff), 2)`, which is quite
close to bulk-$R_{\rm eff}$ for `lp__`. This is not that
surprising as the potential energy in normal model is relative to
$\sum_{j=1}^J x_j^2$.

Let's check the relative efficiency in different parts of the
posterior by computing the relative efficiency of small interval
probability estimates for `x[1]^2`.
```{r}
plot_local_reff(fit = samp, par = 1, nalpha = 100)
```

The relative efficiency is mostly a bit below 1, but for the right
tail of $x_1^2$ the relative efficiency drops. This likely due to
only some iterations have high enough total energy to obtain draws
from the high energy part of the tail.

Let's check the relative efficiency of quantiles.
```{r}
plot_quantile_reff(fit = samp, par = 1, nalpha = 100)
```

We can see the correlation between `lp__` and magnitude of `x[1]` in
the following plot.
```{r}
samp <- as.array(fit_n)
qplot(
  as.vector(samp[, , "lp__"]),
  abs(as.vector(samp[, , "x[1]"]))
) + 
  xlab('lp__') + 
  ylab('x[1]')
```

Low `lp__` corresponds to high energy and more variation in `x[1]`, and
high `lp__` corresponds to low energy and small variation in `x[1]`. Finally $\sum_{j=1}^J x_j^2$ is perfectly correlated with `lp__`.
```{r}
qplot(
  as.vector(samp[, , "lp__"]),
  as.vector(apply(samp[, , 1:16]^2, 1:2, sum))
) + 
  xlab('lp__') + 
  ylab('sum(x^2)')
```

This shows that even if we get high relative efficiency estimates for
central quantities (like mean and median), it is important to look at
relative efficiency of scale and tail quantities, too. The relative
efficiency of `lp__` can also indicate problems of sampling in tails.

# References {.unnumbered}

<div id="refs"></div>

# Original Computing Environment {.unnumbered}

```{r, comment=NA}
makevars <- file.path(Sys.getenv("HOME"), ".R/Makevars")
if (file.exists(makevars)) {
  writeLines(readLines(makevars)) 
}
```

```{r, comment=NA}
devtools::session_info("rstan")
```

