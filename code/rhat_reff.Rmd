---
title: "Rank-normalized split-Rhat and relative efficiency estimates"
author: "Aki Vehtari, Andrew Gelman, Daniel Simpson, Bob Carpenter, Paul BÃ¼rkner"
date: "First version 2017-05-23. Last modified `r format(Sys.Date())`."
encoding: "UTF-8"
output:
  html_document:
    fig_caption: yes
    toc: TRUE
    toc_depth: 2
    number_sections: TRUE
    toc_float:
      smooth_scroll: FALSE
bibliography: rhat_reff.bib
csl: harvard-cite-them-right.csl
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(
  comment = NA, 
  cache = FALSE,
  fig.width = 10
)
options(width = 100)
```

# Introduction

The Split-$\widehat{R}$ statistic and the effective sample size $S_{\rm eff}$
(previously called $N_{\rm eff}$ or $n_{\rm eff}$) are routinely used to monitor
the convergence of iterative simulations, which are omnipresent in Bayesian
statistics in the form of Markov-Chain Monto-Carlo samples. The original
$\widehat{R}$ statistic [@Gelman+Rubin:1992; @Brooks+Gelman:1998] and
*split*-$\widehat{R}$ [@BDA3] are both based on the ratio of between and
within-chain marginal variances of the simulations, while the latter is computed
from split chains (hence the name).

$\widehat{R}$, *split*-$\widehat{R}$, and $S_{\rm eff}$ are well defined only if
the marginal distributions have finite mean and variance. Even if that's the
case, their estimates are less stable for distributions with long tails. To
alleviate these problems, we define *split*-$\widehat{R}$ and $S_{\rm eff}$
using rank normalized values, empirical cumulative density functions, and small
posterior intervals.

The code for the new *split*-$\widehat{R}$ and $S_{\rm eff}$ versions and for
the corresponding diagnostic plots can be found in [monitornew.R](monitornew.R)
and [monitorplot.R](monitorplot.R), respectively.

# Review of *split*-$\widehat{R}$ and effective sample size

In this section, we will review the split-$\widehat{R}$ and 
effective sample size estimates as implemented in Stan 2.18 [@Stan.2.18].
These implementations represent the current de facto standard of convergence
diagnostics for iterative simulations.

## *Split*-$\widehat{R}$ {#SplitRhat}

Below, we present the computation of *Split*-$\widehat{R}$ following
@BDA3, but using the notation style of @StanBook. Our general recommendation
is to always run several chains. $N$ is the number of draws per chain, $M$ is
the number of chains, and $S=MN$ is the total number of draws from all
chains. For each scalar summary of interest $\theta$, we
compute $B$ and $W$, the between- and within-chain variances:

<!--
$$
B = \frac{N}{M-1}\sum_{m=1}^{M}(\overline{\theta}_{.m}-\overline{\theta}_{..})^2,
\;\mbox{ where }\;\;\overline{\theta}_{.m}=\frac{1}{N}\sum_{n=1}^nN \theta_{nm},\;\;
\;\;\overline{\theta}_{..} = \frac{1}{M}\sum_{m=1}^M\overline{\theta}_{.m}\\
W =
 \frac{1}{M}\sum_{m=1}^{M}s_j^2, \;\mbox{ where }\;\; s_m^2=\frac{1}{N-1}
\sum_{n=1}^N (\theta_{nm}-\overline{\theta}_{.m})^2.
$$
-->

$$
B = \frac{N}{M-1}\sum_{m=1}^{M}(\overline{\theta}^{(.m)}-\overline{\theta}^{(..)})^2,
\;\mbox{ where }\;\;\overline{\theta}^{(.m)}=\frac{1}{N}\sum_{n=1}^N \theta^{(nm)},\;\;
\;\;\overline{\theta}^{(..)} = \frac{1}{M}\sum_{m=1}^M\overline{\theta}^{(.m)}
\\
W = \frac{1}{M}\sum_{m=1}^{M}s_j^2, \;\mbox{ where }\;\; s_m^2=\frac{1}{N-1}
\sum_{n=1}^N (\theta^{(nm)}-\overline{\theta}^{(.m)})^2.
$$

The between-chain variance, $B$, also contains the factor $N$ because it is
based on the variance of the within-chain means, $\overline{\theta}^{(.m)}$,
each of which is an average of $N$ values $\theta^{(nm)}$.

We can estimate $\mbox{var}(\theta \mid y)$, the marginal posterior variance
of the estimand, by a weighted average of $W$ and $B$, namely
$$
\widehat{\mbox{var}}^+(\theta \mid y)=\frac{N-1}{N}W + \frac{1}{N}B.
$$
This quantity *overestimates* the marginal posterior variance assuming the
starting distribution of the simulations is appropriately overdispersed compared
to the target distribution, but is *unbiased* under stationarity (that is, if
the starting distribution equals the target distribution), or in the limit
$N\rightarrow\infty$. To have an overdispersed starting distribution,
independent Markov chains should be initialized with diffuse starting values for
the parameters.

Meanwhile, for any finite $N$, the within-chain variance
$W$ should *underestimate* $\mbox{var}(\theta \mid y)$ because the 
individual chains haven't had the time to explore all of the target 
distribution and, as a result, will have less variability. 
In the limit as $N\rightarrow\infty$, the expectation of $W$ also
approaches $\mbox{var}(\theta \mid y)$.

We monitor convergence of the iterative simulations to the target
distribution by estimating the factor by which the scale of the 
current distribution for $\theta$ might be reduced if the simulations 
were continued in the limit $N\rightarrow\infty$. This potential 
scale reduction is estimated as
$$
\widehat{R}=
\sqrt{\frac{\widehat{\mbox{var}}^+(\theta \mid y)}{W}},
$$
which declines to 1 as $N\rightarrow\infty$. We call this *split*-$\widehat{R}$
because we are applying it to chains that have been split in half so that $M$ is
twice the number of actual chains. Without splitting, $\widehat{R}$ would get
fooled by non-stationary chains (see [Appendix D](#AppendixD)).

We note that *split*-$\widehat{R}$ is also well defined for sequences
that are not Markov-chains. However, for simplicity, we always refer
to 'chains' instead of more generally to 'sequences' as the former is
our primary use case for $\widehat{R}$-like measures.

## Effective sample size $S_{\rm eff}$ {#Seff}

If the $N$ simulation draws within each chain were truly
independent, the between-chain variance $B$ would be an unbiased
estimate of the posterior variance, $\mbox{var}(\theta \mid y)$, and we would have
a total of $S = MN$ independent simulations from the $M$
chains. In general, however, the simulations of $\theta$ within each
chain will be autocorrelated, and thus $B$ will be larger than 
$\mbox{var}(\theta \mid y)$, in expectation.

A nice introductory reference for analyzing MCMC results in general
and effective sample size in particular is provided by @Geyer:2011
[see also @Geyer:1992].  The particular calculations used by Stan
[@Stan.2.18] follow those for split-$\widehat{R}$, which involve both
between-chain (mean) and within-chain calculations
(autocorrelation). They were introduced in the Stan manual
[@StanManual.2.18.0] and explained in more detail in @BDA3.

One way to define effective sample size for correlated simulation
draws is to consider the statistical efficiency of the average of the
simulations $\bar{\theta}^{(..)}$ as an estimate of the posterior mean
$\mbox{E}(\theta \mid y)$. This generalizes also to posterior
expectations of functionals of parameters $\mbox{E}(g(\theta) \mid y)$
and we return later to how to estimate the effective sample size of
quantiles which cannot be presented as expectations. For
simplification, in this section we consider the effective sample size
for the posterior mean.

The effective sample size of a chain is defined in terms of the
autocorrelations within the chain at different lags. The
autocorrelation $\rho_t$ at lag $t \geq 0$ for a chain with joint
probability function $p(\theta)$ with mean $\mu$ and variance
$\sigma^2$ is defined to be
$$
\rho_t 
=
\frac{1}{\sigma^2} \, \int_{\Theta} (\theta^{(n)} - \mu)
(\theta^{(n+t)} - \mu) \, p(\theta) \, d\theta.
$$
This is just the correlation between the two chains offset by $t$
positions.  Because we know $\theta^{(n)}$ and $\theta^{(n+t)}$ have
the same marginal distribution in an MCMC setting, multiplying the
two difference terms and reducing yields
$$
\rho_t
=
\frac{1}{\sigma^2} \, \int_{\Theta} \theta^{(n)} \, \theta^{(n+t)} \, p(\theta) \, d\theta.
$$

The effective sample size of one chain generated by a process with
autocorrelations $\rho_t$ is defined by
$$
N_{\rm eff}
\ = \
\frac{N}{\sum_{t = -\infty}^{\infty} \rho_t}
\ = \
\frac{N}{1 + 2 \sum_{t = 1}^{\infty} \rho_t}.
$$

<!--
Paul: Here, you still use Neff, but elsewhere you consistently use Seff.
Is this intentional?
-->

Effective sample size $N_{\rm eff}$ can be larger than $N$ in case of antithetic
Markov chains, which have negative autocorrelations on odd lags. The Dynamic
Hamiltonian Monte-Carlo algorithms used in Stan [@Hoffman+Gelman:2014; @betancourt2017conceptual] can
produce $N_{\rm eff}>N$ for parameters with a close to Gaussian posterior (in the unconstrained space)
and low dependency on other parameters.

### Estimation of the Effective Sample Size

In practice, the probability function in question cannot be tractably
integrated and thus neither autocorrelation nor the effective sample size
can be calculated. Instead, these quantities must be estimated
from the samples themselves. The rest of this section describes an
autocorrelation and split-$\widehat{R}$ based effective sample
size estimator, based on multiple split chains. For simplicity, 
each chain will be assumed to be of the same length $N$.

Stan carries out the autocorrelation computations for all lags
simultaneously using Eigen's fast Fourier transform (FFT) package with
appropriate padding; see @Geyer:2011 for more details on using
FFT for autocorrelation calculations.
The autocorrelation estimates $\hat{\rho}_{t,m}$ at lag $t$ from
multiple chains $m \in (1,\ldots,M)$ are combined with the within-chain
variance estimate $W$ and the multi-chain variance estimate
$\widehat{\mbox{var}}^{+}$ introduced in the previous section to
compute the combined autocorrelation at lag $t$ as
$$
\hat{\rho}_t
= 1 - \frac{\displaystyle W - \textstyle \frac{1}{M}\sum_{m=1}^M 
\hat{\rho}_{t,j}}{\widehat{\mbox{var}}^{+}}. \label{rhohat}
$$
If the chains have not converged, the variance estimator
$\widehat{\mbox{var}}^{+}$ will overestimate the true marginal variance 
which leads to an overestimation of the autocorrelation and an 
underestimation of the effective sample size.

Because of noise in the correlation estimates $\hat{\rho}_t$ increases as
$t$ increases, typically the truncated sum of $\hat{\rho}_t$ is used.
Negative autocorrelations can happen only on odd lags and by summing
over pairs starting from lag $t=0$, the paired autocorrelation is
guaranteed to be positive, monotone and convex modulo estimator noise
[@Geyer:1992; @Geyer:2011].  Stan 2.18 uses Geyer's initial monotone
sequence criterion. The effective sample size of combined chains is defined as
$$
S_{\rm eff} = \frac{N \, M}{\hat{\tau}},
$$
where
$$
\hat{\tau} = 1 + 2 \sum_{t=1}^{2k+1} \hat{\rho}_t = 
-1 + 2 \sum_{t'=0}^{k} \hat{P}_{t'},
$$
and $\hat{P}_{t'}=\hat{\rho}_{2t'}+\hat{\rho}_{2t'+1}$. The initial
positive sequence estimator is obtained by choosing the largest $k$
such that $\hat{P}_{t'}>0$ for all $t' = 1,\ldots,k$. The initial monotone
sequence estimator is obtained by further reducing $\hat{P}_{t'}$ to the minimum
of the preceding values so that the estimated sequence becomes monotone.

<!--
Paul: Does \hat{\tau} have a specific name we could use? 
Is this monotone sequence finally used to compute \hat{\tau}? 
This should be made explicit.
-->

The effective sample size $S_{\rm eff}$ described here is different from similar
formulas in the literature in that we use multiple chains and between-chain
variance in the computation, which typically gives us more conservative claims
(lower values of $S_{\rm eff}$) compared to single chain estimates, especially
when mixing of the chains is poor. If the chains are not mixing at all (e.g.,
the posterior is multimodal and the chains are stuck in different modes), then
our $S_{\rm eff}$ is close to the number of chains.

Before version 2.18, Stan used a slightly incorrect initial sequence which
implied that $S_{\rm eff}$ was capped at $S$ and thus the effective sample size
was underestimated for some models. As antithetic behavior (i.e., $S_{\rm eff} >
S$) is not that common or the effect is small, and capping at $S$ can be
considered to be pessimistic, this had negligible effect on any inference.
However, it may have led to an underestimation of Stan's efficiency when
compared to other packages performing MCMC sampling.

# Rank normalized *split*-$\widehat{R}$ and relative efficiency estimates

As *split*-$\widehat{R}$, and $S_{\rm eff}$ are well defined only if
the marginal posteriors have finite mean and variance, we next
introduce *split*-$\widehat{R}$ and $S_{\rm eff}$ using rank
normalized values, empirical cumulative density functions, and small
posterior intervals which are well defined for all distributions and
more robust for long tailed distributions.

## Rank normalized *split*-$\widehat{R}$

Rank normalized *split*-$\widehat{R}$ is computed using the equations in
[Section *Split*-$\widehat{R}$](#SplitRhat) by replacing the original parameter
values $\theta^{(nm)}$ with their corresponding rank normalized values
$z^{(nm)}$.

Rank normalization:
1. Rank: Replace each value $\theta^{(nm)}$ by its rank $r^{(nm)}$. Average
rank for ties are used to conserve the number of unique values of discrete
quantities. Ranks are computed jointly for all draws from all chains.
2. Normalize: Normalize ranks by inverse normal transformation $z^{(nm)} =
\phi^{-1}((r^{(nm)}-1/2)/S)$. 

[Appendix B](#AppendixB) illustrates the rank normalization of
multiple chains.

For continuous variables and $S \rightarrow \infty$, the rank
normalized values are normally distributed and rank normalization
performs non-parametric transformation to normal distribution. Using
normalized ranks instead of ranks directly, has the benefit that the
behavior of $\widehat{R}$ and $S_{\rm eff}$ do not change for normally
distributed $\theta$.

<!--
Paul: What exactly is implied by "rank normalization
performs non-parametric transformation to normal distribution"?
What's the importance of "non-parametric" here?
I think the purpose of this statement needs to be better explained
-->

## Rank normalized *folded-split*-$\widehat{R}$

Both original and rank-normalized *split*-$\widehat{R}$ can be fooled
if chains have different scales but the same location (see [Appendix
D](#AppendixD)). To alleviate this problem, we propose to compute rank
normalized *folded-split*-$\widehat{R}$ using *folded* split chains by
rank normalizing absolute deviations from median
$$
  {\rm abs}(\theta^{(nm)}-{\rm median}(\theta)).
$$

To obtain a single conservative $\widehat{R}$ estimate, we propose to
report the maximum of rank normalized *split*-$\widehat{R}$ and
rank normalized *folded-split*-$\widehat{R}$ for each parameter.

## Relative efficiency using rank normalized values

In addition to using rank-normalized values for convergence
diagnostics via $\widehat{R}$, we can also compute the corresponding
effective sample size.  This estimate will be well defined even if the
original distribution does not have finite mean and variance. It is
not directly applicable to estimate the Monte Carlo error of the mean
of the original values, but it will provide a bijective
transformation-invariant estimate of the mixing efficiency of
chains. For simplicity we propose to report relative efficiency values
$$
R_{\rm eff}=\textit{rank-normalized-split-}S_{\rm eff} / S,
$$
where $\textit{split-}S_{\rm eff}$ is computed using equations in
[Section Effective sample size](#Seff) by replacing parameter values
$\theta^{(nm)}$ with rank normalized values $z^{(nm)}$. For parameters with
a close to normal distribution, the difference to using the original
values is small. However, for parameters with a distribution far from
normal, rank normalization can be seen as a near optimal non-parametric
transformation.

<!--
Paul: Do we have a citation for the last statment?
-->

The relative efficiency estimate using rank normalized values is a
useful measure for relative efficiency of estimating the bulk (mean
and quantiles near the median) of the distribution, and as shorthand
term we use term *bulk relative efficiency* (*bulk*-$R_{\rm
eff}$). Bulk relative efficiency estimate is also useful for
diagnosing problems due to trends or different means of the chains (see
[Appendix D](#AppendixD)).

We propose to compute the relative efficiency also using *folded*
split chains by rank normalizing absolute deviations from median (see
above), which is a useful measure for the relative efficiency of
estimating the distributions' tail. As a shorthand, we use the term
*tail relative efficiency* (*tail*-$R_{\rm eff}$). Tail relative
efficiency estimate is also useful for diagnosing problems due to 
different scales of the chains (see [Appendix D](#AppendixD)).

## Relative efficiency of the cumulative distribution function

The bulk and tail relative efficiency measures introduced above are useful as
overall efficiency measures. Next, we introduce relative efficiency estimates of
the cumulative distribution function (CDF), and later we use that to introduce
relative efficiency diagnostics of quantiles and local small probability
intervals.

Quantiles and posterior intervals derived on their basis are often
reported quantities which are easy to estimate from posterior draws.
Estimating the relative efficiency of such quantiles thus has a high
practical relevance in particular as we observe the relative
efficiency for tail quantiles to often be lower than for the mean or
median. The $\alpha$-quantile is defined as the parameter value
$\theta_\alpha$ for which $p(\theta \leq \theta_\alpha) = \alpha$. An estimate
$\hat{\theta}_\alpha$ of $\theta_\alpha$ can thus be obtained by finding the
$\alpha$-quantile of the empirical CDF (ECDF) of the posterior draws
$\theta^{(s)}$. However, quantiles cannot be written as an expectation, and thus
the above equations for $\widehat{R}$ and $S_{\rm eff}$ are not directly
applicable. Thus, we first focus on the relative efficiency of the cumulative
probability $p(\theta \leq \theta_\alpha)$ for different values of $\theta_\alpha$.

For any $\theta_\alpha$, the ECDF gives an estimate of the cumulative 
probability
$$
p(\theta \leq \theta_\alpha) \approx \bar{I}_\alpha = \frac{1}{S}\sum_{s=1}^S
I(\theta^{(s)} \leq\theta_\alpha),
$$
where $I()$ is the indicator function. The indicator function transforms
simulation draws to 0's and 1's, and thus the subsequent computations are
bijectively invariant. Efficiency estimates of the ECDF at any $\theta_\alpha$ can
now be obtained by applying rank-normalizing and subsequent computations
directly on the indictor function's results. See [Appendix
C](#AppendixC) for an illustration of variance of ECDF.

## Relative efficiency of quantiles {#quantile_R_eff}

Assuming that we know the CDF to be a certain continuous function $F$ which is
smooth near an $\alpha$-quantile of interest, we could use the delta method to
compute a variance estimate for $F^{-1}(\bar{I}_\alpha)$. Although we
don't usually know $F$, the delta method approach reveals that the variance of
$\bar{I}_\alpha$ for some $\theta_\alpha$ is scaled by the (usually unknown)
density $f(\theta_\alpha)$, but the relative efficiency depends only on the relative
efficiency of $\bar{I}_\alpha$. Thus, we can use the relative efficiency of
the ECDF computed via the indicator function 
$I(\theta^{(s)} \leq \theta_\alpha)$ also for the corresponding quantile 
estimates.

## Relative efficiency of median and MAD

Since the marginal posterior distributions might not have finite mean
and variance, by default RStan [@RStan.2.17] and RStanARM
[@RStanARM.2.17] report median and median absolute deviation (MAD)
instead of mean and standard error (SE). Median and MAD are well
defined even when the marginal distribution does not have finite mean
and variance. Since the median is just 50%-quantile, we can estimate its 
relative efficiency as for any other quantile.  

We can also compute the relative efficiency for the
median absolute deviation (MAD), by computing the relative efficiency
for the median of absolute deviations from the median of all draws. The
absolute deviations from the median of all draws are same as
previously defined for folded samples
$$
{\rm abs}(\theta^{(nm)}-{\rm median}(\theta)).
$$
We see that the relative efficiency of MAD is obtained by using the
same approach as for the median (and other quantiles) but with the folded
values also used in *rank-normalized-folded-split*-$S_{\rm eff}$.

## Monte Carlo error estimates for quantiles

Previously, Stan has reported Monte Carlo standard error estimates for
the mean of a quantity. This is valid only if the corresponding
marginal distribution has finite mean and variance; and even if valid,
it may be easier and more robust to focus on the median and other
quantiles, instead.

Median, MAD and quantiles are well defined even when the distribution does not
have finite mean and variance, and they are asymptotically normal for continuous
distributions which are non-zero in the relevant neighborhood. As the delta method
for computing the variance would require explicit knowledge of the normalized 
posterior density, we propose the following alternative approach:

1. Compute quantiles of the
${\rm Beta}(R_{\rm eff} \bar{I}_\alpha+1, R_{\rm eff}(1-\bar{I}_\alpha)+1)$
distribution. Including $R_{\rm eff}$ 
takes into account the relative efficiency of the posterior draws.
2. Find indices in $\{1,\ldots,S\}$ closest to the ranks of these quantiles. 
For example, for quantile $Q$, find $s = {\rm round(Q S)}$.
3. Use the corresponding $\theta^{(s)}$ from the list of sorted
posterior draws as quantiles from the error distribution. These quantiles can 
be used to approximate the Monte Carlo standard error.

<!--
Paul: These steps are still rather vague. We should try to make them more explicit.
Step 1 needs to state which quantiles are extracted. I see
that from the code but I can only guess the justification
Step 3 needs more explanation how these quantiles are used. Again,
I can infer that from the code, but I am not entirely sure about
the justification.
-->

## Relative efficiency of small interval probability estimates {#small_interval_R_eff}

We can get more local relative efficiency estimates by considering
small probability intervals. We propose to compute the relative
efficiencies for
$$
\bar{I}_{\alpha,\delta} = p(\hat{Q}_\alpha < \theta \leq \hat{Q}_{\alpha+\delta}),
$$
where $\hat{Q}_\alpha$ is an empirical $\alpha$-quantile, $\delta=1/k$
is the length of the interval with some positive integer $k$, and
$\alpha \in (0,\delta,\ldots,1-\delta)$ changes in steps of $\delta$.
Each interval has $S/k$ draws, and the efficiency measures
autocorrelation of an indicator function which is $1$ when the values
are inside the specific interval and $0$ otherwise. This gives us a
local efficiency measure which does not depend on the shape of the
distribution.

## Rank plots

In addition to using rank-normalized values to compute
*split*-$\widehat{R}$, we propose to use rank plots for each chain
instead of trace plots. Rank plots are nothing else than histograms of the 
ranked posterior samples (ranked over all chains) plotted separately
for each chain. If rank plots of all chains look similar, this indicates
good mixing of the chains. As compared to trace plots, rank plots don't tend
to squeeze to a mess in case of long chains.

## Proposed changes in Stan

The proposal is to switch in Stan:

- from split-$\widehat{R}$ to the maximum of rank-normalized-split-$\widehat{R}$
and rank-normalized-folded-split-$\widehat{R}$
- from the classic effective sample size estimate, which currently doesn't use
chain splitting, to rank-normalized-split-$R_{\rm eff}$ and
rank-normalized-folded-split-$R_{\rm eff}$
- instead of mean and std, report only quantiles and compute Monte
  Carlo error for each quantile computed
- if computing MAD_SD, report the corresponding MCSE

Justifications for the changes are:

- Rank normalization makes $\widehat{R}$ and (relative) effective sample size
measures well defined for all distributions, invariant under bijective
transformations, and more stable than their classical counterparts. 
- Adding folded versions of $\widehat{R}$ and (relative) effective sample size
helps in detecting scale differences across chains.
- Monte Carlo SE's of the quantiles and MAD_SD are well defined, they can be quite different for different quantiles and MAD_SD, and it's difficult to compute MCSE in head from the sample size alone.

In summary outputs, we propose to use `Rhat` to denote also the new
version. However, to make it more explicit that the rank-normalized
efficiency is different than standard efficiency, we could use the
term `Reff` to denote relative efficiency instead of using `Neff` for
the effective sample size (i.e.  absolute efficiency). The relative
efficiency is also easier to check for low values as we don't need to
compare it to the total number of draws. There are cases where the
effective sample size `Seff` might be useful, so function to compute
that is useful to be available.

## Proposed additions to bayesplot

We propose to add to the **bayesplot** package:

- Rank plots
- Plots for relative efficiency of quantiles
- Plots for relative efficiency of small probability intervals

## Warning thresholds

Based on the experiments presented in [Appendices D-F](#AppendixD),
more strict convergence diagnostics and relative efficiency warning
limits could be used. We propose the following warning thresholds
although additional experiments would be useful:

 - Rhat > 1.01
 - Seff < 400

Plots shown in the upcoming sections have dashed lines based on these thresholds
(in continuous plots, a dashed line at 1.005 is plotted instead of 1.01, as
values larger than that are usually rounded in our summaries to 1.01).

# Examples

In this section, we will go through some examples to demonstrate the
usefulness of our proposed methods as well as the associated workflow
in determining convergence. [Appendices D-G](#AppendixD) contain more
detailed analysis of different algorithm variants and further
examples.

First, we load all the necessary R packages and additional functions.

```{r, comment=NA, message=FALSE, warning=FALSE, results='hide', cache=FALSE}
library(tidyverse)
library(gridExtra)
library(rstan)
options(mc.cores = parallel::detectCores())
rstan_options(auto_write = TRUE)
library(bayesplot)
theme_set(bayesplot::theme_default(base_family = "sans"))
source('monitornew.R')
source('monitorplot.R')
```

## Cauchy: A distribution with infinite mean and variance

The classic *split*-$\widehat{R}$ is based on calculating within and between
chain variances. If the marginal distribution of a chain is such that the
variance is not defined (i.e., infinite), the classic *split*-$\widehat{R}$ is
not well justified. In this section, we will use the Cauchy distribution as an
example of such a distribution. [Appendix E](#AppendixE) contains more 
detailed analysis of different algorithm variants and further Cauchy 
examples.

The following Cauchy models are from Michael Betancourt's case study
[Fitting The Cauchy Distribution](https://betanalpha.github.io/assets/case_studies/fitting_the_cauchy.html)

### Nominal parameterization of Cauchy

The nominal Cauchy model with direct parameterization is as follows:

```{r}
writeLines(readLines("cauchy_nom.stan"))
```

#### Default Stan options

Run the nominal model:
```{r fit_nom, cache=TRUE, comment=NA, results='hide'}
fit_nom <- stan(file = 'cauchy_nom.stan', seed = 7878, refresh = 0)
```

Treedepth exceedence and Bayesian Fraction of Missing Information are
dynamic HMC specific diagnostics [@betancourt2017conceptual]. We get
warnings about a very large number of transitions after
warmup that exceeded the maximum treedepth, which is likely due to
very long tails of the Cauchy distribution. All chains have low 
estimated Bayesian fraction of missing information also indicating
slow mixing.

```{r}
mon <- monitor(fit_nom)
print(mon)
which_min_eff <- which.min(mon[1:50, 'Bulk_Reff'])
```

Several Rhat > 1.01 and some Reff < 0.1 indicate that the results should not be 
trusted. The extended case study [rhat_reff_extra](rhat_reff_extra.html) has 
more results with longer chains as well.

We can further analyze potential problems using local relative efficiency and
rank plots. We specifically investigate x[`r which_min_eff`], which has the
smallest bulk relative efficiency `r round(min(mon[,'Bulk_Reff']), 2)`. 

We examine the relative efficiency in different parts of the posterior by
computing the relative efficiency of small interval probability estimates (see
Section [Relative efficiency of small interval probability
estimates](#small_interval_R_eff)). Each interval contains $1/k$ of the draws
(e.g., $5\%$ each, if $k=20$). The small interval efficiency measures mixing of
an function which indicates when the values are inside or outside the specific
small interval. As detailed above, this gives us a local efficiency measure
which does not depend on the shape of the distribution.

```{r}
plot_local_reff(fit = fit_nom, par = which_min_eff, nalpha = 20)
```

We see that the efficiency of our posterior draws is worryingly low in the tails
(which is caused by slow mixing in long tails of Cauchy). Orange ticks
show iterations that exceeded the maximum treedepth.

An alternative way to examine the relative efficiency in different parts of the
posterior is to compute relative efficiencies for quantiles (see Section
[Relative efficiency of quantiles](#quantile_R_eff)). Each interval has a
specified proportion of draws, and the efficiency measures mixing of a function
which indicates when the values are smaller than or equal to the corresponding
quantile.

```{r, cache=FALSE}
plot_quantile_reff(fit = fit_nom, par = which_min_eff, nalpha = 40)
```

Similar as above, we see that the efficiency of our posterior draws is worryingly
low in the tails. Again, orange ticks show iterations that exceeded the maximum
treedepth.

We may also investigate how the estimated relative efficiency changes when we
use more and more draws. If the relative efficiency is highly unstable or
decreases with more draws, this indicates that simply running longer chains will
likely not solve the convergence issues. In the plots below, we see how unstable
both bulk and tail relative efficiency are for this example.

```{r, cache=FALSE}
plot_change_reff(fit = fit_nom, par = which_min_eff, type = "bulk")
plot_change_reff(fit = fit_nom, par = which_min_eff, type = "tail")
```

We can further analyze potential problems using rank plots in which we clearly
see differences between chains.

```{r}
samp <- as.array(fit_nom)
xmin <- paste0("x[", which_min_eff, "]")
mcmc_hist_r_scale(samp[, , xmin])
```


### Alternative parameterization of Cauchy

Next we examine an alternative parameterization that considers the Cauchy
distribution as a scale mixture of Gaussian distributions. The model has two
parameters and the Cauchy distributed $x$'s can be computed from those. In
addition to improved sampling performance, the example illustrates that focusing
on diagnostics matters.

```{r}
writeLines(readLines("cauchy_alt_1.stan"))
```

Run the alternative model:

```{r fit_alt1, cache=TRUE, comment=NA, results='hide'}
fit_alt1 <- stan(file = 'cauchy_alt_1.stan', seed = 7878, refresh = 0)
```

There are no warnings, and the sampling is much faster.

```{r, cache=FALSE}
mon <- monitor(fit_alt1)
print(mon)
which_min_eff <- which.min(mon[101:150, 'Bulk_Reff'])
```

All Rhat < 1.01 and Reff > 0.1 indicate the sampling worked much better with 
the alternative parameterization. The extended case study 
[rhat_reff_extra](rhat_reff_extra.html) has more results using alternative 
parameterizations.

We can further analyze potential problems using local relative efficiency and
rank plots. We take a detailed look at x[`r which_min_eff`], which has the 
smallest bulk relative efficiency of `r round(mon[which_min_eff, 'Bulk_Reff'], 2)`.

We examine the relative efficiency in different parts of the
posterior by computing the relative efficiency of small interval
probability estimates.

```{r}
plot_local_reff(fit = fit_alt1, par = which_min_eff + 100, nalpha = 20)
```

The relative efficiency is good in all parts of the posterior. Further, we 
examine the relative efficiency of different quantile estimates.

```{r}
plot_quantile_reff(fit = fit_alt1, par = which_min_eff + 100, nalpha = 40)
```

Rank plots also look rather similar across chains.

```{r}
samp <- as.array(fit_alt1)
xmin <- paste0("x[", which_min_eff, "]")
mcmc_hist_r_scale(samp[, , xmin])
```

In summary, the alterative parameterization produces results that look much
better than for the nominal parameterization. There are still some differences
in the tails, which we also identified via the tail relative efficiency estimates.


### Half-Cauchy with nominal parameterization

Half-Cauchy priors are common and, for example, in Stan usually set
using the nominal parameterization. However, when the constraint 
`<lower=0>` is used, Stan does the sampling automatically
in the unconstrained `log(x)` space, which changes the geometry
crucially.

```{r}
writeLines(readLines("half_cauchy_nom.stan"))
```

Run the half-Cauchy with nominal parameterization (and positive constraint):

```{r fit_half_nom, cache=TRUE, comment=NA, results='hide'}
fit_half_nom <- stan(file = 'half_cauchy_nom.stan', seed = 7878, refresh = 0)
```

There are no warnings, and the sampling is much faster than for the
Cauchy nominal model.

```{r, cache=FALSE}
mon <- monitor(fit_half_nom)
print(mon)
```

All Rhat < 1.01 and Reff > 0.1 indicate good performance of the sampler. We see
that the Stan's automatic (and implicit) transformation of constraint parameters
can have a big effect on the sampling performance. More experimentes with
different parameterizations of the half-Cauchy distribution can be found in
[Appendix E](#AppendixE).


## Hierarchical model: Eight Schools {#eightschools}

The Eight Schools data is a classic example for hierarchical models [see Section
5.5 in @BDA3], which despite the apparent simplicity nicely illustrates
the typical problems in inference for hierarchical models. The Stan
models below are from Michael Betancourt's case study on [Diagnosing
Biased Inference with
Divergences](http://mc-stan.org/users/documentation/case-studies/divergences_and_bias.html).
[Appendix F](#AppendixF) contains more 
detailed analysis of different algorithm variants.

### A Centered Eight Schools model

```{r, comment=NA}
writeLines(readLines("eight_schools_cp.stan"))
```

#### Centered Eight Schools model

We directly run the centered parameterization model with an increased
`adapt_delta` value to reduce the probability of getting divergent
transitions.
```{r fit_cp, cache=TRUE, comment=NA, results='hide'}
eight_schools <- read_rdump("eight_schools.data.R")
fit_cp <- stan(
  file = 'eight_schools_cp.stan', data = eight_schools,
  iter = 2000, chains = 4, seed = 483892929, refresh = 0,
  control = list(adapt_delta = 0.95)
)
```

Despite an increased `adapt_delta`, we still observe a lot of
divergent transitions, which in itself is already sufficient indicator
to not trust the results.  We can use Rhat and Reff diagnostics to
recognize problematic parts of the posterior and they could be used in
cases when other MCMC algorithms than HMC is used.

```{r, cache=FALSE}
mon <- monitor(fit_cp)
print(mon)
```

See [Appendix F](#AppendixF) for results of longer chains.

Bulk-$R_{\rm eff}$ for the between school standard deviation `tau` is
0.05<0.01, indicating we should investigate that parameter more
carefully.  We thus examine the relative efficiency in different parts
of the posterior by computing the relative efficiency of small
interval estimates for `tau`. These plots may either show quantiles or
parameter values at the vertical axis. Red ticks show divergent
transitions.

```{r}
plot_local_reff(fit = fit_cp, par = "tau", nalpha = 20)
```

```{r}
plot_local_reff(fit = fit_cp, par = "tau", nalpha = 20, rank = FALSE)
```

We see that the sampler has difficulties in exploring small `tau` values. As
the efficiency for estimating small `tau` values is practically zero,
we may assume that we may miss substantial amount of posterior mass
and get biased estimates. Red ticks, which show iterations with divergences,
have concentrated to small `tau` values, indicate also problems exploring
small values which is likely to cause bias.

We examine also the relative efficiency of different quantile estimates. Again,
these plots may either show quantiles or parameter values at the vertical axis.

```{r}
plot_quantile_reff(fit = fit_cp, par = "tau", nalpha = 40)
```

```{r}
plot_quantile_reff(fit = fit_cp, par = "tau", nalpha = 40, rank = FALSE)
```

Most of the quantile estimates have worryingly low relative efficiency.

Let's see how the estimated relative efficiency changes when we
use more and more draws.

```{r, cache=FALSE}
plot_change_reff(fit = fit_cp, par = "tau", type = "bulk")
plot_change_reff(fit = fit_cp, par = "tau", type = "tail")
```

In lines with these findings, the rank plots of `tau` clearly show problems
in the mixing of the chains.

```{r}
samp_cp <- as.array(fit_cp)
mcmc_hist_r_scale(samp_cp[, , "tau"])
```


### Non-centered Eight Schools model

For hierarchical models, the non-centered parameterization often works better
than the centered one:

```{r, comment=NA}
writeLines(readLines("eight_schools_ncp.stan"))
```

For reasons of comparability, we also run the non-centered parameterization 
model with an increased `adapt_delta` value:

```{r fit_ncp2, cache=TRUE, comment=NA, results='hide'}
fit_ncp2 <- stan(
  file = 'eight_schools_ncp.stan', data = eight_schools,
  iter = 2000, chains = 4, seed = 483892929, refresh = 0,
  control = list(adapt_delta = 0.95)
)
```

We get zero divergences and no other warnings which is a first good sign.

```{r, cache=FALSE}
mon <- monitor(fit_ncp2)
print(mon)
```

All Rhat < 1.01 and Rhat > 0.1 indicate a much better performance of the
non-centered parameterization.

We examine the relative efficiency in different parts of the
posterior by computing the relative efficiency of small interval
probability estimates for `tau`.

```{r}
plot_local_reff(fit = fit_ncp2, par = 2, nalpha = 20)
```

Small `tau` values are still more difficult to explore, but the relative
efficiency is in a good range. We may also check this with a finer resolution:

```{r}
plot_local_reff(fit = fit_ncp2, par = 2, nalpha = 50)
```

The relative efficiency of different quantile estimates looks good as well.

```{r}
plot_quantile_reff(fit = fit_ncp2, par = 2, nalpha = 40)
```

In line with these findings, the rank plots of `tau` show no substantial 
differences between chains.

```{r}
samp_ncp2 <- as.array(fit_ncp2)
mcmc_hist_r_scale(samp_ncp2[, , 2])
```

# References {.unnumbered}

<div id="refs"></div>

# Appendices {.unnumbered}

## Appendix A: Abbreviations {#AppendixA .unnumbered}

The following abbreviations are used throughout the appendices:

 - N = total number of draws
 - Rhat = classic no-split-Rhat
 - sRhat = classic split-Rhat
 - zsRhat = rank-normalized split-Rhat
    + all chains are jointly ranked and z-transformed
    + can detect differences in location and trends
 - zfsRhat = rank-normalized folded split-Rhat
    + all chains are jointly "folded" by computing absolute deviation
      from median, ranked and z-transformed
    + can detect differences in scales
 - neff = no-split effective sample size
 - reff = neff / N
 - zsneff = rank-normalized split effective sample size
    + estimates the efficiency of mean estimate for rank normalized values
 - zsreff = zsneff / N
 - zfsneff = rank-normalized folded split effective sample size
    + estimates the efficiency of rank normalized *mean* absolute deviation
 - zfsreff = zfsneff / N
 - medsneff = median split effective sample size
    + estimates the efficiency of the median
 - medsreff = medsneff / N
 - madsneff = mad split effective sample size
    + estimates the efficiency of the median absolute deviation
 - madsreff = madsneff / N
 
## Appendix B: Examples of rank normalization {#AppendixB .unnumbered}

We will illustrate the rank normalization with a few examples. First, we plot
histograms, and empirical cumulative distribution functions (ECDF)  with respect
to the original parameter values ($\theta$), scaled ranks (ranks divided by the
maximum rank), and rank normalized values (z). We used scaled ranks to make the
plots look similar for different number of draws.

100 draws from Normal(0, 1):
```{r, message=FALSE}
n <- 100
theta <- rnorm(n)
plotranknorm(theta, n)
```

100 draws from Exponential(1):
```{r, message=FALSE}
theta <- rexp(n)
plotranknorm(theta, n)
```

100 draws from Cauchy(0, 1):
```{r, message=FALSE}
theta <- rcauchy(n)
plotranknorm(theta, n)
```

In the above plots, the ECDF with respect to scaled rank and rank normalized
$z$-values look exactly the same for all distributions. In *Split*-$\widehat{R}$
and effective sample size computations, we rank all draws jointly, but then
compare ranks and ECDF of individual split chains. To illustrate the variation
between chains, we draw 8 batches of 100 draws each from Normal(0, 1):

```{r, message=FALSE}
n <- 100
m <- 8
theta <- rnorm(n * m)
plotranknorm(theta, n, m)
```

The variation in ECDF due to the variation ranks is now visible also in scaled 
ranks and rank normalized $z$-values from different batches.

The benefit of rank normalization is more obvious for non-normal distribution 
such as Cauchy:

```{r, message=FALSE}
theta <- rcauchy(n * m)
plotranknorm(theta, n, m)
```

Rank normalization makes the subsequent computations well defined and
invariant under bijective transformations. This means that we get the
same results, for example, if we use unconstrained or constrained
parameterisations in a model. 


## Appendix C: Variance of the cumulative distribution function  {#AppendixC .unnumbered}

In Section 3, we had defined the empirical CDF (ECDF) for any $\theta_\alpha$ as
$$
p(\theta \leq \theta_\alpha) \approx \bar{I}_\alpha = \frac{1}{S}\sum_{s=1}^S
I(\theta^{(s)} \leq\theta_\alpha),
$$

For independent draws, $\bar{I}_\alpha$ has a 
${\rm Beta}(\bar{I}_\alpha+1, S - \bar{I}_\alpha + 1)$ 
distribution. Thus we can easily examine the variation of the ECDF for any
$\theta_\alpha$ value from a single chain. If $\bar{I}_\alpha$ is not very close
to $1$ or $S$ and $S$ is large, we can use the variance of Beta distribution

$$
{\rm Var}[p(\theta \leq \theta_\alpha)] =
\frac{(\bar{I}_\alpha+1)*(S-\bar{I}_\alpha+1)}{(S+2)^2(S+3)}.
$$
We illustrate uncertainty intervals of the Beta distribution and normal
approximation of ECDF for 100 draws from Normal(0, 1):
```{r, message=FALSE}
n <- 100
m <- 1
theta <- rnorm(n*m)
plotranknorm(theta, n, m, interval = TRUE)
```

Uncertainty intervals of ECDF for draws from Cauchy(0, 1) illustrate again the 
improved visual clarity in plotting when using scaled ranks:

```{r, message=FALSE}
n <- 100
m <- 1
theta <- rcauchy(n*m)
plotranknorm(theta, n, m, interval = TRUE)
```

The above plots illustrate that the normal approximation is accurate for
practical purposes in MCMC diagnostics.


## Appendix D: Normal distributions with additional trend, shift or scaling {#AppendixD .unnumbered}

This part focuses on diagnostics for

 - all chains having a trend and a similar marginal distribution
 - one of the chains having a different mean
 - one of the chains having a lower marginal variance
 
To simplify, in this part, independent draws are used as a proxy for very
efficient MCMC sampling. First, we sample draws from a standard-normal 
distribution. We will discuss the behavior for non-normal distributions later.
See [Appendix A](#AppendixA) for the abbreviations used.

### Adding the same trend to all chains

All chains are from the same Normal(0, 1) distribution plus a linear trend 
added to all chains:

```{r}
conds <- expand.grid(
  iters = c(250, 1000, 4000), 
  trend = c(0, 0.25, 0.5, 0.75, 1),
  rep = 1:10
)
res <- vector("list", nrow(conds))
chains = 4
for (i in 1:nrow(conds)) {
  iters <- conds[i, "iters"]
  trend <- conds[i, "trend"]
  rep <- conds[i, "rep"]
  r <- array(rnorm(iters * chains), c(iters, chains))
  r <- r + seq(-trend, trend, length.out = iters)
  rs <- as.data.frame(monitor_extra(r))
  res[[i]] <- cbind(iters, trend, rep, rs)
}
res <- bind_rows(res)
```

If we don't split chains, Rhat misses the trends if all chains still have a
similar marginal distribution.

```{r}
ggplot(data = res, aes(y = Rhat, x = trend)) + 
  geom_point() + 
  geom_jitter() + 
  facet_grid(. ~ iters) + 
  geom_hline(yintercept = 1.005, linetype = 'dashed') + 
  geom_hline(yintercept = 1) + 
  ggtitle('Rhat without splitting chains')
```

Split-Rhat can detect trends, even if the marginals of the chains are similar.
```{r}
ggplot(data = res, aes(y = zsRhat, x = trend)) + 
  geom_point() + geom_jitter() + 
  facet_grid(. ~ iters) + 
  geom_hline(yintercept = 1.005, linetype = 'dashed') + 
  geom_hline(yintercept = 1) + 
  ggtitle('Split-Rhat')
```

**Result:** Split-Rhat is useful for detecting non-stationarity (i.e., trends)
in the chains. If we use a threshold of $1.01$, we can detect trends which
account for 2% or more of the total marginal variance. If we use a threshold of
$1.1$, we can detect trends which account for 30% or more of the total marginal
variance.

Relative efficiency (effective sample size divided by the number of
draws) is based on split Rhat and within-chain autocorrelation.

```{r}
ggplot(data = res, aes(y = zsreff, x = trend)) + 
  geom_point() + 
  geom_jitter() + 
  facet_grid(. ~ iters) + 
  geom_hline(yintercept = c(0,1)) + 
  geom_hline(yintercept = 0.1, linetype = 'dashed') + 
  ggtitle('Relative efficiency (zsreff)') + 
  scale_y_continuous(breaks = seq(0, 1, by = 0.25))
```

**Result:** Split-Rhat is more sensitive to trends for small sample
sizes, but relative efficiency becomes more sensitive for larger samples
sizes (as autocorrelations can be estimated more accurately).

**Advice:** If in doubt, run longer chains for more accurate convergence 
diagnostics.

### Shifting one chain

Next we investigate the sensitivity to detect if one of the chains has
not converged to the same distribution as the others, but has a different mean.

```{r}
conds <- expand.grid(
  iters = c(250, 1000, 4000), 
  shift = c(0, 0.25, 0.5, 0.75, 1),
  rep = 1:10
)
res <- vector("list", nrow(conds))
chains = 4
for (i in 1:nrow(conds)) {
  iters <- conds[i, "iters"]
  shift <- conds[i, "shift"]
  rep <- conds[i, "rep"]
  r <- array(rnorm(iters * chains), c(iters, chains))
  r[, 1] <- r[, 1] + shift
  rs <- as.data.frame(monitor_extra(r))
  res[[i]] <- cbind(iters, shift, rep, rs)
}
res <- bind_rows(res)
```

```{r}
ggplot(data = res, aes(y = zsRhat, x = shift)) + 
  geom_point() + 
  geom_jitter() + 
  facet_grid(. ~ iters) + 
  geom_hline(yintercept = 1.005, linetype = 'dashed') + 
  geom_hline(yintercept = 1) + 
  ggtitle('Split-Rhat')
```

**Result:** If we use a threshold of $1.01$, we can detect shifts with
a magnitude of one third or more of the marginal standard deviation. If we use
a threshold of $1.1$, we can detect a shift with a magnitude equal to or larger 
than the marginal standard deviation.

```{r}
ggplot(data = res, aes(y = zsreff, x = shift)) + 
  geom_point() +
  geom_jitter() + 
  facet_grid(. ~ iters) + 
  geom_hline(yintercept = c(0,1)) + 
  geom_hline(yintercept = 0.1, linetype = 'dashed') + 
  ggtitle('Relative efficiency (zsreff)') + 
  scale_y_continuous(breaks = seq(0, 1, by = 0.25))
```

**Result:** The relative efficiency is not as sensitive, but a shift
with a magnitude of half the marginal standard deviation or more will lead to
very low efficiency when sample size increases.

Rank plots can be used to visualize differences between chains. Here, we show 
rank plots for the case of 4 chains, 250 draws per chain, and a shift of 0.5.

```{r}
iters = 250
chains = 4
shift = 0.5
r <- array(rnorm(iters * chains), c(iters, chains))
r[, 1] <- r[, 1] + shift
colnames(r) <- 1:4
mcmc_hist_r_scale(r)
```

<!--
add guidelines for uniformity as in
https://betanalpha.github.io/assets/case_studies/principled_bayesian_workflow.html
-->

Although, Rhat was less than $1.05$ for this situation, the rank plots clearly 
show that the first chains behaves differently.

### Scaling one chain

Next, we investigate the sensitivity to detect if one of the chains has
not converged to the same distribution as the others, but has lower
marginal variance.

```{r, cache=FALSE}
conds <- expand.grid(
  iters = c(250, 1000, 4000), 
  scale = c(0, 0.25, 0.5, 0.75, 1),
  rep = 1:10
)
res <- vector("list", nrow(conds))
chains = 4
for (i in 1:nrow(conds)) {
  iters <- conds[i, "iters"]
  scale <- conds[i, "scale"]
  rep <- conds[i, "rep"]
  r <- array(rnorm(iters * chains), c(iters, chains))
  r[, 1] <- r[, 1] * scale
  rs <- as.data.frame(monitor_extra(r))
  res[[i]] <- cbind(iters, scale, rep, rs)
}
res <- bind_rows(res)
```

We first look at the Rhat estimates:

```{r}
ggplot(data = res, aes(y = zsRhat, x = scale)) + 
  geom_point() + 
  geom_jitter() + 
  facet_grid(. ~ iters) + 
  geom_hline(yintercept = 1.005, linetype = 'dashed') + 
  geom_hline(yintercept = 1) + 
  ggtitle('Split-Rhat')
```

**Result:** Split-Rhat is not able to detect scale differences between chains.

```{r}
ggplot(data = res, aes(y = zfsRhat, x = scale)) + 
  geom_point() + 
  geom_jitter() + 
  facet_grid(. ~ iters) + 
  geom_hline(yintercept = 1.005, linetype = 'dashed') + 
  geom_hline(yintercept = 1) + 
  ggtitle('Folded-split-Rhat')
```

**Result:** Folded-Split-Rhat focuses explicitly on scales and can thus detect
scale differences.

**Result:** If we use a threshold of $1.01$, we can detect a chain with scale
less than $3/4$ of the standard deviation of the others. If we use threshold 
of $1.1$, we can detect a chain with standard deviation less than $1/4$ of 
the standard deviation of the others.

Next, we look at the relative efficiency estimates:

```{r}
ggplot(data = res, aes(y = zsreff, x = scale)) + 
  geom_point() + 
  geom_jitter() + 
  facet_grid(. ~ iters) + 
  geom_hline(yintercept = c(0,1)) + 
  geom_hline(yintercept = 0.1, linetype = 'dashed') + 
  ggtitle('Relative efficiency (zsreff)') + 
  scale_y_continuous(breaks = seq(0, 1, by = 0.25))
```

**Result:** The relative efficiency of the mean does not see a problem as it
focuses on location differences between chains.

```{r}
ggplot(data = res, aes(y = zfsreff, x = scale)) + 
  geom_point() + 
  geom_jitter() + 
  facet_grid(. ~ iters) + 
  geom_hline(yintercept = c(0,1)) + 
  geom_hline(yintercept = 0.1, linetype = 'dashed') + 
  ggtitle('Folded relative efficiency (zfsreff)') + 
  scale_y_continuous(breaks = seq(0, 1, by = 0.25))
```

**Result:** The relative efficiency of the standard deviation 
does see the problem as it focuses explicitely on the scale of the chains.

Rank plots can be used to visualize differences between chains. Here, we show
rank plots for the case of 4 chains, 250 draws per chain, and with one chain
having a standard deviation of 0.75 as opposed to a standard deviation of 1 for
the other chains.

```{r}
iters = 250
chains = 4
scale = 0.75
r <- array(rnorm(iters * chains), c(iters, chains))
r[, 1] <- r[, 1] * scale
colnames(r) <- 1:4
mcmc_hist_r_scale(r)
```

Although folded Rhat is $1.06$, the rank plots clearly show that the first
chains behaves differently.


## Appendix E: Cauchy: A distribution with infinite mean and variance {#AppendixE .unnumbered}

The classic split-Rhat is based on calculating within and between chain
variances. If the marginal distribution of a chain is such that
the variance is not defined (i.e. infinite), the classic split-Rhat is not 
well justified. In this section, we will use the Cauchy distribution 
as an example of such distribution. Also in cases where
mean and variance are finite, the distribution can be far from
Gaussian. Especially distributions with very long tails cause
instability for variance and autocorrelation estimates. To alleviate
these problems we will use Split-Rhat for rank-normalized draws. 

The following Cauchy models are from Michael Betancourt's case study
[Fitting The Cauchy Distribution](https://betanalpha.github.io/assets/case_studies/fitting_the_cauchy.html)

### Nominal parameterization of Cauchy

We already looked at the nominal Cauchy model with direct
parameterization in the main text, but for completeness, we take a
closer look using different variants of the diagnostics.

```{r}
writeLines(readLines("cauchy_nom.stan"))
```

#### Default Stan options

Run the nominal model:
```{r fit_nom_extra, cache=TRUE, comment=NA, results='hide'}
fit_nom <- stan(file = 'cauchy_nom.stan', seed = 7878, refresh = 0)
```

Treedepth exceedence and Bayesian Fraction of Missing Information are
dynamic HMC specific diagnostics [@betancourt2017conceptual]. We get
warnings about very large number of transitions after
warmup that exceeded the maximum treedepth, which is likely due to
very long tails of the Cauchy distribution. All chains have low 
estimated Bayesian fraction of missing information also indicating
slow mixing.

Trace plots for the first parameter look wild with occasional large values:

```{r}
samp <- as.array(fit_nom) 
mcmc_trace(samp[, , 1])
```

Let's check Rhat and relative efficiency diagnostics.

```{r}
res <- monitor_extra(samp[, , 1:50])
which_min_eff <- which.min(res$zsreff)
plot_rhat(res)
```

For one parameter, Rhats exceed the classic threshold of 1.1. Depending on the
Rhat estimate, a few others also exceed the threshold of 1.01. The rank
normalized split-Rhat has several values over 1.01. Please note that the classic
split-Rhat is not well defined in this example, because mean and variance of 
the Cauchy distribution are not finite.

```{r, warning=FALSE}
plot_reff(res) 
```

Both classic and new relative efficiency estimates have
several near zero values, and so the overall sample shouldn't be trusted.

**Result:** Relative efficiency is more sensitive than (rank-normalized) 
split-Rhat to detect problems of slow mixing.

We also check the log posterior value `lp__` and find out that the relative 
efficiency is worryingly low.

```{r}
res <- monitor_extra(samp[, , 51:52]) 
cat('lp__: Bulk-R_eff = ', round(res['lp__', 'zsreff'], 2), '\n')
cat('lp__: Tail-R_eff = ', round(res['lp__', 'zfsreff'], 2), '\n')
```

We can further analyze potential problems using local relative
efficiency and rank plots. We examine x[`r which_min_eff`], which has
the smallest bulk relative efficiency of `r round(min(res$zsreff), 2)`.

We examine the relative efficiency in different parts of the
posterior by computing the relative efficiency of small interval
probability estimates (see [Section Relative efficiency of small
interval probability estimates](#small_interval_R_eff)).  Each
interval contains $1/k$ of the draws (e.g., with $k=20$).
The small interval efficiency measures mixing of an indicator
function which indicates when the values are inside the specific
small interval.  This gives us a local efficiency measure which does not
depend on the shape of the distribution.

```{r}
plot_local_reff(fit = fit_nom, par = which_min_eff, nalpha = 20)
```

We see that the efficiency is worryingly low in the tails
(which is caused by slow mixing in long tails of Cauchy). Orange ticks
show draws that exceeded the maximum treedepth.

An alternative way to examine the relative efficiency in different parts
of the posterior is to compute relative efficiency for quantiles (see
[Section Relative efficiency of quantiles](#quantile_R_eff)). Each
interval has a specified proportion of draws, and the efficiency measures
mixing of an indicator function's results which indicate when the
values are inside the specific interval. 

```{r, cahce=FALSE}
plot_quantile_reff(fit = fit_nom, par = which_min_eff, nalpha = 40)
```

We see that the efficiency is worryingly low in the tails
(which is caused by slow mixing in long tails of Cauchy). Orange ticks
show draws that exceeded the maximum treedepth.

We can further analyze potential problems using rank plots,
from which we clearly see differences between chains.

```{r}
xmin <- paste0("x[", which_min_eff, "]")
mcmc_hist_r_scale(samp[, , xmin])
```


#### Default Stan options + increased maximum treedepth

We can try to improve the performance by increasing `max_treedepth` to $20$: 

```{r fit_nom_td20, cache=TRUE, comment=NA, results='hide'}
fit_nom_td20 <- stan(
  file = 'cauchy_nom.stan', seed = 7878, 
  refresh = 0, control = list(max_treedepth = 20)
)
```

Trace plots for the first parameter still look wild with occasional large 
values.

```{r}
samp <- as.array(fit_nom_td20)
mcmc_trace(samp[, , 1])
```

```{r}
res <- monitor_extra(samp[, , 1:50])
which_min_eff <- which.min(res$zsreff)
```

We check the diagnostics for all $x$.

```{r}
plot_rhat(res)
```

All Rhats are below $1.1$, but many are over $1.01$. Classic split-Rhat has more
variation than the rank normalized Rhat (note that the former is not well
defined). The folded rank normalized Rhat shows that there is still
more variation in the scale than in the location between different chains.

```{r, warning=FALSE}
plot_reff(res) 
```

Some classic Reff's are close to zero. If we wouldn't realize that the variance
is infinite, we might try to run longer chains, but in case of an infinite
variance, zero efficiency is the truth and longer chains won't help with that. However
other quantities can be well defined, and that's why it is useful to also look
at the rank normalized version as a generic transformation to achieve finite mean and
variance. The smallest bulk-$R_{\rm eff}$ are around $0.25$, which is not that
bad. The smallest median-$R_{\rm eff}$s are larger than $0.5$, that is we are
able to estimate the median efficiently. However, many tail-$R_{\rm eff}$s are
small indicating problemes for estimating the scale of the posterior.

**Result:** The rank normalized relative efficiency is more stable than
classic relative efficiency, which is not well defined for the Cauchy distribution.

**Result:** It is useful to look at both bulk and tail relative efficiencies.

We check also `lp__`. Although increasing `max_treedepth` improved
efficiency for bulk of `x`, the efficiency for `lp__` didn't change.

```{r}
res <- monitor_extra(samp[, , 51:52])
cat('lp__: Bulk-R_eff =', round(res['lp__', 'zsreff'], 2), '\n')
cat('lp__: Tail-R_eff =', round(res['lp__', 'zfsreff'], 2), '\n')
```

We examine the relative efficiency in different parts of the
posterior by computing the relative efficiency of small interval
probability estimates.

```{r}
plot_local_reff(fit = fit_nom_td20, par = which_min_eff, nalpha = 20)
```

It seems that increasing `max_treedepth` has not much improved the efficiency 
in the tails. We also examine the relative efficiency of different quantile 
estimates.

```{r}
plot_quantile_reff(fit = fit_nom_td20, par = which_min_eff, nalpha = 40)
```

The rank plot visualisation of x[`r which_min_eff`], which has the smallest
relative efficiency of `r round(min(res$zsreff))` among the $x$, indicates 
clear convergence problems.

```{r}
xmin <- paste0("x[", which_min_eff, "]")
mcmc_hist_r_scale(samp[, , xmin])
```

The rank plot visualisation of `lp__`, which has relative efficiency `r round(monitor_extra(samp[,, "lp__"])$zsreff)`, doesn't look so good either.

```{r}
mcmc_hist_r_scale(samp[, , "lp__"])
```

#### Default Stan options + increased maximum treedepth + longer chains

Let's try running 8 times longer chains.

```{r fit_nom_td20l, cache=TRUE, comment=NA, results='hide'}
fit_nom_td20l <- stan(
  file = 'cauchy_nom.stan', seed = 7878, 
  refresh = 0, control = list(max_treedepth = 20), 
  warmup = 1000, iter = 9000
)
```

Trace plots for the first parameter still look wild with occasional large 
values.

```{r}
samp <- as.array(fit_nom_td20l)
mcmc_trace(samp[, , 1])
```

```{r}
res <- monitor_extra(samp[, , 1:50])
which_min_eff <- which.min(res$zsreff)
```

Let's check the diagnostics for all $x$.

```{r}
plot_rhat(res)
```

All Rhats are below $1.01$. The classic split-Rhat has more variation than the
rank normalized Rhat (note that the former is not well defined).

```{r, warning=FALSE}
plot_reff(res) 
```

Most classic $R_{\rm eff}$s are close to zero. Running longer chains just made 
most classic $R_{\rm eff}$s even smaller.

The smallest bulk-$R_{\rm eff}$ are around $0.25$, which is not that
bad. The smallest median-$R_{\rm eff}$'s are larger than $0.75$, that
is we are able to estimate the median efficiently. However, many
tail-$R_{\rm eff}$'s are small indicating problmes for estimating the
scale of the posterior.

**Result:** The rank normalized relative efficiency is more stable than
classic relative efficiency even for very long chains.

**Result:** It is useful to look at both bulk and tail relative efficiencies.

We also check `lp__`. Although increasing the number of iterations improved
efficiency for the bulk of the $x$, the efficiency for `lp__` didn't change.

```{r}
res <- monitor_extra(samp[, , 51:52])
cat('lp__: Bulk-R_eff =', round(res['lp__', 'zsreff'], 2), '\n')
cat('lp__: Tail-R_eff =', round(res['lp__', 'zfsreff'], 2), '\n')
```

We examine the relative efficiency in different parts of the
posterior by computing the relative efficiency of small interval
probability estimates.

```{r}
plot_local_reff(fit = fit_nom_td20l, par = which_min_eff, nalpha = 20)
```

Increasing the chain length did not seem to change the relative
efficiency. With more draws from the longer chains we can use
a finer resolution for the local efficiency estimates.

```{r}
plot_local_reff(fit = fit_nom_td20l, par = which_min_eff, nalpha = 100)
```

The efficiency far in the tails is worryingly low. This was more
difficult to see previously with less draws from the tails. We see
similar problems in the plot of relative efficiency of quantiles.

```{r}
plot_quantile_reff(fit = fit_nom_td20l, par = which_min_eff, nalpha = 100)
```

Let's look at the rank plot visualisation of x[`r which_min_eff`], which has 
the smallestrelative efficiency `r round(min(res$zsreff), 2)` among the $x$.

```{r}
xmin <- paste0("x[", which_min_eff, "]")
mcmc_hist_r_scale(samp[, , xmin])
```

Increasing the number of iterations couldn't remove the mixing
problems at the tails. The mixing problem is inherent to the nominal 
parameterization of Cauchy distribution.

### First alternative parameterization of the Cauchy distribution

Next, we examine an alternative parameterization and consider the Cauchy
distribution as a scale mixture of Gaussian distributions. The model has two
parameters and the Cauchy distributed $x$ can be computed from those. In
addition to improved sampling performance, the example illustrates that focusing
on diagnostics matters.

```{r}
writeLines(readLines("cauchy_alt_1.stan"))
```

We run the alternative model:

```{r fit_alt1_extra, cache=TRUE, comment=NA, results='hide'}
fit_alt1 <- stan(file='cauchy_alt_1.stan', seed=7878, refresh = 0)
```

There are no warnings and the sampling is much faster.

```{r}
samp <- as.array(fit_alt1)
res <- monitor_extra(samp[, , 101:150])
which_min_eff <- which(res$zsreff == min(res$zsreff))
```

```{r}
plot_rhat(res)
```

All Rhats are below $1.01$. Classic split-Rhat's also look good even though 
they are not well defined for the Cauchy distribution.

```{r, warning=FALSE}
plot_reff(res) 
```

**Result:** Rank normalized R_eff's have less variation than classic 
one which is not well defined for Cauchy.

We check `lp__`:
```{r}
res <- monitor_extra(samp[, , 151:152])
cat('lp__: Bulk-R_eff =', round(res['lp__', 'zsreff'], 2), '\n')
cat('lp__: Tail-R_eff =', round(res['lp__', 'zfsreff'], 2), '\n')
```

The relative efficiencies for `lp__` are also much better than with the
nominal parameterization.

We examine the relative efficiency in different parts of the
posterior by computing the relative efficiency of small interval
probability estimates.

```{r}
plot_local_reff(fit = fit_alt1, par = 100 + which_min_eff, nalpha = 20)
```

The relative efficiency is good in all parts of the posterior. We also examine 
the relative efficiency of different quantile estimates.

```{r}
plot_quantile_reff(fit = fit_alt1, par = 100 + which_min_eff, nalpha = 40)
```

We compare the mean relative efficiencies of the underlying parameters in the 
new parameterization and the actual $x$ we are interested in.

```{r, cahce=FALSE}
res <- monitor_extra(samp[, , 101:150])
res1 <- monitor_extra(samp[, , 1:50])
res2 <- monitor_extra(samp[, , 51:100])
```

```{r}
cat('Mean bulk-R_eff for x =' , round(mean(res[, 'zsreff']), 2), '\n')
cat('Mean tail-R_eff for x =' , round(mean(res[, 'zfsreff']), 2), '\n')
cat('Mean bulk-R_eff for x_a =' , round(mean(res1[, 'zsreff']), 2), '\n')
cat('Mean bulk-R_eff for x_b =' , round(mean(res2[, 'zsreff']), 2), '\n')
```

**Result:** We see that the relative efficiency of the interesting $x$
can be different from the relative efficiency of the parameters $x_a$
and $x_b$ that we used to compute it.

The rank plot visualisation of x[`r which_min_eff`], which has the smallest
relative efficiency of `r round(min(res$zsreff), 2)` among the $x$ looks better
than for the nominal parameterization.

```{r}
xmin <- paste0("x[", which_min_eff, "]")
mcmc_hist_r_scale(samp[, , xmin])
```

Similarily, the rank plot visualisation of `lp__`, which has a relative
efficiency of `r round(monitor_extra(samp[,, "lp__"]), 2)` looks better than for
the nominal parameterization.

```{r}
mcmc_hist_r_scale(samp[, , "lp__"])
```

### Another alternative parameterization of the Cauchy distribution

Another alternative parameterization is obtained by a univariate transformation
as shown in the following code (see also the 3rd alternative in Michael 
Betancourt's case study).

```{r}
writeLines(readLines("cauchy_alt_3.stan"))
```

We run the alternative model:

```{r fit_alt2, cache=TRUE, comment=NA, results='hide'}
fit_alt3 <- stan(file='cauchy_alt_3.stan', seed=7878, refresh = 0)
```

There are no warnings, and the sampling is much faster than for the
nominal model.

```{r}
samp <- as.array(fit_alt3)
res <- monitor_extra(samp[, , 51:100])
which_min_eff <- which(res$zsreff == min(res$zsreff))
```

```{r}
plot_rhat(res)
```

All Rhats except some folded Rhats are below 1.01. Classic split-Rhat's look
also good even though it is not well defined for the Cauchy distribution.

```{r, warning=FALSE}
plot_reff(res) 
```

**Result:** Rank normalized relative efficiencies have less variation than
classic ones. Bulk-$R_{\rm eff}$ and median-$R_{\rm eff}$ are slightly larger
than 1, which is possible for antithetic Markov chains which have negative
correlation for odd lags.

We also take a closer look at the `lp__` value:

```{r}
res <- monitor_extra(samp[, , 101:102])
cat('lp__: Bulk-R_eff =', round(res['lp__', 'zsreff'], 2), '\n')
cat('lp__: Tail-R_eff =', round(res['lp__', 'zfsreff'], 2), '\n')
```

The relative efficiency for these are also much better than with
the nominal parameterization.

We examine the relative efficiency in different parts of the
posterior by computing the relative efficiency of small interval
probability estimates.

```{r}
plot_local_reff(fit = fit_alt3, par = 50 + which_min_eff, nalpha = 20)
```

We examine also the relative efficiency of different quantile estimates.

```{r}
plot_quantile_reff(fit = fit_alt3, par = 50 + which_min_eff, nalpha = 40)
```

The relative efficiency in tails is worse than for the first
alternative parameterization, although it's still better than for the
nominal parameterization.

We compare the mean relative efficiency of the underlying parameter in the new
parameterization and the actually Cauchy distributed $x$ we are interested in.

```{r}
res <- monitor_extra(samp[, , 51:100])
res1 <- monitor_extra(samp[, , 1:50])
cat('Mean bulk-Reff for x =' , round(mean(res[, 'zsreff']), 2), '\n')
cat('Mean tail-Reff for x =' , round(mean(res[, 'zfsreff']), 2), '\n')
cat('Mean bulk-Reff for x_tilde =' , round(mean(res1[, 'zsreff']), 2), '\n')
cat('Mean tail-Reff for x_tilde =' , round(mean(res1[, 'zfsreff']), 2), '\n')
```

The Rank plot visualisation of x[`r which_min_eff`], which has the smallest
relative efficiency of `r round( min(res$zsreff), 2)` among the $x$ reveals
shows good efficiency, similar to the results for `lp__`.

```{r}
xmin <- paste0("x[", which_min_eff, "]")
mcmc_hist_r_scale(samp[, , xmin])
```

```{r}
mcmc_hist_r_scale(samp[, , "lp__"])
```


### Half-Cauchy distribution with nominal parameterization

Half-Cauchy priors are common and, for example, in Stan usually set
using the nominal parameterization. However, when the constraint 
`<lower=0>` is used, Stan does the sampling automatically
in the unconstrained `log(x)` space, which changes the geometry
crucially.

```{r}
writeLines(readLines("half_cauchy_nom.stan"))
```

We run the half-Cauchy model with nominal parameterization (and positive constraint).

```{r fit_half_nom_extra, cache=TRUE, comment=NA, results='hide'}
fit_half_nom <- stan(file = 'half_cauchy_nom.stan', seed = 7878, refresh = 0)
```

There are no warnings and the sampling is much faster than for the full
Cauchy distribution with nominal parameterization.

```{r}
samp <- as.array(fit_half_nom)
res <- monitor_extra(samp[, , 1:50])
which_min_eff <- which.min(res$zsreff)
```

```{r}
plot_rhat(res) 
```

All Rhats are below $1.01$. Classic split-Rhats also look good even though they
are not well defined for the half-Cauchy distribution.

```{r, warning=FALSE}
plot_reff(res)  
```

**Result:** Rank normalized Reffs have less variation than classic
ones. Some Bulk-$R_{\rm eff}$ and median-$R_{\rm eff}$ are larger than 1, 
which is possible for antithetic Markov chains which have negative 
correlation for odd lags.

Due to the `<lower=0>` constraint, the sampling was made in the `log(x)` space,
and we can also check the performance in that space.

```{r, cache=FALSE}
res <- monitor_extra(log(samp[, , 1:50]))
```

```{r, warning=FALSE, cache=FALSE}
plot_reff(res) 
```

$\log(x)$ is quite close to Gaussian, and thus classic Reff is also
close to rank normalized Reff which is exactly the same as for the original 
$x$ as rank normalization is invariant to bijective transformations.

**Result:** The rank normalized relative efficiency is close to the classic 
relative efficiency for transformations which make the distribution 
close to Gaussian.

We examine the relative efficiency in different parts of the
posterior by computing the relative efficiency of small interval
probability estimates.

```{r}
plot_local_reff(fit = fit_half_nom, par = which_min_eff, nalpha = 20)
```

The relative efficiency is good overall, with only a small dip in tails. We 
can also examine the relative efficiency of different quantile estimates.

```{r}
plot_quantile_reff(fit = fit_half_nom, par = which_min_eff, nalpha = 40)
```

The rank plot visualisation of x[`r which_min_eff`], which has the smallest 
relative efficiency of `r round( min(res$zsreff), 2)` among $x$, looks good.

```{r}
xmin <- paste0("x[", which_min_eff, "]")
mcmc_hist_r_scale(samp[, , xmin])
```

The rank plot visualisation of `lp__` reveals some small differences in the 
scales, but it's difficult to know whether this small variation from uniform 
is relevant.

```{r}
mcmc_hist_r_scale(samp[, , "lp__"])
```


### Alternative parameterization of the half-Cauchy distribution

```{r}
writeLines(readLines("half_cauchy_alt.stan"))
```

Run half-Cauchy with alternative parameterization
```{r fit_half_reparam, cache=TRUE, comment=NA, results='hide'}
fit_half_reparam <- stan(
  file = 'half_cauchy_alt.stan', seed = 7878, refresh = 0
)
```

There are no warnings and the sampling is as fast for the half-Cauchy
nominal model.

```{r}
samp <- as.array(fit_half_reparam)
res <- monitor_extra(samp[, , 101:150])
which_min_eff <- which.min(res$zsreff)
```

```{r}
plot_rhat(res)
```

```{r, warning=FALSE}
plot_reff(res) 
```

**Result:** The Rank normalized relative efficiencies have less variation
than classic ones which is not well defined for the Cauchy distribution.  Based on
bulk-$R_{\rm eff}$ and median-$R_{\rm eff}$, the efficency for central
quantities is much lower, but based on tail-$R_{\rm eff}$ and
MAD-$R_{\rm eff}$, the efficency in the tails is slightly better than for
the half-Cauchy distribution with nominal parameterization. We
also see that a parameterization which is good for the full Cauchy distribution 
is not necessarily good for the half-Cauchy distribution as the `<lower=0>`
constraint additionally changes the parameterization.

We also check the `lp__` values:

```{r}
res <- monitor_extra(samp[, , 151:152])
cat('lp__: Bulk-R_eff =', round(res['lp__', 'zsreff'], 2), '\n')
cat('lp__: Tail-R_eff =', round(res['lp__', 'zfsreff'], 2), '\n')
```

We examine the relative efficiency in different parts of the
posterior by computing the relative efficiency of small interval
probability estimates.

```{r}
plot_local_reff(fit_half_reparam, par = 100 + which_min_eff, nalpha = 20)
```

We also examine the relative efficiency of different quantile estimates.

```{r}
plot_quantile_reff(fit_half_reparam, par = 100 + which_min_eff, nalpha = 40)
```

The relative efficiency near zero is much worse than for the
half-Cauchy distribution with nominal parameterization.

The Rank plot visualisation of x[`r which_min_eff`], which has the smallest relative
efficiency of `r round( min(res$zsreff), 2)` among  the $x$, reveals deviations
from uniformity, which is expected with lower relative efficiency.

```{r}
xmin <- paste0("x[", which_min_eff, "]")
mcmc_hist_r_scale(samp[, , xmin])
```

A similar result is obtained when looking at the rank plots of `lp__`.

```{r}
mcmc_hist_r_scale(samp[, , "lp__"])
```


## Appendix F: Hierarchical model: Eight Schools {#AppendixF .unnumbered}

We continue with our discussion about hierarchical models on the Eight Schools
data, which we started in [Section Eight Schools](#eightschools). We also analyse the performance of of different variants of the diagnostics.

### A Centered Eight Schools model

```{r, comment=NA}
writeLines(readLines("eight_schools_cp.stan"))
```

In the main text, we observed that the centered parameterization of this
hierarchical model did not work well with the default MCMC options of Stan
plus increased `adapt_delta`, and so we directly try to fit the model with 
longer chains.

#### Centered parameterization with longer chains

Low efficiency can be sometimes compensated with longer chains. Let's check
10 times longer chain.

```{r fit_cp2, cache=TRUE, comment=NA, results='hide'}
fit_cp2 <- stan(
  file = 'eight_schools_cp.stan', data = eight_schools,
  iter = 20000, chains = 4, seed = 483892929, refresh = 0,
  control = list(adapt_delta = 0.95)
)
```

```{r}
res <- monitor_extra(fit_cp2)
print(res)
```

We still get a whole bunch of divergent transitions so it's clear that the results
can't be trusted even if all other diagnostics were good. Still, it may be worth
looking at additional diagnostics to better understand what's happening. 

Some rank-normalized split-Rhats are still larger than $1.01$. Bulk-$R_{\rm
eff}$ for `tau` and `lp__` are around $1\%$. A drop in the relative efficiency
when increasing the number of iterations indicates serious problems in mixing.

We examine the relative efficiency in different parts of the posterior by
computing the relative efficiency of small intervals for `tau`.

```{r}
plot_local_reff(fit = fit_cp2, par = "tau", nalpha = 50)
```

We see that the MCMC sampling has difficulties in exploring small `tau` values.
As the efficiency for estimating small `tau` values is practically zero, we may
assume that we may miss substantial amount of posterior mass and get biased
estimates.

We also examine the relative efficiency of different quantile estimates.

```{r}
plot_quantile_reff(fit = fit_cp2, par = "tau", nalpha = 100)
```

Let's see how the estimated relative efficiency changes when we
use more and more draws.

```{r, cache=FALSE}
plot_change_reff(fit = fit_cp2, par = "tau", type = "bulk")
plot_change_reff(fit = fit_cp2, par = "tau", type = "tail")
```

Most of the quantile estimates have worryingly low relative efficiency. That
many of the are practically zero indicates clear failure in mixing. The rank
plot visualisation of `tau` reveals substantially differences across chains.

```{r}
samp_cp2 <- as.array(fit_cp2)
mcmc_hist_r_scale(samp_cp2[, , "tau"])
```

Similar results are obtained for `lp__`, which is closely connected to `tau` 
for this model.

```{r}
mcmc_hist_r_scale(samp_cp2[, , "lp__"])
```

We may also examine small interval efficiencies for `mu`.

```{r}
plot_local_reff(fit = fit_cp2, par = "mu", nalpha = 50)
```

There are gaps of poor efficiency which again indicates problems in the mixing
of the chains. However, these problems do not occur for any specific range of 
values of `mu` as was the case for `tau`. This tells us that it's probably not
`mu` with which the sampler has problems, but more likely `tau` or a related
quantity.

As we observed divergences, we shouldn't trust any Monte Carlo
standard error (MCSE) estimates as they are likely to be biased, too.
However, for illustrationary purposes, we compute the MCSE, tail
quantiles and corresponding Seff for the median of `mu` and
`tau`. Comparing to the shorter MCMC run, 10 times more draws has not
reduced the MCSE to one third as would be expected without problems in
the mixing of the chains.

```{r}
round(quantile_mcse(samp_cp2[ , , "mu"], prob = 0.5), 2)
round(quantile_mcse(samp_cp2[ , , "tau"], prob = 0.5), 2)
```

#### Centered parameterization with very long chains

For further evidence, let's check 100 times longer chains than the default. This
is not something we would recommend doing in practice, as it is not able to
solve any problems with divergences as illustrated below.

```{r fit_cp3, cache=TRUE, comment=NA, results='hide'}
fit_cp3 <- stan(
  file = 'eight_schools_cp.stan', data = eight_schools,
  iter = 200000, chains = 4, seed = 483892929, refresh = 0,
  control = list(adapt_delta = 0.95)
)
```

```{r}
res <- monitor_extra(fit_cp3)
print(res)
```

Small interval and quantile plots of `tau` still look bad even with 
so many posterior samples.

```{r}
plot_local_reff(fit = fit_cp3, par = "tau", nalpha = 100)
plot_quantile_reff(fit = fit_cp3, par = "tau", nalpha = 100)
```

Same for the rank plots of `tau`.

```{r}
samp_cp3 <- as.array(fit_cp3)
mcmc_hist_r_scale(samp_cp3[, , "tau"])
```

What we do see is an advantage of rank plots over trace plots as even with
100000 draws per chain, rank plots don't get crowded and slow mixing of chains
is still easy to see.

### Non-centered Eight Schools model

In the following, we want to expand our understanding of the non-centered
parameterization of the hierachical model fit to the eight schools data.

```{r, comment=NA}
writeLines(readLines("eight_schools_ncp.stan"))
```

#### Non-centered parameterization with default MCMC options

In the main text, we have already seen that the non-centered parameterization
works better than the centered parameterization, at least when we use an
increased `adapt_delta` vaue. Let's see what happens when using the default 
MCMC option of Stan.

```{r fit_ncp, cache=TRUE, comment=NA, results='hide'}
fit_ncp <- stan(
  file = 'eight_schools_ncp.stan', data = eight_schools,
  iter = 2000, chains = 4, seed = 483892929, refresh = 0
)
```

We observe a few divergent transitions with the default of `adapt_delta=0.8`. 
Let's analyze the sample.

```{r}
res <- monitor_extra(fit_ncp)
print(res)
```

All Rhats are close to 1, and relative efficiencies are good despite a few
divergent transitions. Small interval and quantile plots of `tau` reveal some
sampling problems for small `tau` values, but not nearly as strong as for the
centered parameterization.

```{r}
plot_local_reff(fit = fit_ncp, par = "tau", nalpha = 20)
plot_quantile_reff(fit = fit_ncp, par = "tau", nalpha = 40)
```

Overall, the non-centered parameterization looks good even for the default
settings of `adapt_delta`, and increasing it to 0.95 gets rid of the last
remaining problems. This stands in sharp contrast to what we observed for the
centered parameterzation, where increasing `adapt_delta` didn't help at all.
Actually, this is something we observe quite often: A suboptimal
parameterization can cause problems that are not simply solved by tuning the
sampler. Instead, we have to adjust our model to achieve trustworthy inference.


## Appendix G: Dynamic HMC and effective sample size {#AppendixG .unnumbered}

We have already seen that the relative efficiency of dynamic HMC can be higher
than with independent draws. The next example illustrates interesting relative
efficiency phenomena due to the properties of dynamic HMC algorithms.

We sample from a simple 16-dimensional standard normal model.

```{r}
writeLines(readLines("normal.stan"))
```

```{r fit_n, cache=TRUE, comment=NA, results='hide'}
fit_n <- stan(
  file = 'normal.stan', data = data.frame(J = 16),
  iter = 20000, chains = 4, seed = 483892929, refresh = 0 
)
```

```{r}
samp <- as.array(fit_n)
res <- monitor_extra(samp)
print(res)
```

The Bulk-$R_{\rm eff}$ for all $x$ is larger than 
`r round(min(res[1:16, "zsreff"]), 2)`.  However tail-$R_{\rm eff}$ for all
$x$ is less than `r round(max(res[1:16, "zfsreff"]), 2)`. Further, 
bulk-$R_{\rm eff}$ for `lp__` is only `r round(res["lp__", "zsreff"], 2)`.  
If we take a look at all the Stan examples in this notebook, we see that the 
bulk-$R_{\rm eff}$ for `lp__` is always below 0.5. This is because `lp__` 
correlates strongly with the total energy in HMC, which is sampled using a 
random walk proposal once per iteration. Thus, it's likely that `lp__` has some
random walk behavior, as well, leading to autocorrelation and a small relative
efficiency. At the same time, adaptive HMC can create antithetic Markov chains
which have negative auto-correlations at odd lags. This results in a bulk 
relative efficiency of greater than 1 for some parameters.

Let's check the relative efficiency in different parts of the
posterior by computing the relative efficiency of small interval estimates 
for `x[1]`.

```{r}
plot_local_reff(fit_n, par = 1, nalpha = 100)
```

The relative efficiency for probability estimate for a small interval
is close to 1 with a slight drop in the tails. This is a good result,
but far from the relative efficiency for the bulk, mean, and median estimates.
Let's check the relative efficiency of quantiles.

```{r}
plot_quantile_reff(fit = fit_n, par = 1, nalpha = 100)
```

Central quantile estimates have higher relative efficiency than tail
quantile estimates.

The total energy of HMC should affect how far in the tails a chain in
one iteration can go. Fat tails of the target have high energy, and
thus only chains with high total energy can reach there. This will
suggest that the random walk in total energy would cause random walk
in the variance of $x$. Let's check the second moment of $x$.

```{r}
samp_x2 <- as.array(fit_n, pars = "x")^2
res <- monitor_extra(samp_x2)
print(res)
```

The mean of the bulk-$R_{\rm eff}$ for $x_j^2$ is `r round(mean(res$zsreff),
2)`, which is quite close to the bulk-$R_{\rm eff}$ for `lp__`. This is not that
surprising as the potential energy in normal model is proportional to
$\sum_{j=1}^J x_j^2$.

Let's check the relative efficiency in different parts of the posterior by
computing the relative efficiency of small interval probability estimates for
`x[1]^2`.

```{r}
plot_local_reff(fit = samp_x2, par = 1, nalpha = 100)
```

The relative efficiency is mostly a bit below 1, but for the right tail of
$x_1^2$ the relative efficiency drops. This is likely due to only some
iterations having high enough total energy to obtain draws from the high energy
part of the tail. Let's check the relative efficiency of quantiles.

```{r}
plot_quantile_reff(fit = samp_x2, par = 1, nalpha = 100)
```

We can see the correlation between `lp__` and magnitude of `x[1]` in
the following plot.

```{r}
samp <- as.array(fit_n)
qplot(
  as.vector(samp[, , "lp__"]),
  abs(as.vector(samp[, , "x[1]"]))
) + 
  labs(x = 'lp__', y = 'x[1]')
```

Low `lp__` values corresponds to high energy and more variation in `x[1]`, and
high `lp__` corresponds to low energy and small variation in `x[1]`. Finally $\sum_{j=1}^J x_j^2$ is perfectly correlated with `lp__`.

```{r}
qplot(
  as.vector(samp[, , "lp__"]),
  as.vector(apply(samp[, , 1:16]^2, 1:2, sum))
) + 
  labs(x = 'lp__', y = 'sum(x^2)')
```

This shows that even if we get high relative efficiency estimates for central
quantities (like mean or median), it is important to look at the relative
efficiency of scale and tail quantities, as well. The relative efficiency of
`lp__` can also indicate problems of sampling in the tails.


# Original Computing Environment {.unnumbered}

```{r, comment=NA}
makevars <- file.path(Sys.getenv("HOME"), ".R/Makevars")
if (file.exists(makevars)) {
  writeLines(readLines(makevars)) 
}
```

```{r, comment=NA}
devtools::session_info("rstan")
```

