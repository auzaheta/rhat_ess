---
title: "Rank-normalization, folding, and localization: An improved $\\widehat{R}$ for assessing convergence of MCMC (online appendix)"
author: "Aki Vehtari, Andrew Gelman, Daniel Simpson, Bob Carpenter, Paul-Christian Bürkner"
date: "Major version 2019-03-19. Minor modifications `r format(Sys.Date())`."
encoding: "UTF-8"
output:
  html_document:
    fig_caption: yes
    toc: TRUE
    toc_depth: 2
    number_sections: TRUE
    toc_float:
      smooth_scroll: FALSE
bibliography: rhat_ess.bib
csl: harvard-cite-them-right.csl
editor_options: 
  chunk_output_type: console
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(
  comment = NA, 
  cache = FALSE,
  fig.width = 10
)
options(width = 100)
```

# Overview

This is the online appendix of the paper

- Aki Vehtari, Andrew Gelman, Daniel Simpson, Bob Carpenter,
Paul-Christian Bürkner (2020): Rank-normalization, folding, and localization: An improved $\widehat{R}$ for assessing convergence of MCMC. [arXiv preprint arXiv:1903.08008](http://arxiv.org/abs/1903.08008).

The code for the paper is available on Github
(https://github.com/avehtari/rhat_ess). Here, we introduce all the
code related to the examples presented in the paper and more
numerical experiments not discussed in the paper itself.

To help you finding your way through all the examples presented in this online
appendix, below please find a list of links to the examples discussed
in the paper:

- [Cauchy: A distribution with infinite mean and variance](#cauchy)
- [Hierarchical model: Eight schools](#eightschools)
- [Appendix A: Normal distributions with additional trend, shift or scaling](#AppendixB)
- [Appendix B: More experiments with the Cauchy distribution](#AppendixC)
- [Appendix C: A centered eight schools model with very long chains and thinning](#AppendixD)
- [Appendix D: A centered eight schools model fit using a Gibbs sampler](#AppendixE)

# Examples

In this section, we will go through some examples to demonstrate the
usefulness of our proposed methods as well as the associated workflow
in determining convergence. [Appendices A-D](#AppendixA) contain more
detailed analysis of different algorithm variants and further examples.

First, we load all the necessary R packages and additional functions.

```{r, comment=NA, message=FALSE, warning=FALSE, results='hide', cache=FALSE}
library(tidyverse)
library(gridExtra)
library(rstan)
options(mc.cores = parallel::detectCores())
rstan_options(auto_write = TRUE)
library(bayesplot)
theme_set(bayesplot::theme_default(base_family = "sans"))
library(rjags)
library(abind)
source('monitornew.R')
source('monitorplot.R')
```

## Cauchy: A distribution with infinite mean and variance {#cauchy}

This section relates to the examples presented in Section 5.1 of the paper. 

Traditional $\widehat{R}$ is based on calculating within and between
chain variances. If the marginal distribution of a chain is such that the
variance is infinite, this approach is
not well justified, as we demonstrate here with a Cauchy-distributed example.
The following Cauchy models are from Michael Betancourt's case study
[Fitting The Cauchy Distribution](https://betanalpha.github.io/assets/case_studies/fitting_the_cauchy.html).
[Appendix B](#AppendixB) contains more detailed analysis of different algorithm
variants and further Cauchy examples.

### Nominal parameterization of Cauchy

The nominal Cauchy model with direct parameterization is as follows:

```{r}
writeLines(readLines("cauchy_nom.stan"))
```

#### Default Stan options

Run the nominal model:
```{r fit_nom, cache=TRUE, comment=NA, results='hide'}
fit_nom <- stan(file = 'cauchy_nom.stan', seed = 7878, refresh = 0)
```

We get HMC specific diagnostic [@betancourt2017conceptual] warnings
about a very large number of transitions after warmup that exceed the
maximum treedepth and low estimated Bayesian fraction of missing
information, indicating slow mixing likely due to very long tails of
the Cauchy distribution.

```{r}
mon <- monitor(fit_nom)
print(mon)
which_min_ess <- which.min(mon[1:50, 'Tail_ESS'])
```

Several values of Rhat greater than 1.01 and some ESS less than 400 also indicate convergence propblems. The [Appendix B](#AppendixB) contains more results
with longer chains.

We can further analyze potential problems using local efficiency and
rank plots. We specifically investigate x[`r which_min_ess`], which, in this specific run, had the
smallest tail-ESS of `r round(min(mon[,'Tail_ESS']), 2)`. 

We examine the sampling efficiency in different parts of the posterior by
computing the efficiency of small interval probability estimates (see
Section 4.3 in the paper). Each interval contains $1/k$ of the draws
(e.g., $5\%$ each, if $k=20$). The small interval efficiency measures mixing of
an function which indicates when the values are inside or outside the specific
small interval. As detailed above, this gives us a local efficiency measure
which does not depend on the shape of the distribution.

```{r}
plot_local_ess(fit = fit_nom, par = which_min_ess, nalpha = 20)
```

The efficiency of sampling is low in the tails, which is clearly
caused by slow mixing in long tails of the Cauchy distribution.  
Orange ticks
show iterations that exceeded the maximum treedepth.

An alternative way to examine the efficiency in different parts of the
posterior is to compute efficiency estimates for quantiles (see Section
4.3 in the paper). Each interval has a
specified proportion of draws, and the efficiency measures mixing of a function
which indicates when the values are smaller than or equal to the corresponding
quantile.

```{r, cache=FALSE}
plot_quantile_ess(fit = fit_nom, par = which_min_ess, nalpha = 40)
```

Similar as above, we see that the efficiency of sampling is low in the tails.
Orange ticks show iterations that exceeded the maximum treedepth.

We may also investigate how the estimated effective sample sizes
change when we use more and more draws; @Brooks+Gelman:1998 proposed
to use similar graph for $\widehat{R}$. If the effective sample size
is highly unstable, does not increase proportionally with more draws,
or even decreases, this indicates that simply running longer chains
will likely not solve the convergence issues.  In the plot below, we
see how unstable both bulk-ESS and tail-ESS are for this example.

```{r, cache=FALSE}
plot_change_ess(fit = fit_nom, par = which_min_ess)
```

We can further analyze potential problems using rank plots which
clearly show the mixing problem between chains. In case of good mixing
all rank plots should be close to uniform.

```{r}
samp <- as.array(fit_nom)
xmin <- paste0("x[", which_min_ess, "]")
mcmc_hist_r_scale(samp[, , xmin])
```


### Alternative parameterization of Cauchy

Next, we examine an alternative parameterization  of the
Cauchy as a scale mixture of Gaussians. The model has two
parameters, and the Cauchy distributed $x$ can be computed deterministically from those. In
addition to improved sampling performance, the example illustrates that focusing
on diagnostics matters.

```{r}
writeLines(readLines("cauchy_alt_1.stan"))
```

Run the alternative model:

```{r fit_alt1, cache=TRUE, comment=NA, results='hide'}
fit_alt1 <- stan(file = 'cauchy_alt_1.stan', seed = 7878, refresh = 0)
```

There are no warnings, and the sampling is much faster.

```{r, cache=FALSE}
mon <- monitor(fit_alt1)
print(mon)
which_min_ess <- which.min(mon[101:150, 'Tail_ESS'])
```

For all parameters, Rhat is less than 1.01 and ESS exceeds 400, indicating that sampling worked much better
with this alternative parameterization. [Appendix B](#AppendixB) has
more results using other parameterizations of the Cauchy distribution. The vectors `x_a` and
`x_b` used to form the Cauchy-distributed `x` have stable quantile,
mean and sd values. The quantiles of each `x_j` are stable too, but the mean and variance estimates are widely varying.

We can further analyze potential problems using local efficiency estimates and
rank plots. For this example. we take a detailed look at x[`r which_min_ess`], which had the 
smallest bulk-ESS of `r round(mon[which_min_ess, 'Tail_ESS'], 2)`.

We examine the sampling efficiency in different parts of the
posterior by computing the efficiency estimates for small interval
probability estimates.

```{r}
plot_local_ess(fit = fit_alt1, par = which_min_ess + 100, nalpha = 20)
```

The efficiency estimate is good in all parts of the posterior. Further, we 
examine the sampling efficiency of different quantile estimates.

```{r}
plot_quantile_ess(fit = fit_alt1, par = which_min_ess + 100, nalpha = 40)
```

The rank plots also look close to
uniform across chains, which is consistent with good mixing.

```{r}
samp <- as.array(fit_alt1)
xmin <- paste0("x[", which_min_ess, "]")
mcmc_hist_r_scale(samp[, , xmin])
```

In summary, the alternative parameterization produces results that look much
better than for the nominal parameterization. There are still some differences
in the tails, which we also identified via the tail-ESS.


### Half-Cauchy with nominal parameterization

Half-Cauchy priors for non-negative parameters are common and, at least in Stan, 
usually specified via the nominal parameterization. In this example, we set independent half-Cauchy distributions on each element
of the 50-dimensional vector $x$ constrained to be positive
(in Stan, `<lower=0>`).  Stan then
automatically switches to the unconstrained `log(x)` space, which changes the geometry
crucially.

```{r}
writeLines(readLines("half_cauchy_nom.stan"))
```

Run the half-Cauchy with nominal parameterization and positive constraint:

```{r fit_half_nom, cache=TRUE, comment=NA, results='hide'}
fit_half_nom <- stan(file = 'half_cauchy_nom.stan', seed = 7878, refresh = 0)
```

There are no warnings, and the sampling is much faster than for the
Cauchy nominal model without the constraint.

```{r, cache=FALSE}
mon <- monitor(fit_half_nom)
print(mon)
```

All values of Rhat are less than 1.01 and ESS exceeds 400 for all
parameters, indicating good performance of the sampler despite using
the nominal parameterization of the Cauchy distribution.  More
experiments with the half-Cauchy distribution can be found in
[Appendix B](#AppendixB).


## Hierarchical model: Eight Schools {#eightschools}

This section relates to the examples presented in Section 5.2 of the paper. 

The Eight Schools data is a classic example for hierarchical models [see Section
5.5 in @BDA3], which even in its simplicity illustrates
the typical problems in inference for hierarchical models. The Stan
models are adapted from Michael Betancourt's case study on [Diagnosing
Biased Inference with
Divergences](http://mc-stan.org/users/documentation/case-studies/divergences_and_bias.html).
[Appendix C](#AppendixC) contains more detailed analysis of different algorithm variants.

### A Centered Eight Schools model

```{r, comment=NA}
writeLines(readLines("eight_schools_cp.stan"))
```

#### Centered Eight Schools model

We directly run the centered parameterization model with an increased
`adapt_delta` value to reduce the probability of getting divergent
transitions.
```{r fit_cp, cache=TRUE, comment=NA, results='hide'}
eight_schools <- read_rdump("eight_schools.data.R")
fit_cp <- stan(
  file = 'eight_schools_cp.stan', data = eight_schools,
  iter = 2000, chains = 4, seed = 483892929, refresh = 0,
  control = list(adapt_delta = 0.95)
)
```

Still, we observe a lot of
divergent transitions, which in itself is already sufficient indicator
of convergence problems.  We can use Rhat and ESS diagnostics to
recognize problematic parts of the posterior. The latter
two have the advantage over the divergent transitions diagnostic that they
can be used with all MCMC algorithms not only with HMC.

```{r, cache=FALSE}
mon <- monitor(fit_cp)
print(mon)
```

See [Appendix C](#AppendixC) for results of longer chains.

Bulk-ESS and Tail-ESS for the between school standard deviation `tau`
are `r mon['tau', 'Bulk_ESS']` and `r mon['tau', 'Tail_ESS']`
respectively. Both are much less than 400, indicating we should investigate that
parameter more carefully.  We thus examine the sampling efficiency in
different parts of the posterior by computing the efficiency estimate
for small interval estimates for `tau`. These plots may either show
quantiles or parameter values at the vertical axis. Red ticks show
divergent transitions.

```{r}
plot_local_ess(fit = fit_cp, par = "tau", nalpha = 20)
```

```{r}
plot_local_ess(fit = fit_cp, par = "tau", nalpha = 20, rank = FALSE)
```

We see that the sampler has difficulties in exploring small `tau` values. As
the sampling efficiency for estimating small `tau` values is practically zero,
we may assume that we miss substantial amount of posterior mass
and get biased estimates. Red ticks, which show iterations with divergences,
have concentrated to small `tau` values, which gives us another indication
of problems in exploring small values.

We examine also the sampling efficiency of different quantile estimates. Again,
these plots may either show quantiles or parameter values at the vertical axis.

```{r}
plot_quantile_ess(fit = fit_cp, par = "tau", nalpha = 40)
```

```{r}
plot_quantile_ess(fit = fit_cp, par = "tau", nalpha = 40, rank = FALSE)
```

Most of the quantile estimates have worryingly low effective sample size.

Next we examine how the estimated effective sample size changes when we use
more and more draws. Here we do not see sudden changes, but both
bulk-ESS and tail-ESS are consistently low. See [Appendix C](#AppendixC) for
results of longer chains.

```{r, cache=FALSE}
plot_change_ess(fit = fit_cp, par = "tau")
```

In line with the other findings, rank plots of `tau` clearly show problems
in the mixing of the chains. In particular, the rank plot for the first chain indicates that it was unable to 
explore the lower-end of the posterior range, while the spike in the rank plot 
for chain 2 indicates that it spent too much time stuck in these values.

```{r}
samp_cp <- as.array(fit_cp)
mcmc_hist_r_scale(samp_cp[, , "tau"])
```


### Non-centered Eight Schools model

For hierarchical models, the non-centered parameterization often works better
than the centered one:

```{r, comment=NA}
writeLines(readLines("eight_schools_ncp.stan"))
```

For reasons of comparability, we also run the non-centered parameterization 
model with an increased `adapt_delta` value:

```{r fit_ncp2, cache=TRUE, comment=NA, results='hide'}
fit_ncp2 <- stan(
  file = 'eight_schools_ncp.stan', data = eight_schools,
  iter = 2000, chains = 4, seed = 483892929, refresh = 0,
  control = list(adapt_delta = 0.95)
)
```

We get zero divergences and no other warnings which is a first good sign.

```{r, cache=FALSE}
mon <- monitor(fit_ncp2)
print(mon)
```

All Rhat < 1.01 and ESS > 400 indicate a much better performance of the
non-centered parameterization.

We examine the sampling efficiency in different parts of the
posterior by computing the effective sample size for small interval
probability estimates for `tau`.

```{r}
plot_local_ess(fit = fit_ncp2, par = 2, nalpha = 20)
```

Small `tau` values are still more difficult to explore, but the relative
efficiency is good. We may also check this with a finer resolution:

```{r}
plot_local_ess(fit = fit_ncp2, par = 2, nalpha = 50)
```

The sampling efficiency for different quantile estimates looks good as well.

```{r}
plot_quantile_ess(fit = fit_ncp2, par = 2, nalpha = 40)
```

The rank plots of `tau` show no substantial differences between chains.

```{r}
samp_ncp2 <- as.array(fit_ncp2)
mcmc_hist_r_scale(samp_ncp2[, , 2])
```


# References {.unnumbered}

<div id="refs"></div>


# Appendices {.unnumbered}

The following abbreviations are used throughout the appendices:

 - N = total number of draws
 - Rhat = classic no-split-Rhat
 - sRhat = classic split-Rhat
 - zsRhat = rank-normalized split-Rhat
    + all chains are jointly ranked and z-transformed
    + can detect differences in location and trends
 - zfsRhat = rank-normalized folded split-Rhat
    + all chains are jointly "folded" by computing absolute deviation
      from median, ranked and z-transformed
    + can detect differences in scales
 - seff = no-split effective sample size
 - reff = seff / N
 - zsseff = rank-normalized split effective sample size
    + estimates the efficiency of mean estimate for rank normalized values
 - zsreff = zsseff / N
 - zfsseff = rank-normalized folded split effective sample size
    + estimates the efficiency of rank normalized *mean* absolute deviation
 - zfsreff = zfsseff / N
 - tailseff = minimum of rank-normalized split effective sample sizes of 
 the 5% and 95% quantiles
 - tailreff = tailseff / N
 - medsseff = median split effective sample size
    + estimates the efficiency of the median
 - medsreff = medsseff / N
 - madsseff = mad split effective sample size
    + estimates the efficiency of the median absolute deviation
 - madsreff = madsseff / N


## Appendix A: Normal distributions with additional trend, shift or scaling {#AppendixA .unnumbered}

This part focuses on diagnostics for

 - all chains having a trend and a similar marginal distribution
 - one of the chains having a different mean
 - one of the chains having a lower marginal variance
 
To simplify, in this part, independent draws are used as a proxy for very
efficient MCMC sampling. First, we sample draws from a standard-normal 
distribution. We will discuss the behavior for non-normal distributions later.
See [Appendix A](#AppendixA) for the abbreviations used.

### Adding the same trend to all chains {.unnumbered}

All chains are from the same Normal(0, 1) distribution plus a linear trend 
added to all chains:

```{r}
conds <- expand.grid(
  iters = c(250, 1000, 4000), 
  trend = c(0, 0.25, 0.5, 0.75, 1),
  rep = 1:10
)
res <- vector("list", nrow(conds))
chains = 4
for (i in 1:nrow(conds)) {
  iters <- conds[i, "iters"]
  trend <- conds[i, "trend"]
  rep <- conds[i, "rep"]
  r <- array(rnorm(iters * chains), c(iters, chains))
  r <- r + seq(-trend, trend, length.out = iters)
  rs <- as.data.frame(monitor_extra(r))
  res[[i]] <- cbind(iters, trend, rep, rs)
}
res <- bind_rows(res)
```

If we don't split chains, Rhat misses the trends if all chains still have a
similar marginal distribution.

```{r}
ggplot(data = res, aes(y = Rhat, x = trend)) + 
  geom_point() + 
  geom_jitter() + 
  facet_grid(. ~ iters) + 
  geom_hline(yintercept = 1.005, linetype = 'dashed') + 
  geom_hline(yintercept = 1) + 
  ggtitle('Rhat without splitting chains')
```

Split-Rhat can detect trends, even if the marginals of the chains are similar.
```{r}
ggplot(data = res, aes(y = zsRhat, x = trend)) + 
  geom_point() + geom_jitter() + 
  facet_grid(. ~ iters) + 
  geom_hline(yintercept = 1.005, linetype = 'dashed') + 
  geom_hline(yintercept = 1) + 
  ggtitle('Split-Rhat')
```

**Result:** Split-Rhat is useful for detecting non-stationarity (i.e., trends)
in the chains. If we use a threshold of $1.01$, we can detect trends which
account for 2% or more of the total marginal variance. If we use a threshold of
$1.1$, we detect trends which account for 30% or more of the total marginal
variance.

The effective sample size is based on split Rhat and within-chain
autocorrelation. We plot the relative efficiency $R_{\rm eff}=S_{\rm eff}/S$ 
for easier comparison between different values of $S$. In the plot below,
dashed lines indicate the threshold at which we would consider the effective
sample size to be sufficient (i.e., $S_{\rm eff} > 400$). Since we plot
the relative efficiency instead of the effective sample size itself,
this threshold is divided by $S$, which we compute here as the number of
iterations per chain (variable `iter`) times the number of chains ($4$).

```{r}
ggplot(data = res, aes(y = zsreff, x = trend)) + 
  geom_point() + 
  geom_jitter() + 
  facet_grid(. ~ iters) + 
  geom_hline(yintercept = c(0,1)) + 
  geom_hline(aes(yintercept = 400 / (4 * iters)), linetype = 'dashed') + 
  ggtitle('Relative Bulk-ESS (zsreff)') + 
  scale_y_continuous(breaks = seq(0, 1.5, by = 0.25))
```

**Result:** Split-Rhat is more sensitive to trends for small sample
sizes, but effective sample size becomes more sensitive for larger samples
sizes (as autocorrelations can be estimated more accurately).

**Advice:** If in doubt, run longer chains for more accurate convergence 
diagnostics.

### Shifting one chain {.unnumbered}

Next we investigate the sensitivity to detect if one of the chains has
not converged to the same distribution as the others, but has a different mean.

```{r}
conds <- expand.grid(
  iters = c(250, 1000, 4000), 
  shift = c(0, 0.25, 0.5, 0.75, 1),
  rep = 1:10
)
res <- vector("list", nrow(conds))
chains = 4
for (i in 1:nrow(conds)) {
  iters <- conds[i, "iters"]
  shift <- conds[i, "shift"]
  rep <- conds[i, "rep"]
  r <- array(rnorm(iters * chains), c(iters, chains))
  r[, 1] <- r[, 1] + shift
  rs <- as.data.frame(monitor_extra(r))
  res[[i]] <- cbind(iters, shift, rep, rs)
}
res <- bind_rows(res)
```

```{r}
ggplot(data = res, aes(y = zsRhat, x = shift)) + 
  geom_point() + 
  geom_jitter() + 
  facet_grid(. ~ iters) + 
  geom_hline(yintercept = 1.005, linetype = 'dashed') + 
  geom_hline(yintercept = 1) + 
  ggtitle('Split-Rhat')
```

**Result:** If we use a threshold of $1.01$, we can detect shifts with
a magnitude of one third or more of the marginal standard deviation. If we use
a threshold of $1.1$, we detect shifts with a magnitude equal to or larger 
than the marginal standard deviation.

```{r}
ggplot(data = res, aes(y = zsreff, x = shift)) + 
  geom_point() +
  geom_jitter() + 
  facet_grid(. ~ iters) + 
  geom_hline(yintercept = c(0,1)) + 
  geom_hline(aes(yintercept = 400 / (4 * iters)), linetype = 'dashed') + 
  ggtitle('Relative Bulk-ESS (zsreff)') + 
  scale_y_continuous(breaks = seq(0, 1.5, by = 0.25))
```

**Result:** The effective sample size is not as sensitive, but a shift
with a magnitude of half the marginal standard deviation or more will lead to
very low relative efficiency when the total number of draws increases.

Rank plots can be used to visualize differences between chains. Here, we show 
rank plots for the case of 4 chains, 250 draws per chain, and a shift of 0.5.

```{r}
iters = 250
chains = 4
shift = 0.5
r <- array(rnorm(iters * chains), c(iters, chains))
r[, 1] <- r[, 1] + shift
colnames(r) <- 1:4
mcmc_hist_r_scale(r)
```

<!--
add guidelines for uniformity as in
https://betanalpha.github.io/assets/case_studies/principled_bayesian_workflow.html
-->

Although, Rhat was less than $1.05$ for this situation, the rank plots clearly 
show that the first chains behaves differently.

### Scaling one chain {.unnumbered}

Next, we investigate the sensitivity to detect if one of the chains has
not converged to the same distribution as the others, but has lower
marginal variance.

```{r, cache=FALSE}
conds <- expand.grid(
  iters = c(250, 1000, 4000), 
  scale = c(0, 0.25, 0.5, 0.75, 1),
  rep = 1:10
)
res <- vector("list", nrow(conds))
chains = 4
for (i in 1:nrow(conds)) {
  iters <- conds[i, "iters"]
  scale <- conds[i, "scale"]
  rep <- conds[i, "rep"]
  r <- array(rnorm(iters * chains), c(iters, chains))
  r[, 1] <- r[, 1] * scale
  rs <- as.data.frame(monitor_extra(r))
  res[[i]] <- cbind(iters, scale, rep, rs)
}
res <- bind_rows(res)
```

We first look at the Rhat estimates:

```{r}
ggplot(data = res, aes(y = zsRhat, x = scale)) + 
  geom_point() + 
  geom_jitter() + 
  facet_grid(. ~ iters) + 
  geom_hline(yintercept = 1.005, linetype = 'dashed') + 
  geom_hline(yintercept = 1) + 
  ggtitle('Split-Rhat')
```

**Result:** Split-Rhat is not able to detect scale differences between chains.

```{r}
ggplot(data = res, aes(y = zfsRhat, x = scale)) + 
  geom_point() + 
  geom_jitter() + 
  facet_grid(. ~ iters) + 
  geom_hline(yintercept = 1.005, linetype = 'dashed') + 
  geom_hline(yintercept = 1) + 
  ggtitle('Folded-split-Rhat')
```

**Result:** Folded-Split-Rhat focuses on scales and detects
scale differences.

**Result:** If we use a threshold of $1.01$, we can detect a chain with scale
less than $3/4$ of the standard deviation of the others. If we use threshold 
of $1.1$, we detect a chain with standard deviation less than $1/4$ of 
the standard deviation of the others.

Next, we look at the effective sample size estimates:

```{r}
ggplot(data = res, aes(y = zsreff, x = scale)) + 
  geom_point() + 
  geom_jitter() + 
  facet_grid(. ~ iters) + 
  geom_hline(yintercept = c(0,1)) + 
  geom_hline(aes(yintercept = 400 / (4 * iters)), linetype = 'dashed') + 
  ggtitle('Relative Bulk-ESS (zsreff)') + 
  scale_y_continuous(breaks = seq(0, 1.5, by = 0.25))
```

**Result:** The bulk effective sample size of the mean does not see a
problem as it focuses on location differences between chains.

Rank plots can be used to visualize differences between chains. Here, we show
rank plots for the case of 4 chains, 250 draws per chain, and with one chain
having a standard deviation of 0.75 as opposed to a standard deviation of 1 for
the other chains.

```{r}
iters = 250
chains = 4
scale = 0.75
r <- array(rnorm(iters * chains), c(iters, chains))
r[, 1] <- r[, 1] * scale
colnames(r) <- 1:4
mcmc_hist_r_scale(r)
```

Although folded Rhat is $1.06$, the rank plots clearly show that the first
chains behaves differently.


## Appendix B: More experiments with the Cauchy distribution {#AppendixB .unnumbered}

The classic split-Rhat is based on calculating within and between chain
variances. If the marginal distribution of a chain is such that
the variance is not defined (i.e. infinite), the classic split-Rhat is not 
well justified. In this section, we will use the Cauchy distribution 
as an example of such distribution. Also in cases where
mean and variance are finite, the distribution can be far from
Gaussian. Especially distributions with very long tails cause
instability for variance and autocorrelation estimates. To alleviate
these problems we will use Split-Rhat for rank-normalized draws. 

The following Cauchy models are from Michael Betancourt's case study
[Fitting The Cauchy Distribution](https://betanalpha.github.io/assets/case_studies/fitting_the_cauchy.html)

### Nominal parameterization of Cauchy {.unnumbered}

We already looked at the nominal Cauchy model with direct
parameterization in the main text, but for completeness, we take a
closer look using different variants of the diagnostics.

```{r}
writeLines(readLines("cauchy_nom.stan"))
```

#### Default Stan options {.unnumbered}

Run the nominal model:
```{r fit_nom_extra, cache=TRUE, comment=NA, results='hide'}
fit_nom <- stan(file = 'cauchy_nom.stan', seed = 7878, refresh = 0)
```

Treedepth exceedence and Bayesian Fraction of Missing Information are
dynamic HMC specific diagnostics [@betancourt2017conceptual]. We get
warnings about very large number of transitions after
warmup that exceeded the maximum treedepth, which is likely due to
very long tails of the Cauchy distribution. All chains have low 
estimated Bayesian fraction of missing information also indicating
slow mixing.

Trace plots for the first parameter look wild with occasional large values:

```{r}
samp <- as.array(fit_nom) 
mcmc_trace(samp[, , 1])
```

Let's check Rhat and ESS diagnostics.

```{r}
res <- monitor_extra(samp[, , 1:50])
which_min_ess <- which.min(res$tailseff)
plot_rhat(res)
```

For one parameter, Rhats exceed the classic threshold of 1.1. Depending on the
Rhat estimate, a few others also exceed the threshold of 1.01. The rank
normalized split-Rhat has several values over 1.01. Please note that the classic
split-Rhat is not well defined in this example, because mean and variance of 
the Cauchy distribution are not finite.

```{r, warning=FALSE}
plot_ess(res) 
```

Both classic and new effective sample size estimates have several very
small values, and so the overall sample shouldn't be trusted.

**Result:** Effective sample size is more sensitive than (rank-normalized) 
split-Rhat to detect problems of slow mixing.

We also check the log posterior value `lp__` and find out that the effective
sample size is worryingly low.

```{r}
res <- monitor_extra(samp[, , 51:52]) 
cat('lp__: Bulk-ESS = ', round(res['lp__', 'zsseff'], 2), '\n')
cat('lp__: Tail-ESS = ', round(res['lp__', 'tailseff'], 2), '\n')
```

We can further analyze potential problems using local effective sample size 
and rank plots. We examine x[`r which_min_ess`], which has
the smallest tail-ESS of `r round(min(res$zsseff), 2)`.

We examine the sampling efficiency in different parts of the
posterior by computing the effective sample size for small interval
probability estimates (see Section 4.3 in the paper).  Each
interval contains $1/k$ of the draws (e.g., with $k=20$).
The small interval efficiency measures mixing of an indicator
function which indicates when the values are inside the specific
small interval. This gives us a local efficiency measure which does not
depend on the shape of the distribution.

```{r}
plot_local_ess(fit = fit_nom, par = which_min_ess, nalpha = 20)
```

We see that the efficiency is worryingly low in the tails
(which is caused by slow mixing in long tails of Cauchy). Orange ticks
show draws that exceeded the maximum treedepth.

An alternative way to examine the effective sample size in different parts
of the posterior is to compute effective sample size for quantiles (see
[Section Efficiency for quantiles](#quantile_S_eff)). Each
interval has a specified proportion of draws, and the efficiency measures
mixing of an indicator function's results which indicate when the
values are inside the specific interval. 

```{r, cache=FALSE}
plot_quantile_ess(fit = fit_nom, par = which_min_ess, nalpha = 40)
```

We see that the efficiency is worryingly low in the tails
(which is caused by slow mixing in long tails of Cauchy). Orange ticks
show draws that exceeded the maximum treedepth.

We can further analyze potential problems using rank plots,
from which we clearly see differences between chains.

```{r}
xmin <- paste0("x[", which_min_ess, "]")
mcmc_hist_r_scale(samp[, , xmin])
```


#### Default Stan options + increased maximum treedepth {.unnumbered}

We can try to improve the performance by increasing `max_treedepth` to $20$: 

```{r fit_nom_td20, cache=TRUE, comment=NA, results='hide'}
fit_nom_td20 <- stan(
  file = 'cauchy_nom.stan', seed = 7878, 
  refresh = 0, control = list(max_treedepth = 20)
)
```

Trace plots for the first parameter still look wild with occasional large 
values.

```{r}
samp <- as.array(fit_nom_td20)
mcmc_trace(samp[, , 1])
```

```{r}
res <- monitor_extra(samp[, , 1:50])
which_min_ess <- which.min(res$tailseff)
```

We check the diagnostics for all $x$.

```{r}
plot_rhat(res)
```

All Rhats are below $1.1$, but many are over $1.01$. Classic split-Rhat has more
variation than the rank normalized Rhat (note that the former is not well
defined). The folded rank normalized Rhat shows that there is still
more variation in the scale than in the location between different chains.

```{r, warning=FALSE}
plot_ess(res) 
```

Some classic effective sample sizes are very small. If we wouldn't realize
that the variance is infinite, we might try to run longer chains, but in case of
an infinite variance, zero relative efficiency  (ESS/S) is the truth and longer chains won't help
with that. However other quantities can be well defined, and that's why it is
useful to also look at the rank normalized version as a generic transformation
to achieve finite mean and variance. The smallest bulk-ESS is less than 1000,
which is not that bad. The smallest median-ESS is larger than 2500, that is we
are able to estimate the median efficiently. However, many tail-ESS's are less than 400
indicating problems for estimating the scale of the posterior.

**Result:** The rank normalized effective sample size is more stable than
classic effective sample size, which is not well defined for the Cauchy 
distribution.

**Result:** It is useful to look at both bulk- and tail-ESS.

We check also `lp__`. Although increasing `max_treedepth` improved
bulk-ESS of `x`, the efficiency for `lp__` didn't change.

```{r}
res <- monitor_extra(samp[, , 51:52])
cat('lp__: Bulk-ESS =', round(res['lp__', 'zsseff'], 2), '\n')
cat('lp__: Tail-ESS =', round(res['lp__', 'tailseff'], 2), '\n')
```

We examine the sampling efficiency in different parts of the
posterior by computing the effective sample size for small interval
probability estimates.

```{r}
plot_local_ess(fit = fit_nom_td20, par = which_min_ess, nalpha = 20)
```

It seems that increasing `max_treedepth` has not much improved the efficiency 
in the tails. We also examine the effective sample size of different quantile 
estimates.

```{r}
plot_quantile_ess(fit = fit_nom_td20, par = which_min_ess, nalpha = 40)
```

The rank plot visualisation of x[`r which_min_ess`], which has the smallest
tail-ESS of `r round(min(res$tailseff))` among the $x$, indicates 
clear convergence problems.

```{r}
xmin <- paste0("x[", which_min_ess, "]")
mcmc_hist_r_scale(samp[, , xmin])
```

The rank plot visualisation of `lp__`, which has an effective sample size 
`r round(monitor_extra(samp[,, "lp__"])$zsseff)`, doesn't look so good either.

```{r}
mcmc_hist_r_scale(samp[, , "lp__"])
```

#### Default Stan options + increased maximum treedepth + longer chains {.unnumbered}

Let's try running 8 times longer chains.

```{r fit_nom_td20l, cache=TRUE, comment=NA, results='hide'}
fit_nom_td20l <- stan(
  file = 'cauchy_nom.stan', seed = 7878, 
  refresh = 0, control = list(max_treedepth = 20), 
  warmup = 1000, iter = 9000
)
```

Trace plots for the first parameter still look wild with occasional large 
values.

```{r}
samp <- as.array(fit_nom_td20l)
mcmc_trace(samp[, , 1])
```

```{r}
res <- monitor_extra(samp[, , 1:50])
which_min_ess <- which.min(res$tailseff)
```

Let's check the diagnostics for all $x$.

```{r}
plot_rhat(res)
```

All Rhats are below $1.01$. The classic split-Rhat has more variation than the
rank normalized Rhat (note that the former is not well defined in this case).

```{r, warning=FALSE}
plot_ess(res) 
```

Most classic ESS's are close to zero. Running longer chains just made 
most classic ESS's even smaller.

The smallest bulk-ESS are around 5000, which is not that
bad. The smallest median-ESS's are larger than 25000, that
is we are able to estimate the median efficiently. However, the smallest
tail-ESS is `r round(min(res$tailseff), 2)` indicating problems for estimating the
scale of the posterior.

**Result:** The rank normalized effective sample size is more stable than
classic effective sample size even for very long chains.

**Result:** It is useful to look at both bulk- and tail-ESS.

We also check `lp__`. Although increasing the number of iterations improved
bulk-ESS of the $x$, the relative efficiency for `lp__` didn't change.

```{r}
res <- monitor_extra(samp[, , 51:52])
cat('lp__: Bulk-ESS =', round(res['lp__', 'zsseff'], 2), '\n')
cat('lp__: Tail-ESS =', round(res['lp__', 'tailseff'], 2), '\n')
```

We examine the sampling efficiency in different parts of the
posterior by computing the effective sample size for small interval
probability estimates.

```{r}
plot_local_ess(fit = fit_nom_td20l, par = which_min_ess, nalpha = 20)
```

Increasing the chain length did not seem to change the relative
efficiency. With more draws from the longer chains we can use
a finer resolution for the local efficiency estimates.

```{r}
plot_local_ess(fit = fit_nom_td20l, par = which_min_ess, nalpha = 100)
```

The sampling efficiency far in the tails is worryingly low. This was more
difficult to see previously with less draws from the tails. We see
similar problems in the plot of effective sample size for quantiles.

```{r}
plot_quantile_ess(fit = fit_nom_td20l, par = which_min_ess, nalpha = 100)
```

Let's look at the rank plot visualisation of x[`r which_min_ess`], which has 
the smallest tail-ESS `r round(min(res$tailseff), 2)` among the $x$.

```{r}
xmin <- paste0("x[", which_min_ess, "]")
mcmc_hist_r_scale(samp[, , xmin])
```

Increasing the number of iterations couldn't remove the mixing
problems at the tails. The mixing problem is inherent to the nominal 
parameterization of Cauchy distribution.

### First alternative parameterization of the Cauchy distribution {.unnumbered}

Next, we examine an alternative parameterization and consider the Cauchy
distribution as a scale mixture of Gaussian distributions. The model has two
parameters and the Cauchy distributed $x$ can be computed from those. In
addition to improved sampling performance, the example illustrates that focusing
on diagnostics matters.

```{r}
writeLines(readLines("cauchy_alt_1.stan"))
```

We run the alternative model:

```{r fit_alt1_extra, cache=TRUE, comment=NA, results='hide'}
fit_alt1 <- stan(file='cauchy_alt_1.stan', seed=7878, refresh = 0)
```

There are no warnings and the sampling is much faster.

```{r}
samp <- as.array(fit_alt1)
res <- monitor_extra(samp[, , 101:150])
which_min_ess <- which.min(res$tailseff)
```

```{r}
plot_rhat(res)
```

All Rhats are below $1.01$. Classic split-Rhats also look good even though 
they are not well defined for the Cauchy distribution.

```{r, warning=FALSE}
plot_ess(res) 
```

**Result:** Rank normalized ESS's have less variation than classic 
one which is not well defined for Cauchy.

We check `lp__`:
```{r}
res <- monitor_extra(samp[, , 151:152])
cat('lp__: Bulk-ESS =', round(res['lp__', 'zsseff'], 2), '\n')
cat('lp__: Tail-ESS =', round(res['lp__', 'tailseff'], 2), '\n')
```

The relative efficiencies for `lp__` are also much better than with the
nominal parameterization.

We examine the sampling efficiency in different parts of the
posterior by computing the effective sample size for small interval
probability estimates.

```{r}
plot_local_ess(fit = fit_alt1, par = 100 + which_min_ess, nalpha = 20)
```

The effective sample size is good in all parts of the posterior. We also examine 
the effective sample size of different quantile estimates.

```{r}
plot_quantile_ess(fit = fit_alt1, par = 100 + which_min_ess, nalpha = 40)
```

We compare the mean relative efficiencies of the underlying parameters in the 
new parameterization and the actual $x$ we are interested in.

```{r, cache=FALSE}
res <- monitor_extra(samp[, , 101:150])
res1 <- monitor_extra(samp[, , 1:50])
res2 <- monitor_extra(samp[, , 51:100])
```

```{r}
cat('Mean Bulk-ESS for x =' , round(mean(res[, 'zsseff']), 2), '\n')
cat('Mean Tail-ESS for x =' , round(mean(res[, 'tailseff']), 2), '\n')
cat('Mean Bulk-ESS for x_a =' , round(mean(res1[, 'zsseff']), 2), '\n')
cat('Mean Bulk-ESS for x_b =' , round(mean(res2[, 'zsseff']), 2), '\n')
```

**Result:** We see that the effective sample size of the interesting $x$
can be different from the effective sample size of the parameters $x_a$
and $x_b$ that we used to compute it.

The rank plot visualisation of x[`r which_min_ess`], which has the smallest
tail-ESS of `r round(min(res$tailseff), 2)` among the $x$ looks better
than for the nominal parameterization.

```{r}
xmin <- paste0("x[", which_min_ess, "]")
mcmc_hist_r_scale(samp[, , xmin])
```

Similarly, the rank plot visualisation of `lp__`, which has a relative
efficiency of `r round(monitor_extra(samp[,, "lp__"]), 2)` looks better than for
the nominal parameterization.

```{r}
mcmc_hist_r_scale(samp[, , "lp__"])
```

### Another alternative parameterization of the Cauchy distribution {.unnumbered}

Another alternative parameterization is obtained by a univariate transformation
as shown in the following code (see also the 3rd alternative in Michael 
Betancourt's case study).

```{r}
writeLines(readLines("cauchy_alt_3.stan"))
```

We run the alternative model:

```{r fit_alt2, cache=TRUE, comment=NA, results='hide'}
fit_alt3 <- stan(file='cauchy_alt_3.stan', seed=7878, refresh = 0)
```

There are no warnings, and the sampling is much faster than for the
nominal model.

```{r}
samp <- as.array(fit_alt3)
res <- monitor_extra(samp[, , 51:100])
which_min_ess <- which.min(res$tailseff)
```

```{r}
plot_rhat(res)
```

All Rhats except some folded Rhats are below 1.01. Classic split-Rhat's look
also good even though it is not well defined for the Cauchy distribution.

```{r, warning=FALSE}
plot_ess(res) 
```

**Result:** Rank normalized relative efficiencies have less variation than
classic ones. Bulk-ESS and median-ESS are slightly larger
than 1, which is possible for antithetic Markov chains which have negative
correlation for odd lags.

We also take a closer look at the `lp__` value:

```{r}
res <- monitor_extra(samp[, , 101:102])
cat('lp__: Bulk-ESS =', round(res['lp__', 'zsseff'], 2), '\n')
cat('lp__: Tail-ESS =', round(res['lp__', 'tailseff'], 2), '\n')
```

The effective sample size for these are also much better than with
the nominal parameterization.

We examine the sampling efficiency in different parts of the
posterior by computing the effective sample size for small interval
probability estimates.

```{r}
plot_local_ess(fit = fit_alt3, par = 50 + which_min_ess, nalpha = 20)
```

We examine also the sampling efficiency of different quantile estimates.

```{r}
plot_quantile_ess(fit = fit_alt3, par = 50 + which_min_ess, nalpha = 40)
```

The effective sample size in tails is worse than for the first
alternative parameterization, although it's still better than for the
nominal parameterization.

We compare the mean effective sample size of the underlying parameter in the new
parameterization and the actually Cauchy distributed $x$ we are interested in.

```{r}
res <- monitor_extra(samp[, , 51:100])
res1 <- monitor_extra(samp[, , 1:50])
cat('Mean bulk-seff for x =' , round(mean(res[, 'zsseff']), 2), '\n')
cat('Mean tail-seff for x =' , round(mean(res[, 'zfsseff']), 2), '\n')
cat('Mean bulk-seff for x_tilde =' , round(mean(res1[, 'zsseff']), 2), '\n')
cat('Mean tail-seff for x_tilde =' , round(mean(res1[, 'zfsseff']), 2), '\n')
```

The Rank plot visualisation of x[`r which_min_ess`], which has the smallest
tail-ESS of `r round( min(res$tailseff), 2)` among the $x$ reveals
shows good efficiency, similar to the results for `lp__`.

```{r}
xmin <- paste0("x[", which_min_ess, "]")
mcmc_hist_r_scale(samp[, , xmin])
```

```{r}
mcmc_hist_r_scale(samp[, , "lp__"])
```


### Half-Cauchy distribution with nominal parameterization {.unnumbered}

Half-Cauchy priors are common and, for example, in Stan usually set
using the nominal parameterization. However, when the constraint 
`<lower=0>` is used, Stan does the sampling automatically
in the unconstrained `log(x)` space, which changes the geometry
crucially.

```{r}
writeLines(readLines("half_cauchy_nom.stan"))
```

We run the half-Cauchy model with nominal parameterization (and positive constraint).

```{r fit_half_nom_extra, cache=TRUE, comment=NA, results='hide'}
fit_half_nom <- stan(file = 'half_cauchy_nom.stan', seed = 7878, refresh = 0)
```

There are no warnings and the sampling is much faster than for the full
Cauchy distribution with nominal parameterization.

```{r}
samp <- as.array(fit_half_nom)
res <- monitor_extra(samp[, , 1:50])
which_min_ess <- which.min(res$tailseff)
```

```{r}
plot_rhat(res) 
```

All Rhats are below $1.01$. Classic split-Rhats also look good even though they
are not well defined for the half-Cauchy distribution.

```{r, warning=FALSE}
plot_ess(res)  
```

**Result:** Rank normalized effective sample size have less variation than
classic ones. Some Bulk-ESS and median-ESS are larger than 1, which is possible
for antithetic Markov chains which have negative correlation for odd lags.

Due to the `<lower=0>` constraint, the sampling was made in the `log(x)` space,
and we can also check the performance in that space.

```{r, cache=FALSE}
res <- monitor_extra(log(samp[, , 1:50]))
```

```{r, warning=FALSE, cache=FALSE}
plot_ess(res) 
```

$\log(x)$ is quite close to Gaussian, and thus classic effective sample size is
also close to rank normalized ESS which is exactly the same as for the original
$x$ as rank normalization is invariant to bijective transformations.

**Result:** The rank normalized effective sample size is close to the classic 
effective sample size for transformations which make the distribution 
close to Gaussian.

We examine the sampling efficiency in different parts of the
posterior by computing the effective sample size for small interval
probability estimates.

```{r}
plot_local_ess(fit = fit_half_nom, par = which_min_ess, nalpha = 20)
```

The effective sample size is good overall, with only a small dip in tails. We 
can also examine the effective sample size of different quantile estimates.

```{r}
plot_quantile_ess(fit = fit_half_nom, par = which_min_ess, nalpha = 40)
```

The rank plot visualisation of x[`r which_min_ess`], which has the smallest 
tail-ESS of `r round( min(res$tailseff), 2)` among $x$, looks good.

```{r}
xmin <- paste0("x[", which_min_ess, "]")
mcmc_hist_r_scale(samp[, , xmin])
```

The rank plot visualisation of `lp__` reveals some small differences in the 
scales, but it's difficult to know whether this small variation from uniform 
is relevant.

```{r}
mcmc_hist_r_scale(samp[, , "lp__"])
```


### Alternative parameterization of the half-Cauchy distribution {.unnumbered}

```{r}
writeLines(readLines("half_cauchy_alt.stan"))
```

Run half-Cauchy with alternative parameterization
```{r fit_half_reparam, cache=TRUE, comment=NA, results='hide'}
fit_half_reparam <- stan(
  file = 'half_cauchy_alt.stan', seed = 7878, refresh = 0
)
```

There are no warnings and the sampling is as fast for the half-Cauchy
nominal model.

```{r}
samp <- as.array(fit_half_reparam)
res <- monitor_extra(samp[, , 101:150])
which_min_ess <- which.min(res$tailseff)
```

```{r}
plot_rhat(res)
```

```{r, warning=FALSE}
plot_ess(res) 
```

**Result:** The Rank normalized relative efficiencies have less variation
than classic ones which is not well defined for the Cauchy distribution.  Based on
bulk-ESS and median-ESS, the efficiency for central
quantities is much lower, but based on tail-ESS and
MAD-ESS, the efficiency in the tails is slightly better than for
the half-Cauchy distribution with nominal parameterization. We
also see that a parameterization which is good for the full Cauchy distribution 
is not necessarily good for the half-Cauchy distribution as the `<lower=0>`
constraint additionally changes the parameterization.

We also check the `lp__` values:

```{r}
res <- monitor_extra(samp[, , 151:152])
cat('lp__: Bulk-ESS =', round(res['lp__', 'zsseff'], 2), '\n')
cat('lp__: Tail-ESS =', round(res['lp__', 'tailseff'], 2), '\n')
```

We examine the sampling efficiency in different parts of the
posterior by computing the effective sample size for small interval
probability estimates.

```{r}
plot_local_ess(fit_half_reparam, par = 100 + which_min_ess, nalpha = 20)
```

We also examine the effective sample size for different quantile estimates.

```{r}
plot_quantile_ess(fit_half_reparam, par = 100 + which_min_ess, nalpha = 40)
```

The effective sample size near zero is much worse than for the
half-Cauchy distribution with nominal parameterization.

The Rank plot visualisation of x[`r which_min_ess`], which has the
smallest tail-ESS of `r round( min(res$tailseff), 2)` among the $x$,
reveals deviations from uniformity, which is expected with lower
effective sample size.

```{r}
xmin <- paste0("x[", which_min_ess, "]")
mcmc_hist_r_scale(samp[, , xmin])
```

A similar result is obtained when looking at the rank plots of `lp__`.

```{r}
mcmc_hist_r_scale(samp[, , "lp__"])
```


### The Cauchy distribution with Jags {.unnumbered}

So far, we have run all models in Stan, but we want to also investigate whether
similar problems arise with probabilistic programming languages that use other
samplers than variants of Hamiltonian Monte-Carlo. Thus, we will fit the eight
schools models also with Jags, which uses a dialect of the BUGS language to
specify models. Jags uses a clever mix of Gibbs and Metropolis-Hastings
sampling. This kind of sampling does not scale well to high dimensional
posteriors of strongly interdependent parameters, but for the relatively
simple models discussed in this case study it should work just fine.

The Jags code for the nominal parameteriztion of the cauchy distribution 
looks as follows:

```{r, comment=NA}
writeLines(readLines("cauchy_nom.bugs"))
```

First, we initialize the Jags model for reusage later.

```{r}
jags_nom <- jags.model(
  "cauchy_nom.bugs",
  n.chains = 4, n.adapt = 10000
)
```

Next, we sample 1000 iterations for each of the 4 chains for easy
comparison with the corresponding Stan results.

```{r}
samp_jags_nom <- coda.samples(
  jags_nom, variable.names = "x",
  n.iter = 1000
)
samp_jags_nom <- aperm(abind(samp_jags_nom, along = 3), c(1, 3, 2))
dimnames(samp_jags_nom)[[2]] <- paste0("chain:", 1:4)
```

We summarize the model as follows:

```{r}
mon <- monitor(samp_jags_nom)
print(mon)
which_min_ess <- which.min(mon[1:50, 'Bulk_ESS'])
```

The overall results look very promising with Rhats = 1 and ESS values close to
the total number of draws of 4000. We take a detailed look at 
x[`r which_min_ess`], which has the smallest bulk-ESS of 
`r round(mon[which_min_ess,'Bulk_ESS'], 2)`.

We examine the sampling efficiency in different parts of the
posterior by computing the efficiency estimates for small interval
probability estimates.

```{r}
plot_local_ess(fit = samp_jags_nom, par = which_min_ess, nalpha = 20)
```

The efficiency estimate is good in all parts of the posterior. Further, we 
examine the sampling efficiency of different quantile estimates.

```{r}
plot_quantile_ess(fit = samp_jags_nom, par = which_min_ess, nalpha = 40)
```

Rank plots also look rather similar across chains.

```{r}
xmin <- paste0("x[", which_min_ess, "]")
mcmc_hist_r_scale(samp_jags_nom[, , xmin])
```

**Result:** Jags seems to be able to sample from the nominal parameterization of
the Cauchy distribution just fine.


## Appendix C: A centered eight schools model with very long chains and thinning {#AppendixC .unnumbered}

We continue with our discussion about hierarchical models on the Eight Schools
data, which we started in [Section Eight Schools](#eightschools). We also analyse
the performance of different variants of the diagnostics.

### A Centered Eight Schools model {.unnumbered}

```{r, comment=NA}
writeLines(readLines("eight_schools_cp.stan"))
```

In the main text, we observed that the centered parameterization of this
hierarchical model did not work well with the default MCMC options of Stan
plus increased `adapt_delta`, and so we directly try to fit the model with 
longer chains.

#### Centered parameterization with longer chains {.unnumbered}

Low efficiency can be sometimes compensated with longer chains. Let's check
10 times longer chain.

```{r fit_cp2, cache=TRUE, comment=NA, results='hide'}
fit_cp2 <- stan(
  file = 'eight_schools_cp.stan', data = eight_schools,
  iter = 20000, chains = 4, seed = 483892929, refresh = 0,
  control = list(adapt_delta = 0.95)
)
```

```{r}
monitor(fit_cp2)
res <- monitor_extra(fit_cp2)
print(res)
```

We still get a whole bunch of divergent transitions so it's clear that the results
can't be trusted even if all other diagnostics were good. Still, it may be worth
looking at additional diagnostics to better understand what's happening. 

Some rank-normalized split-Rhats are still larger than
$1.01$. Bulk-ESS for `tau` and `lp__` are around 800 which corresponds
to low relative efficiency of $1\%$, but is above our recommendation
of ESS>400. In this kind of cases, it is useful to look at the
local efficiency estimates, too (and the larger number of divergences
is clear indication of problems, too).

We examine the sampling efficiency in different parts of the posterior by
computing the effective sample size for small intervals for `tau`.

```{r}
plot_local_ess(fit = fit_cp2, par = "tau", nalpha = 50)
```

We see that the sampling has difficulties in exploring small `tau` values.
As ESS<400 for small probability intervals in case of small `tau` values, we may
suspect that we may miss substantial amount of posterior mass and get biased
estimates.

We also examine the effective sample size of different quantile estimates.

```{r}
plot_quantile_ess(fit = fit_cp2, par = "tau", nalpha = 100)
```

Several quantile estimates have ESS<400, which raises a doubt that
there are convergence problems and we may have significant bias.

Let's see how the Bulk-ESS and Tail-ESS changes when we use
more and more draws.

```{r, cache=FALSE}
plot_change_ess(fit = fit_cp2, par = "tau")
```

We see that given recommendation that Bulk-ESS>400 and Tail-ESS>400, they are not sufficient to detect convergence problems in this case, even the tail quantile estimates are able to detect these problems.

The rank plot visualisation of `tau` also shows clear sticking and
mixing problems.

```{r}
samp_cp2 <- as.array(fit_cp2)
mcmc_hist_r_scale(samp_cp2[, , "tau"])
```

Similar results are obtained for `lp__`, which is closely connected to `tau` 
for this model.

```{r}
mcmc_hist_r_scale(samp_cp2[, , "lp__"])
```

We may also examine small interval efficiencies for `mu`.

```{r}
plot_local_ess(fit = fit_cp2, par = "mu", nalpha = 50)
```

There are gaps of poor efficiency which again indicates problems in the mixing
of the chains. However, these problems do not occur for any specific range of 
values of `mu` as was the case for `tau`. This tells us that it's probably not
`mu` with which the sampler has problems, but more likely `tau` or a related
quantity.

As we observed divergences, we shouldn't trust any Monte Carlo
standard error (MCSE) estimates as they are likely biased, as well.
However, for illustration purposes, we compute the MCSE, tail
quantiles and corresponding effective sample sizes for the median of `mu` and
`tau`. Comparing to the shorter MCMC run, using 10 times more draws has not
reduced the MCSE to one third as would be expected without problems in
the mixing of the chains.

```{r}
round(mcse_quantile(samp_cp2[ , , "mu"], prob = 0.5), 2)
round(mcse_quantile(samp_cp2[ , , "tau"], prob = 0.5), 2)
```

#### Centered parameterization with very long chains {.unnumbered}

For further evidence, let's check 100 times longer chains than the default. This
is not something we would recommend doing in practice, as it is not able to
solve any problems with divergences as illustrated below.

```{r fit_cp3, cache=TRUE, comment=NA, results='hide'}
fit_cp3 <- stan(
  file = 'eight_schools_cp.stan', data = eight_schools,
  iter = 200000, chains = 4, seed = 483892929, refresh = 0,
  control = list(adapt_delta = 0.95)
)
```

```{r}
monitor(fit_cp3)
res <- monitor_extra(fit_cp3)
print(res)
```

Rhat, Bulk-ESS and Tail-ESS are not able to detect problems, although
Tail-ESS for `tau` is suspiciously low compared to total number of draws.

```{r}
plot_local_ess(fit = fit_cp3, par = "tau", nalpha = 100)
plot_quantile_ess(fit = fit_cp3, par = "tau", nalpha = 100)
```

And the rank plots of `tau` also show sticking and mixing problems for small values of `tau`.

```{r}
samp_cp3 <- as.array(fit_cp3)
mcmc_hist_r_scale(samp_cp3[, , "tau"])
```

What we do see is an advantage of rank plots over trace plots as even
with 100000 draws per chain, rank plots don't get crowded and the
mixing problems of chains is still easy to see.

With centered parameterization the mean estimate tends to get smaller
with more draws.  With 400000 draws using the centered
parameterization the mean estimate is 3.77 (se 0.03). With 40000 draws
using the non-centered parameterization the mean estimate is 3.6 (se
0.02). The difference is more than 8 sigmas. We are able to see the
convergence problems in the centered parameterization case, if we do
look carefully (or use divergence diagnostic ), but we do see that
Rhat, Bulk-ESS, Tail-ESS and Monte Carlo error estimates for the mean
can't be trusted if other diagnostics indicate convergence problems!

#### Centered parameterization with very long chains and thinning {.unnumbered}

When autocorrelation time is high, it has been common to thin the
chains by saving only a small portion of the draws. This will throw
away useful information also for convergence diagnostics. With 400000
iterations per chain, thinning of 200 and 4 chains, we again end up
with 4000 iterations as with the default settings.

```{r fit_cp4, cache=TRUE, comment=NA, results='hide'}
fit_cp4 <- stan(
  file = 'eight_schools_cp.stan', data = eight_schools,
  iter = 400000, thin = 200, chains = 4, seed = 483892929, refresh = 0,
  control = list(adapt_delta = 0.95)
)
```

We observe several divergent transitions and the estimated Bayesian
fraction of missing information is also low, which indicate
convergence problems and potentially biased estimates.

Unfortunately the thinning makes Rhat and ESS estimates to miss the
problems. The posterior mean is still biased, being more than 3 sigmas
away from the estimate obtained using non-centered parameterization.

```{r}
monitor(fit_cp4)
res <- monitor_extra(fit_cp4)
print(res)
```

Various diagnostic plots of `tau` look reasonable as well.
```{r}
plot_local_ess(fit = fit_cp4, par = "tau", nalpha = 100)
plot_quantile_ess(fit = fit_cp4, par = "tau", nalpha = 100)
plot_change_ess(fit = fit_cp4, par = "tau")
```

However, the rank plots seem still to show the problem.

```{r}
samp_cp4 <- as.array(fit_cp4)
mcmc_hist_r_scale(samp_cp4[, , "tau"])
```

### Non-centered Eight Schools model {.unnumbered}

In the following, we want to expand our understanding of the non-centered
parameterization of the hierarchical model fit to the eight schools data.

```{r, comment=NA}
writeLines(readLines("eight_schools_ncp.stan"))
```

#### Non-centered parameterization with default MCMC options {.unnumbered}

In the main text, we have already seen that the non-centered parameterization
works better than the centered parameterization, at least when we use an
increased `adapt_delta` value. Let's see what happens when using the default 
MCMC option of Stan.

```{r fit_ncp, cache=TRUE, comment=NA, results='hide'}
fit_ncp <- stan(
  file = 'eight_schools_ncp.stan', data = eight_schools,
  iter = 2000, chains = 4, seed = 483892929, refresh = 0
)
```

We observe a few divergent transitions with the default of `adapt_delta=0.8`. 
Let's analyze the sample.

```{r}
monitor(fit_ncp)
res <- monitor_extra(fit_ncp)
print(res)
```

All Rhats are close to 1, and ESSs are good despite a few
divergent transitions. Small interval and quantile plots of `tau` reveal some
sampling problems for small `tau` values, but not nearly as strong as for the
centered parameterization.

```{r}
plot_local_ess(fit = fit_ncp, par = "tau", nalpha = 20)
plot_quantile_ess(fit = fit_ncp, par = "tau", nalpha = 40)
```

Overall, the non-centered parameterization looks good even for the default
settings of `adapt_delta`, and increasing it to 0.95 gets rid of the last
remaining problems. This stands in sharp contrast to what we observed for the
centered parameterization, where increasing `adapt_delta` didn't help at all.
Actually, this is something we observe quite often: A suboptimal
parameterization can cause problems that are not simply solved by tuning the
sampler. Instead, we have to adjust our model to achieve trustworthy inference.


## Appendix D: A centered eight schools model fit using a Gibbs sampler {#AppendixD .unnumbered}

We will also run the centered and non-centered parameterizations of
the eight schools model with Jags.

#### Centered Eight Schools Model {.unnumbered}

The Jags code for the centered eight schools model looks as follows:

```{r, comment=NA}
writeLines(readLines("eight_schools_cp.bugs"))
```

First, we initialize the Jags model for reusage later.

```{r}
jags_cp <- jags.model(
  "eight_schools_cp.bugs",
  data = eight_schools,
  n.chains = 4, n.adapt = 10000
)
```

Next, we sample 1000 iterations for each of the 4 chains for easy
comparison with the corresponding Stan results.

```{r}
samp_jags_cp <- coda.samples(
  jags_cp, c("theta", "mu", "tau"),
  n.iter = 1000
)
samp_jags_cp <- aperm(abind(samp_jags_cp, along = 3), c(1, 3, 2))
```

Convergence diagnostics indicate problems in the sampling
of `mu` and `tau`, but also to a lesser degree in all other paramters.

```{r}
mon <- monitor(samp_jags_cp)
print(mon)
```

We also see problems in the sampling of `tau` using various diagnostic plots.

```{r}
plot_local_ess(samp_jags_cp, par = "tau", nalpha = 20)
plot_quantile_ess(samp_jags_cp, par = "tau", nalpha = 20)
plot_change_ess(samp_jags_cp, par = "tau")
```

Let's see what happens if we run 10 times longer chains.

```{r}
samp_jags_cp <- coda.samples(
  jags_cp, c("theta", "mu", "tau"),
  n.iter = 10000
)
samp_jags_cp <- aperm(abind(samp_jags_cp, along = 3), c(1, 3, 2))
```

Convergence looks better now, although `tau` is still estimated not very
efficiently.

```{r}
mon <- monitor(samp_jags_cp)
print(mon)
```

The diagnostic plots of quantiles and small intervals tell a similar story.

```{r}
plot_local_ess(samp_jags_cp, par = "tau", nalpha = 20)
plot_quantile_ess(samp_jags_cp, par = "tau", nalpha = 20)
```

Notably, however, the increase in effective sample size of tau is linear
in the total number of draws indicating that convergence for `tau`
may be achieved by simply running longer chains.

```{r}
plot_change_ess(samp_jags_cp, par = "tau")
```

**Result:** Similar to Stan, Jags also has convergence problems with the
centered parameterization of the eight schools model.

#### Non-Centered Eight Schools Model {.unnumbered}

The Jags code for the non-centered eight schools model looks as follows:

```{r, comment=NA}
writeLines(readLines("eight_schools_ncp.bugs"))
```

First, we initialize the Jags model for reusage later.

```{r}
jags_ncp <- jags.model(
  "eight_schools_ncp.bugs",
  data = eight_schools,
  n.chains = 4, n.adapt = 10000
)
```

Next, we sample 1000 iterations for each of the 4 chains for easy
comparison with the corresponding Stan results.

```{r}
samp_jags_ncp <- coda.samples(
  jags_ncp, c("theta", "mu", "tau"),
  n.iter = 1000
)
samp_jags_ncp <- aperm(abind(samp_jags_ncp, along = 3), c(1, 3, 2))
```

Convergence diagnostics indicate much better mixing than for the centered eight school model.

```{r}
mon <- monitor(samp_jags_ncp)
print(mon)
```

Specifically, the mixing of `tau` looks much better although we still see
some problems in the estimation of larger quantiles.

```{r}
plot_local_ess(samp_jags_ncp, par = "tau", nalpha = 20)
plot_quantile_ess(samp_jags_ncp, par = "tau", nalpha = 20)
```

Change in effective sample size is roughly linear indicating that some remaining
convergence problems are likely to be solved by running longer chains.

```{r}
plot_change_ess(samp_jags_ncp, par = "tau")
```

**Result:** Similar to Stan, Jags can sample from the non-centered
parameterization of the eight schools model much better than from the centered parameterization.


## Appendix F: Examples of rank normalization {#AppendixF .unnumbered}

We will illustrate the rank normalization with a few examples. First, we plot
histograms, and empirical cumulative distribution functions (ECDF)  with respect
to the original parameter values ($\theta$), scaled ranks (ranks divided by the
maximum rank), and rank normalized values (z). We used scaled ranks to make the
plots look similar for different number of draws.

100 draws from Normal(0, 1):
```{r, message=FALSE}
n <- 100
theta <- rnorm(n)
plot_ranknorm(theta, n)
```

100 draws from Exponential(1):
```{r, message=FALSE}
theta <- rexp(n)
plot_ranknorm(theta, n)
```

100 draws from Cauchy(0, 1):
```{r, message=FALSE}
theta <- rcauchy(n)
plot_ranknorm(theta, n)
```

In the above plots, the ECDF with respect to scaled rank and rank normalized
$z$-values look exactly the same for all distributions. In *Split*-$\widehat{R}$
and effective sample size computations, we rank all draws jointly, but then
compare ranks and ECDF of individual split chains. To illustrate the variation
between chains, we draw 8 batches of 100 draws each from Normal(0, 1):

```{r, message=FALSE}
n <- 100
m <- 8
theta <- rnorm(n * m)
plot_ranknorm(theta, n, m)
```

The variation in ECDF due to the variation ranks is now visible also in scaled 
ranks and rank normalized $z$-values from different batches (chains).

The benefit of rank normalization is more obvious for non-normal distribution 
such as Cauchy:

```{r, message=FALSE}
theta <- rcauchy(n * m)
plot_ranknorm(theta, n, m)
```

Rank normalization makes the subsequent computations well defined and
invariant under bijective transformations. This means that we get the
same results, for example, if we use unconstrained or constrained
parameterisations in a model. 


## Appendix G: Variance of the cumulative distribution function  {#AppendixG .unnumbered}

In the paper, we had defined the empirical CDF (ECDF) for any $\theta_\alpha$ as
$$
p(\theta \leq \theta_\alpha) \approx \bar{I}_\alpha = \frac{1}{S}\sum_{s=1}^S
I(\theta^{(s)} \leq\theta_\alpha),
$$

For independent draws, $\bar{I}_\alpha$ has a 
${\rm Beta}(S\bar{I}_\alpha+1, S - S\bar{I}_\alpha + 1)$ 
distribution. Thus we can easily examine the variation of the ECDF for any
$\theta_\alpha$ value from a single chain. If $\bar{I}_\alpha$ is not very close
to $1$ or $S$ and $S$ is large, we can use the variance of Beta distribution

$$
{\rm Var}[p(\theta \leq \theta_\alpha)] =
\frac{(S\bar{I}_\alpha+1)*(S-S\bar{I}_\alpha+1)}{(S+2)^2(S+3)}.
$$
We illustrate uncertainty intervals of the Beta distribution and normal
approximation of ECDF for 100 draws from Normal(0, 1):
```{r, message=FALSE}
n <- 100
m <- 1
theta <- rnorm(n * m)
plot_ranknorm(theta, n, m, interval = TRUE)
```

Uncertainty intervals of ECDF for draws from Cauchy(0, 1) illustrate again the 
improved visual clarity in plotting when using scaled ranks:

```{r, message=FALSE}
n <- 100
m <- 1
theta <- rcauchy(n * m)
plot_ranknorm(theta, n, m, interval = TRUE)
```

The above plots illustrate that the normal approximation is accurate for
practical purposes in MCMC diagnostics.


## Appendix H: Dynamic HMC and effective sample size {#AppendixH .unnumbered}

We have already seen that the effective sample size of dynamic HMC can be higher
than with independent draws. The next example illustrates interesting relative
efficiency phenomena due to the properties of dynamic HMC algorithms.

We sample from a simple 16-dimensional standard normal model.

```{r}
writeLines(readLines("normal.stan"))
```

```{r fit_n, cache=TRUE, comment=NA, results='hide'}
fit_n <- stan(
  file = 'normal.stan', data = data.frame(J = 16),
  iter = 20000, chains = 4, seed = 483892929, refresh = 0 
)
```

```{r}
samp <- as.array(fit_n)
monitor(samp)
res <- monitor_extra(samp)
print(res)
```

The Bulk-ESS for all $x$ is larger than 
`r round(min(res[1:16, "zsseff"]), 2)`.  However tail-ESS for all
$x$ is less than `r round(max(res[1:16, "tailseff"]), 2)`. Further, 
bulk-ESS for `lp__` is only `r round(res["lp__", "zsseff"], 2)`.  
If we take a look at all the Stan examples in this notebook, we see that the 
bulk-ESS for `lp__` is always below 0.5. This is because `lp__` 
correlates strongly with the total energy in HMC, which is sampled using a 
random walk proposal once per iteration. Thus, it's likely that `lp__` has some
random walk behavior, as well, leading to autocorrelation and a small relative
efficiency. At the same time, adaptive HMC can create antithetic Markov chains
which have negative auto-correlations at odd lags. This results in a bulk-ESS 
greater than S for some parameters.

Let's check the effective sample size in different parts of the
posterior by computing the effective sample size for small interval estimates 
for `x[1]`.

```{r}
plot_local_ess(fit_n, par = 1, nalpha = 100)
```

The effective sample size for probability estimate for a small interval
is close to 1 with a slight drop in the tails. This is a good result,
but far from the effective sample size for the bulk, mean, and median estimates.
Let's check the effective sample size for quantiles.

```{r}
plot_quantile_ess(fit = fit_n, par = 1, nalpha = 100)
```

Central quantile estimates have higher effective sample size than tail
quantile estimates.

The total energy of HMC should affect how far in the tails a chain in
one iteration can go. Fat tails of the target have high energy, and
thus only chains with high total energy can reach there. This will
suggest that the random walk in total energy would cause random walk
in the variance of $x$. Let's check the second moment of $x$.

```{r}
samp_x2 <- as.array(fit_n, pars = "x")^2
monitor(samp_x2)
res <- monitor_extra(samp_x2)
print(res)
```

The mean of the bulk-ESS for $x_j^2$ is `r round(mean(res$zsseff),
2)`, which is quite close to the bulk-ESS for `lp__`. This is not that
surprising as the potential energy in normal model is proportional to
$\sum_{j=1}^J x_j^2$.

Let's check the effective sample size in different parts of the posterior by
computing the effective sample size for small interval probability estimates for
`x[1]^2`.

```{r}
plot_local_ess(fit = samp_x2, par = 1, nalpha = 100)
```

The effective sample size is mostly a bit below 1, but for the right tail of
$x_1^2$ the effective sample size drops. This is likely due to only some
iterations having high enough total energy to obtain draws from the high energy
part of the tail. Let's check the effective sample size for quantiles.

```{r}
plot_quantile_ess(fit = samp_x2, par = 1, nalpha = 100)
```

We can see the correlation between `lp__` and magnitude of `x[1]` in
the following plot.

```{r}
samp <- as.array(fit_n)
qplot(
  as.vector(samp[, , "lp__"]),
  abs(as.vector(samp[, , "x[1]"]))
) + 
  labs(x = 'lp__', y = 'x[1]')
```

Low `lp__` values corresponds to high energy and more variation in
`x[1]`, and high `lp__` corresponds to low energy and small variation
in `x[1]`. Finally $\sum_{j=1}^J x_j^2$ is perfectly correlated with `lp__`.

```{r}
qplot(
  as.vector(samp[, , "lp__"]),
  as.vector(apply(samp[, , 1:16]^2, 1:2, sum))
) + 
  labs(x = 'lp__', y = 'sum(x^2)')
```

This shows that even if we get high effective sample size estimates for central
quantities (like mean or median), it is important to look at the relative
efficiency of scale and tail quantities, as well. The effective sample size of
`lp__` can also indicate problems of sampling in the tails.


# Original Computing Environment {.unnumbered}

```{r, comment=NA}
makevars <- file.path(Sys.getenv("HOME"), ".R/Makevars")
if (file.exists(makevars)) {
  writeLines(readLines(makevars)) 
}
```

```{r, comment=NA}
devtools::session_info("rstan")
```

